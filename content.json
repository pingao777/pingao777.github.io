{"meta":{"title":"扯淡有理","subtitle":null,"description":"Java Python R 机器学习 统计 扯淡","author":"nonsense","url":"https://pingao777.github.io"},"pages":[{"title":"Categories","date":"2020-09-12T03:14:00.593Z","updated":"2020-09-12T03:14:00.593Z","comments":true,"path":"categories/index.html","permalink":"https://pingao777.github.io/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2020-09-12T03:14:00.592Z","updated":"2020-09-12T03:14:00.592Z","comments":true,"path":"about/index.html","permalink":"https://pingao777.github.io/about/index.html","excerpt":"","text":"项目 markdown-preview-sync：基于java的vim markdown预览插件 Yiya：无字典中文分词小程序，取“咿呀学语”之意 NewBe：五子棋对战ai，支持人机对战、机机对战 好玩 北京二手房数据分析：恩，买哪个别墅呢 北邮人论坛征友分析：征友者说，我想要“这样的” GitHub: https://github.com/pingao777 扯自己的淡，让别人去喷吧！"},{"title":"Tags","date":"2020-09-12T03:14:00.593Z","updated":"2020-09-12T03:14:00.593Z","comments":true,"path":"tags/index.html","permalink":"https://pingao777.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"毛泽东如何看待鲁迅","slug":"毛泽东如何看待鲁迅","date":"2021-04-17T05:50:27.000Z","updated":"2021-04-17T12:54:39.000Z","comments":true,"path":"2021/04/17/毛泽东如何看待鲁迅/","link":"","permalink":"https://pingao777.github.io/2021/04/17/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E9%B2%81%E8%BF%85/","excerpt":"","text":"坊间一直有个传闻，文革期间一次聊天中有人问毛泽东：要是今天鲁迅还活着，他可能会怎样？毛泽东回答：要么是关在牢里还是要写，要么他识大体不做声。我最早听说这件事是大学时期一个舍友说起的，当时听了既不关心也不在意。工作多年后对教员和社会有了更深的了解后又想起此事，想说点自己的想法。但凡对毛泽东有一点了解后就会发现，除了马克思列宁，没有一个人像鲁迅那样被毛泽东一次又一次的提到，赞美的无以复加，这种赞誉不是只在某一个特定时间段，而是一直到毛泽东去世前的几个月。毛泽东曾经用五个“最”称赞鲁迅，他引用鲁迅说过的话，写过的文章，做过的事，用现在的话说简直就是鲁迅的迷弟。关于此事，已经有人进行了考证（链接），是真是假相信每个人看了都有自己的判断。那么作为第一手的证据，毛泽东的作品中是如何评价鲁迅的呢，下面列举毛选中所有和鲁迅相关的片段，最早为1940年的《新民主主义论》，最晚为1976年去世前几个月的《走资派还在走，“永不翻案”靠不住》。 《新民主主义论&gt;： ……而鲁迅，就是这个文化新军的最伟大和最英勇的旗手。鲁迅是中国文化革命的主将，他不但是伟大的文学家，而且是伟大的思想家和伟大的革命家。鲁迅的骨头是最硬的，他没有丝毫的奴颜和媚骨，这是殖民地半殖民地人民最可宝贵的性格。鲁迅是在文化战线上，代表全民族的大多数，向着敌人冲锋陷阵的最正确、最勇敢、最坚决、最忠实、最热忱的空前的民族英雄。鲁迅的方向，就是中华民族新文化的方向…… ……作为军事“围剿”的结果的东西，是红军的北上抗日；作为文化“围剿”的结果的东西，是一九三五年“一二九”青年革命运动的爆发。而作为这两种“围剿”之共同结果的东西，则是全国人民的觉悟。这三者都是积极的结果。其中最奇怪的，是共产党在国民党统治区域内的一切文化机关中处于毫无抵抗力的地位，为什么文化“围剿”也一败涂地了？这还不可以深长思之吗？而共产主义者的鲁迅，却正在这一“围剿”中成了中国文化革命的伟人…… 《反对党八股》： ……党八股也就是一种洋八股。这洋八股，鲁迅早就反对过的⑷。我们为什么又叫它做党八股呢？这是因为它除了洋气之外，还有一点土气。也算一个创作吧！谁说我们的人一点创作也没有呢？这就是一个！（大笑）…… ……党八股的第二条罪状是：装腔作势，借以吓人。有些党八股，不只是空话连篇，而且装样子故意吓人，这里面包含着很坏的毒素。空话连篇，言之无物，还可以说是幼稚；装腔作势，借以吓人，则不但是幼稚，简直是无赖了。鲁迅曾经批评过这种人，他说：“辱骂和恐吓决不是战斗。”…… ……第三篇，是从《鲁迅全集》里选出的，是鲁迅复北斗杂志⑿社讨论怎样写文章的一封信。他说些什么呢？他一共列举了八条写文章的规则，我现在抽出几条来说一说。第一条：“留心各样的事情，多看看，不看到一点就写。”讲的是“留心各样的事情”，不是一样半样的事情。讲的是“多看看”，不是只看一眼半眼。我们怎么样？不是恰恰和他相反，只看到一点就写吗？第二条：“写不出的时候不硬写。”我们怎么样？不是明明脑子里没有什么东西硬要大写特写吗？不调查，不研究，提起笔来“硬写”，这就是不负责任的态度。第四条：“写完后至少看两遍，竭力将可有可无的字、句、段删去，毫不可惜。宁可将可作小说的材料缩成速写，决不将速写材料拉成小说。”孔夫子提倡“再思”⒀，韩愈也说“行成于思”⒁，那是古代的事情。现在的事情，问题很复杂，有些事情甚至想三四回还不够。鲁迅说“至少看两遍”，至多呢？他没有说，我看重要的文章不妨看它十多遍，认真地加以删改，然后发表。文章是客观事物的反映，而事物是曲折复杂的，必须反复研究，才能反映恰当；在这里粗心大意，就是不懂得做文章的起码知识。第六条：“不生造除自己之外，谁也不懂的形容词之类。”我们“生造”的东西太多了，总之是“谁也不懂”。句法有长到四五十个字一句的，其中堆满了“谁也不懂的形容词之类”。许多口口声声拥护鲁迅的人们，却正是违背鲁迅的啊！…… 《在延安文艺座谈会上的讲话》： ……诚然，为着剥削者压迫者的文艺是有的。文艺是为地主阶级的，这是封建主义的文艺。中国封建时代统治阶级的文学艺术，就是这种东西。直到今天，这种文艺在中国还有颇大的势力。文艺是为资产阶级的，这是资产阶级的文艺。像鲁迅所批评的梁实秋⑶一类人，他们虽然在口头上提出什么文艺是超阶级的，但是他们在实际上是主张资产阶级的文艺，反对无产阶级的文艺的…… ……鲁迅曾说：“联合战线是以有共同目的为必要条件的。……我们战线不能统一，就证明我们的目的不能一致，或者只为了小团体，或者还其实只为了个人。如果目的都在工农大众，那当然战线也就统一了…… ……中国的革命的文学家艺术家，有出息的文学家艺术家，必须到群众中去，必须长期地无条件地全心全意地到工农兵群众中去，到火热的斗争中去，到唯一的最广大最丰富的源泉中去，观察、体验、研究、分析一切人，一切阶级，一切群众，一切生动的生活形式和斗争形式，一切文学和艺术的原始材料，然后才有可能进入创作过程。否则你的劳动就没有对象，你就只能做鲁迅在他的遗嘱里所谆谆嘱咐他的儿子万不可做的那种空头文学家，或空头艺术家…… ……“还是杂文时代，还要鲁迅笔法。”鲁迅处在黑暗势力统治下面，没有言论自由，所以用冷嘲热讽的杂文形式作战，鲁迅是完全正确的。我们也需要尖锐地嘲笑法西斯主义、中国的反动派和一切危害人民的事物，但在给革命文艺家以充分民主自由、仅仅不给反革命分子以民主自由的陕甘宁边区和敌后的各抗日根据地，杂文形式就不应该简单地和鲁迅的一样。我们可以大声疾呼，而不要隐晦曲折，使人民大众不易看懂。如果不是对于人民的敌人，而是对于人民自己，那末，“杂文时代”的鲁迅，也不曾嘲笑和攻击革命人民和革命政党，杂文的写法也和对于敌人的完全两样。对于人民的缺点是需要批评的，我们在前面已经说过了，但必须是真正站在人民的立场上，用保护人民、教育人民的满腔热情来说话…… ……既然必须和新的群众的时代相结合，就必须彻底解决个人和群众的关系问题。鲁迅的两句诗，“横眉冷对千夫指，俯首甘为孺子牛”⒁，应该成为我们的座右铭。“千夫”在这里就是说敌人，对于无论什么凶恶的敌人我们决不屈服。“孺子”在这里就是说无产阶级和人民大众。一切共产党员，一切革命家，一切革命的文艺工作者，都应该学鲁迅的榜样，做无产阶级和人民大众的“牛”，鞠躬尽瘁，死而后已。知识分子要和群众结合，要为群众服务，需要一个互相认识的过程。这个过程可能而且一定会发生许多痛苦，许多磨擦，但是只要大家有决心，这些要求是能够达到的…… 《论十大关系》： ……《阿Q正传》是一篇好小说，我劝看过的同志再看一遍，没看过的同志好好地看看。 鲁迅在这篇小说里面， 主要是写一个落后的不觉悟的农民。他专门写了“不准革命”一章，说假洋鬼子不准阿Q革命。其实，阿Q当时的所谓革命，不过是想跟别人一样拿点东西而已。可是，这样的革命假洋鬼子也还是不准。我看在这点上，有些人很有点像假洋鬼子。他们不准犯错误的人革命，不分犯错误和反革命的界限，甚至把一些犯错误的人杀掉了。我们要记住这个教训。无论在社会上不准人家革命，还是在党内不准犯错误的同志改正错误，都是不好的…… 《在中国共产党全国宣传工作会议上的讲话》: ……有人说，几百字、一二千字一篇的杂文，怎么能作分析呢？我说，怎么不能呢？鲁迅不就是这样的吗？分析的方法就是辩证的方法…… 《工作方法六十条（草案）》: ……〔二十六〕以真正平等的态度对待干部和群众。必须使人感到人们互相间的关系确实是平等的，使人感到你的心是交给他的。学习鲁迅。鲁迅的思想是和他的读者交流的，是和他的读者共鸣的…… 《在七千人大会上的讲话-关于党的民主集中制》: ……世界革命总是要胜利的。不准革命，像鲁迅所写的赵太爷、钱太爷、假洋鬼子不准阿Ｑ革命那样，总是要失败的…… 《部队文艺工作座谈会纪要》: ……三十年代也有好的，那就是以鲁迅为首的战斗的左翼文艺运动。到了三十年代的中期，那时左翼的某些领导人在王明的右倾投降主义路线的影响下，背离马克思列宁主义的阶级观点，提出了“国防文学”〔6〕的口号。这个口号，就是资产阶级的口号，而“民族革命战争的大众文学”这个无产阶级的口号，却是鲁迅提出的。有些左翼文艺工作者，特别是鲁迅，也提出了文艺要为工农服务和工农自己创作文艺的口号，但是并没有系统地解决文艺同工农兵相结合这个根本问题…… ……〔6〕“国防文学”和“民族革命战争的大众文学”的口号之争，指一九三六年上海左翼文学界关于国防文学和民族革命战争的大众文学这两个口号的论争。这两个口号都是因日寇扩大对华侵略和国内阶级关系的新变化，为适应党中央关于建立抗日民族统一战线的策略要求而提出的。国防文学口号先由上海文学界地下党领导周扬提出，并由此开展了国防文学运动和国防戏剧、国防诗歌活动。民族革命战争的大众文学口号由党中央特派员冯雪峰到上海和鲁迅、胡风等商量后由胡风撰文提出的。受到主张国防文学的一些作家的指责而发生论争。鲁迅撰文提出两个口号可以”并存”，批评了主张国防文学的一些左翼领导人的关门主义、宗派派主义错误。这是左翼文学界在新形势下围绕建立文艺界统一战线由于某些思想分歧而发生的论争。鲁迅认为，“民族革命战争的大众文学”这个口号，在本身上，比“国防文学”的提法，意义更明确，更深刻，更有内容。在《论现在我们的文学运动》中，鲁迅进一步强调说：“民族革命战争的大众文学，正如无产革命文学的口号一样，大概是一个总的口号罢。在总口号之下，再提些随时应变的具体的口号，例如“国防文学”“救亡文学”“抗日文艺”……等等，我以为是无碍的。不但没有碍，并且是有益的，需要的。自然，太多了也使人头昏，浑乱。”并苦口婆心地跟徐懋庸那帮人作了解释：“中国的唯一的出路，是全国一致对日的民族革命战争。懂得这一点，则作家观察生活，处理材料，就如理丝有绪；作者可以自由地去写工人，农民，学生，强盗，娼妓，穷人，阔佬，什么材料都可以，写出来都可以成为民族革命战争的大众文学。也无需在作品的后面有意地插一条民族革命战争的尾巴，翘起来当作旗子……。”在这里，鲁迅正确地说明了“民族革命战争的大众文学”与无产阶级革命文学的关系，而且针对左翼文学队伍中有的人忽视、放弃无产阶级领导权的错误，特别强调了统一战线中无产阶级领导权的重要意义。鲁迅同时认为，“国防文学”是“目前文学运动的具体口号之一”，这个口号“颇通俗，已经有很多人听惯，它能扩大我们政治的和文学的影响，加之它可以解释为作家在国防旗帜下联合，为广义的爱国主义的文学的缘故”，因此，“它即使曾被不正确的解释，它本身含义上的缺陷，它仍应当存在，因为存在对于抗日运动有利益。”…… 《给江青的信》： ……在重大问题上，违心地同意别人，在我一生还是第一次。叫做不以人的意志为转移吧。晋朝人阮籍反对刘帮，他从洛阳走到成皋，叹到：世无英雄，遂使竖子成名。鲁迅也曾对于他的杂文说过同样的话，我跟鲁迅的心是相通的。我喜欢他那样坦率。他说，解剖自己，往往严于解剖别人。在跌了几跤之后，我亦往往如此。可是同志们往往不信，我是自信而又有些不自信…… 《关于《水浒》的评论》： ……鲁迅评《水浒》评得好，他说：“一部《水浒》，说得很分明：因为不反对天子，所以大军一到，便受招安，替国家打别的强盗——不‘替天行道’的强盗去了。终于是奴才。”〔《三闲集·流氓的变迁》〕金圣叹把《水浒》砍掉了二十多回。砍掉了，不真实。鲁迅非常不满意金圣叹，专写了一篇评论金圣叹的文章《谈金圣叹》〔见《南腔北调集》〕。《水浒》百回本、百二十回本和七十一回本，三种都要出。把鲁迅的那段评语印在前面…… 《走资派还在走，“永不翻案”靠不住》： ……我建议一二年内读点哲学，读点鲁迅。读哲学，可以看杨荣国〔15〕的《中国古代思想史》和《简明中国哲学史》…… 传言中识大体不作声必定不是鲁迅，不让别人讲话的也必定不是毛泽东。事实上，如果鲁迅能活到建国后，与其说鲁迅因反对文革入狱，不如说他更有可能成为毛泽东为数不多的盟友和导师，因为毛和鲁都是真正的革命者，而真正的革命者必定是一支枪指着敌人，一支枪时刻对准自己，诚如毛在《给江青的信》中所说“我跟鲁迅的心是相通的”。","categories":[],"tags":[{"name":"毛泽东","slug":"毛泽东","permalink":"https://pingao777.github.io/tags/%E6%AF%9B%E6%B3%BD%E4%B8%9C/"},{"name":"鲁迅","slug":"鲁迅","permalink":"https://pingao777.github.io/tags/%E9%B2%81%E8%BF%85/"}]},{"title":"Loom项目的进展：第二部分（State of Loom）","slug":"Loom项目的进展：第二部分（State-of-Loom）","date":"2020-10-31T04:11:39.000Z","updated":"2020-10-31T07:50:51.051Z","comments":true,"path":"2020/10/31/Loom项目的进展：第二部分（State-of-Loom）/","link":"","permalink":"https://pingao777.github.io/2020/10/31/Loom%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%BF%9B%E5%B1%95%EF%BC%9A%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%C2%86%EF%BC%88State-of-Loom%EF%BC%89/","excerpt":"","text":"第一部分介绍了虚拟线程并解释了JDK如何适配的去使用它们。随着线程的数量越来越多，生命周期越来越短，管理它们和在它们之间分配工作的新方法属于 Project Loom 的范畴: 在线程之间传递数据的新的灵活机制(比如通道)可能是可取的; 聚集大量线程可以受益于一种被称为结构化并发(structured concurrency)的组织和监督方法; 最后，我们正在探索一种比线程局部变量更方便、更有效的构造，用于我们暂时称为作用域变量(scope variables)的上下文数据。 和往常一样，如果您能向Loom开发人员邮件列表反馈使用Loom的体验，我们将非常感激。 通道当涉及到线程计算的单个结果的交流时，java.util.concurrent.Future就足够了，同时CompletableFuture类架起了同步世界和异步世界的桥梁：使用thenXXX进行异步操作，使用get进行同步操作。当涉及到多个结果的交流时，Flow类为异步代码提供了一个很好的解决方案。在设计出更多的同步解决方案之前，BlockingQueue可用于在线程之间通信多个值(特别是 LinkedTransferQueue)。 在一个原型中，通道类型被称为 Carrier，以区别于 NIO 通道。尽管可能会发生变化，但目前看起来是这样的: Carrier&lt;String&gt; carrier = new Carrier&lt;&gt;(); Thread producer = Thread.startVirtualThread(() -&gt; &#123; Carrier.Sink&lt;String&gt; sink = carrier.sink(); sink.send(&quot;message1&quot;); sink.send(&quot;message2&quot;); sink.closeExceptionally(new InternalError()); &#125;); Thread consumer = Thread.startVirtualThread(() -&gt; &#123; try (Carrier.Source&lt;String&gt; source = carrier.source()) &#123; while (true) &#123; String message = source.receive(); System.out.println(message); &#125; &#125; catch (IllegalStateException e) &#123; System.out.println(&quot;consumer: &quot; + e + &quot; cause: &quot; + e.getCause()); &#125; &#125;); producer.join(); consumer.join(); 结构化并发由于线程代价低廉且数量众多，它们可以从聚集线程的标准实践中获益。我们发现了一个特别吸引人的方法: 结构化并发。 结构化并发将线程生命周期分解为代码块。类似于结构化编程控制将顺序执行的控制流限制在一个定义良好的代码块中，结构化的并发性对并发控制流也是如此。它的基本原则是: 在某个代码单元中创建的线程必须在我们退出该代码单元时全部终止; 如果执行分裂为某个范围内的多个线程，它必须在退出该范围之前合并。特别是，方法在生成可以无限期存活的线程后不应返回。 为了让这个想法更清楚，让我们看一些代码。在我们当前的原型中，我们使用限制子线程生命周期的代码块代表一个结构化并发范围，通过将java.util.concurrent.ExecutorService成为一个AutoCloseable，close方法用来关闭服务等待终止。这保证了在我们退出try with resources（TWR）块时，提交给executor的所有任务都将终止，并将它们的生命周期限制在代码结构中： ThreadFactory vtf = Thread.builder().virtual().factory(); try (ExecutorService e = Executors.newUnboundedExecutor(vtf)) &#123; e.submit(task1); e.submit(task2); &#125; // blocks and waits 在我们退出TWR块之前，当前线程将阻塞，等待所有任务及其线程完成。一旦离开它，我们就可以保证任务已经结束。 因此，我们直接将代码表示成某些过程计算的非常有组织的形式。如果;是顺序组合，|是并行组合，那么我们的代码可以这样描述：a;(b|((c|d);e));f，其中连接点（我们等待子线程完成）是并行操作之后和下一个顺序操作之前的右括号，如(x|y|z);w。 除了清晰之外，该结构还具有强大的不变性：每个线程（在结构化并发上下文中）都有一些“父”线程，该线程被阻塞以等待其终止，因此应当关心何时（或者如何）执行。它在错误传播和消除方面具有一些强大的优势。 结构化中断非结构化线程脱离了任何上下文或明确的责任。由于结构化线程显然为其父级执行某些工作，因此当取消父级时，也应取消子级。 因此，如果父线程被中断，我们将中断传播给它的子线程。我们还可以给所有任务一个截止期限，在任务到期时中断那些尚未终止的子任务（以及当前线程）： try (var e = Executors.newUnboundedExecutor(myThreadFactory) .withDeadline(Instant.now().plusSeconds(30))) &#123; e.submit(task1); e.submit(task2); &#125; 结构化错误非结构化线程可能会遇到异常，并且会在没有任何注意的情况下单独死亡。结构化线程的故障将由其监视的父级观察到，然后可以将故障置于上下文中，例如，通过将子异常的堆栈跟踪与其父级的堆栈跟踪缝合在一起。 但是错误传播带来了一些挑战。假设一个子线程抛出的异常会自动传播到其父节点，结果，该异常将随后取消（中断）父线程的所有其他子线程。在某些情况下，这可能是理想的选择，但是是否应该是默认行为尚不清楚。因此，目前，我们正在尝试更明确的错误和结果处理。 我们可以使用新的ExecutorService.submitTasks)和CompletableFuture.stream)，它将每个任务完成时的结果流化，不管成功与否(也充当到CompletableFuture的异步世界的桥梁)，以等待第一个任务成功完成，然后取消所有其他任务： try (var e = Executors.newUnboundedVirtualThreadExecutor()) &#123; List&lt;CompletableFuture&lt;String&gt;&gt; tasks = e.submitTasks(List.of( () -&gt; &quot;a&quot;, () -&gt; &#123; throw new IOException(&quot;too lazy for work&quot;); &#125;, () -&gt; &quot;b&quot;, )); try &#123; String first = CompletableFuture.stream(tasks) .filter(Predicate.not(CompletableFuture::isCompletedExceptionally)) .map(CompletableFuture::join) .findFirst() .orElse(null); System.out.println(&quot;one result: &quot; + first); &#125; catch (ExecutionException ee) &#123; System.out.println(&quot;¯\\\\_(ツ)_/¯&quot;); &#125; finally &#123; tasks.forEach(cf -&gt; cf.cancel(true)); &#125; &#125; 一些常见模式可以由helper方法提供服务，比如ExecutorService的invokeAll或invokeAny。此示例与上面更详细的示例执行相同的操作： try (var e = Executors.newUnboundedVirtualThreadExecutor()) &#123; String first = e.invokeAny(List.of( () -&gt; &quot;a&quot;, () -&gt; &#123; throw new IOException(&quot;too lazy for work&quot;); &#125;, () -&gt; &quot;b&quot; )); System.out.println(&quot;one result: &quot; + first); &#125; catch (ExecutionException ee) &#123; System.out.println(&quot;¯\\\\_(ツ)_/¯&quot;); &#125; 这些API位于EA中，但是随着我们试图使线程管理更加友好，该领域可能会有很多变化。 结构化服务性和可观测性结构化并发不仅有助于组织代码，还有助于在进行概要分析和调试时提供有意义的上下文。一百万个线程的线程dump可能没有用，但是如果可以将这些线程显示在根据结构化并发作用域层次结构排列的树中，则可以更好地理解它们。同样，JFR可以按SC作用域对线程及其执行的操作进行分组，从而可以放大或缩小配置文件。这项工作不太可能进入第一个预览版。 作用域变量有时我们需要以对中间框架透明的方式将某些上下文从调用者传递到被调用者。例如，一个调用链foo→bar→baz，foo和baz是应用代码，bar是程序库代码，或者反过来，foo希望在没有bar参与的情况下与baz共享数据。目前，这通常是通过线程局部变量ThreadLocal来完成的，但是TLs(我们将简称为TLs)有严重的缺点。 一方面，它们的结构与我们上面使用的含义类似：一旦设置了TL值，该值在线程的整个生命周期内有效，或者直到将其设置为其他值为止。实际上，我们通常会看到一种使用模式，试图借用TL结构（不幸的是，没有任何性能优势）： var oldValue = myTL.get(); myTL.set(newValue); try &#123; ... &#125; finally &#123; myTL.set(oldValue); &#125; 如果没有这种强制性的结构，当在多个任务之间共享线程时，一个任务的TL值可能会泄漏到另一个任务中。虚拟线程通过足够轻量级而无需共享来解决该问题。但是，这种非结构化的特性还意味着TL实现必须依靠弱引用来允许GC清理不再使用的TL，这会使它们的实现速度大大降低。 另一个问题是继承。例如，那些使用像OpenTracing这样的分布式跟踪工具的人，可能想要从父线程继承跟踪“ span”。这可以通过InheritableThreadLocal(iTL)实现。创建线程时必须复制线程中的iTL映射，因为iTL是可变的，因此无法共享。这既造成了占用空间又造成了速度上的损失。另外，由于当今的线程是非结构化的，因此当子线程访问其继承的span时，其父级可能已将其关闭。虚拟线程只会加剧iTL继承的问题，因为它们鼓励创建许多小线程，其中一些代表其父线程执行一些小任务，例如单个HTTP请求，从而增加了对iTL继承的需求以及复杂的占用空间和速度成本。 如果一次设置后TL不可变，则继承可以提高效率，但可以考虑设置TL的方法。现在，它将根据其调用方是否设置了相同的TL引发非法状态异常，从而严重损害代码的可组合性。 为了解决这些问题，我们正在探索一种在性能、占用空间、结构和正确性方面更好的替代方法，我们尝试性地调用范围变量。与TLs一样，SVs引入了一些隐式上下文，但与TLs不同，它们是针对代码块的span而构造的，而不是针对线程的整个生命周期。SV也是不可变的，尽管它们的值可以被嵌套的作用域遮蔽。 这是使用当前EA原型中的java.lang.Scoped API的示例： static final Scoped&lt;String&gt; sv = Scoped.forType(String.class); void foo() &#123; try (var __ = sv.bind(&quot;A&quot;)) &#123; bar(); baz(); bar(); &#125; &#125; void bar() &#123; System.out.println(sv.get()); &#125; void baz() &#123; try (var __ = sv.bind(&quot;B&quot;)) &#123; bar(); &#125; &#125; baz不会更改sv的绑定，而是在嵌套作用域中引入了新的绑定，从而隐藏了其封闭的绑定。因此foo将输出： A B A 因为SV绑定的生命周期是明确定义的，所以我们不需要依赖GC进行清理，因此我们不需要弱引用来减慢我们的速度。 那继承呢？由于SV是不可变的，并且结构化并发还为我们提供了语法限制的线程生命周期，因此SV继承就像手套一样适合结构化并发： try (var context = Foo.openContext()) &#123; // some temporary context that can be closed try (var __ = contextSV.bind(context); var executor = Executors.newUnboundedExecutor(myThreadFactory)) &#123; executor.submit(() -&gt; &#123; ... &#125;); executor.submit(() -&gt; &#123; ... &#125;); &#125; &#125; 提交的任务会自动继承contextSV的上下文值，并且由于UnboundedExecutor范围被上下文的生命周期范围所包围，因此可以确定任务从contextSV获得的上下文尚未关闭。 其他类型的结构化构造（即其计算仅限于语法元素的构造）也可以提供自动SV继承。例如： try (var __ = sv.bind(value)) &#123; Set.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;).stream().parallel() .forEach(s -&gt; System.out.println(s + &quot;: &quot; + sv.get())); &#125; 由于流的forEach操作也完全受限于SV的绑定范围，即使forEach可能在不同线程中的不同流元素上执行其主体，值也可以继承。 范围变量仍处于设计阶段的早期，并且与我们可能会引入try-with-resources的更一般的更改相关联（请参阅此处以了解一些想法）。即使我们决定使用SV，它们也可能会错过第一个Preview和GA。 处理器本地变量线程本地变量的另一种用法不是将数据与线程上下文关联，而是“标记”一些写量大、易变的数据结构，以避免争用(例如LongAdder，它不使用ThreadLocal类，但依赖于类似的思想)。当线程数不比内核数大很多时，这是有道理的，但是可能有数百万个线程，这纯粹是开销。我们正在探索一种具有类似CAS语义的“处理器本地”结构，如果具有适当的OS支持（例如Linux的可重启序列），它比无竞争的CAS还要快。 有关中断和取消的更多信息线程支持一种协作中断机制，该机制由方法interrupt，interrupted，isInterrupted和InterruptedException组成。这是一种相当复杂的机制：某些线程在另一个线程上调用中断，从而设置目标线程的中断状态。目标线程轮询其中断状态，可能会从阻塞方法中抛出InterruptedException，但也会清除该状态，这有两个原因。首先，线程可能是池中的共享资源。当前任务可以被中断，但是调度程序可能想要重用线程来运行其他任务，因此必须重置中断状态。对于虚拟线程，这是不必要的，因为它们足够轻巧，不会被重复用于其他任务。但是还有另一个原因：线程可能会观察到它已被中断，并且在清理过程中可能希望调用阻塞方法。如果状态未清除，则阻塞方法将立即引发InterruptedException。尽管此机制确实可以满足实际需求，但它容易出错，因此我们希望对其进行重新讨论。我们已经试验了一些原型，但是目前还没有任何具体方案。 强制抢占尽管已经有了关于调度的说法，但在某些特殊情况下，强行抢占占用CPU的线程可能会很有用。例如，代表多个客户端应用程序执行复杂数据查询的批处理服务可以接收客户端任务，并在各自的虚拟线程中运行它们。如果此类任务占用过多的CPU，则该服务可能要强行抢占它，并在该服务负载较轻时再次安排它。为此，我们计划让VM支持尝试在任何安全点强制抢占执行的操作。该功能如何向调度程序公开是待定的，并且可能不会出现在第一个预览版中。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"}]},{"title":"Loom项目的进展：第一部分（State of Loom）","slug":"Loom项目的进展：第一部分（State of Loom）","date":"2020-10-11T05:27:24.000Z","updated":"2020-10-18T09:58:00.410Z","comments":true,"path":"2020/10/11/Loom项目的进展：第一部分（State of Loom）/","link":"","permalink":"https://pingao777.github.io/2020/10/11/Loom%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%BF%9B%E5%B1%95%EF%BC%9A%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%88State%20of%20Loom%EF%BC%89/","excerpt":"","text":"本文是State of Loom的翻译。 Loom 项目旨在大大减少编写、维护和观察高吞吐量并发应用程序的工作量，从而最大限度地利用可用硬件。 Loom项目的工作于2017年开始。本文档解释了项目的动机和所采取的方法，并总结了我们迄今为止的工作。像所有OpenJDK项目一样，它将分阶段交付，不同的组件在不同的时间到达GA(通用可用性) ，可能首先利用预览（ Preview）机制。 您可以在它的wiki上找到更多关于Loom项目的资料，并在Loom EA binaries 文件(Early Access)中尝试下面描述的大部分内容。非常感激如果你能够将使用Loom的意见反馈到loom-dev邮件列表。 Thread.startVirtualThread(() -&gt; &#123; System.out.println(&quot;Hello, Loom!&quot;); &#125;); 要点 虚拟线程是一个Thread——在代码层面、运行时、调试阶段以及分析阶段都如此。 虚拟线程并不是OS线程的包装，而是一个Java对象。 创建一个虚拟线程的代价非常低廉——你可以创建数百万的虚拟线程，不用池化它们。 阻塞一个虚拟线程的代价非常低廉。 不需要改变语言。 可插拔式调度器提供了异步编程的灵活性。 内容 为什么 线程就是一切 支撑线程失去了它们的重点 大小合适的线程 从线程到虚拟线程 如何使用虚拟线程编程（你已经知道） 调度 性能和足迹 自旋 所有阻塞由我们来负责 调试和分析 为什么“虚拟” 第二部分：进一步的工作 为什么线程就是一切Java 用于编写一些世界上最大、最具可伸缩性的应用程序。可伸缩性是程序优雅地处理不断增长的工作负载的能力。实现可伸缩性的一种方式是并行（parallelism）：我们想要处理一大块可能相当大的数据，我们将它转换为lambda流水线，通过将它设置为并行，我们要求多个处理核心一起处理流水线上的任务，就像一群食人鱼吞食一条大鱼一样; 一条食人鱼也可以完成任务—- 只是前面的方式更快。这种机制是在 java8中实现的。但是有一种不同的、更难的、更普遍的扩展方式，即在同一时间处理应用程序中相对独立的任务。它们必须同时得到服务，这不是一种实现选择，而是一种要求。我们称之为并发性（concurrency），它是当代软件的基础，这就是Loom的意义所在。 考虑一下web服务器。它所服务的每个请求在很大程度上都是独立于其他请求的。对于每个服务，我们进行一些解析、查询数据库或向服务发出请求，然后等待结果，再进行一些处理并发送响应。这个过程不仅在完成某项工作时不与其他同时发生的HTTP请求合作，而且大多数时候它根本不关心其他请求在做什么，但它仍然在处理数据和I/O资源方面与它们竞争。不是食人鱼，而是出租车，每一条都有自己的路线和目的地。在同一条道路上行驶的其他出租车并不会让任何一辆出租车更早到达目的地ーー如果非要说有什么影响的话，也许会减慢速度ーー但是如果在城市道路上的任何时间只有一辆出租车，那就不仅仅是一个缓慢的交通系统，而是一个功能失调的系统。越多的出租车可以共用道路同时又不会造成市中心的交通拥堵，这个系统就越好。从早期开始，Java 就支持这种工作。Servlet 允许我们编写在屏幕上看起来简单直观的代码。一个简单的过程为ーー解析、数据库查询、处理、响应ーー不管服务器现在只处理这一个请求还是处理其他一千个请求。 每个并发应用程序都有一些天然属于其领域的并发单元，这些工作是可以独立于其他工作同时完成的。对于web服务器，这可能是HTTP请求或用户会话; 对于数据库服务器，这可能是事务。并发性有着比Java早得多的悠久而丰富的历史，但就Java的设计思想而言，其实很简单: 用一个按顺序运行的并发软件单元来表示这个领域并发单元，就像一辆出租车沿着其简单的路线前进，而不考虑其他任何出租车一样。这种软件构造就是线程。它对从处理器到I/O设备的资源进行虚拟化，并对其使用进行调度ーー利用每个线程可能在不同时间使用不同硬件单元的事实ーー对外暴露出来就好象一个顺序的过程。线程的拥有属性在于，它们不仅对处理操作进行排序，而且还对阻塞进行排序—- 等待某些外部事件的发生，不管是I/O还是某些事件，或者由另一个线程触发，只有在这些事件发生之后才继续执行。线程应该如何最好地相互通信的问题ーー共享数据结构和消息传递的合适的组合应该是什么ーー对于线程的概念来说并不是必不可少的，而且不管Java应用程序当前的组合是什么，它都有可能随着新特性的出现而改变。 无论您是直接使用它们，还是在JAX-RS框架内使用它们，并发在Java中意味着线程。事实上，整个Java平台——从虚拟机，到语言和库，到调试器和分析器——都是围绕线程构建的，作为运行程序的核心组成部分: I/O API是同步的，I/O操作初始化并通过阻塞线程等待一系列语句的顺序结果； 内存副作用(如果为无竞争的)按照线程的操作顺序排序，就好像没有其他线程竞争使用该内存; 异常通过将失败操作放在当前线程的调用堆栈的上下文中提供有用的信息; 调试器中的单步执行按照顺序执行，无论是需要进行某种处理还是 I/O，因为单步执行与线程相关联; 分析器使用线程来展示操作、I/O等待或同步所耗费的时间； 问题在于，作为并发性的软件单元，线程的规模无法与应用领域的并发性单元(会话、 HTTP 请求或单个数据库操作)相匹配，也无法与现代硬件所能支持的并发性规模相匹配。一台服务器可以处理超过100万个并发打开的套接字，但是操作系统不能有效地处理超过几千个活动(非空闲)线程。随着servlet容器的工作负载增加，越来越多的请求处于运行状态，它的伸缩能力受到操作系统能够支持的线程数量相对较少的限制，因为Little定律告诉我们，服务请求的平均持续时间与我们能够并发执行的请求数量成正比。因此，如果我们用一个线程来表示一个并发领域单元，那么线程的稀缺性早在硬件实现之前就成为了我们的可伸缩性瓶颈。servlet 读起来好伸缩性不好。 这不是线程概念的基本限制，而是它们在JDK中作为操作系统线程的简单包装器实现的一个偶然特性。操作系统线程的占用空间很大，创建它们需要分配操作系统资源，而调度它们(即为它们分配硬件资源)是次优的。他们与其说是出租车，不如说是火车。 这就造成了线程本来要做的事情与它们能够有效地做的事情之间的巨大不匹配。几个数量级的不匹配可能会产生很大的影响。 支撑线程失去了它们的重点上述实现产生了巨大的影响。具有讽刺意味的是，线程发明出来是为了透明地共享虚拟化的稀缺计算资源，而线程本身已经成为稀缺资源，以至于我们不得不建立复杂的脚手架来共享它们。 因为线程的创建成本很高，所以我们将它们集中起来。创建一个新线程的成本是如此之高，以至于为了重用它们，我们很乐意为泄漏的线程局部变量和复杂的取消协议买单。 但是线程池本身提供的线程共享机制过于粗粒度。即使在一个时间点上运行的所有并发任务线程池中都没有足够的线程来表示。在任务的整个持续时间都会占用从线程池中借用到的线程，即使在等待某个外部事件(如来自数据库或服务的响应，或任何其他可能阻止它的活动)时。当任务正在等待时，操作系统线程挂起的代价实在是太高了。为了更好和更有效地共享线程，我们可以在每次任务必须等待某个结果时将线程返回池。这意味着任务在整个执行过程中不再绑定到单个线程。这也意味着我们必须避免阻塞线程，因为阻塞的线程不能用于其他任何工作。 其结果是异步api的大行其道，从JDK中的异步NIO，到异步servlet，再到许多所谓的“反应”库，这些库正是这样做的——在任务等待时将线程返回到池中，并尽最大努力不阻塞线程。将任务分解并异步构造最后再将它们组合在一起，结果形成了侵入式的、全局的和约束性的框架。即使是基本的控制流，比如循环和try/catch，也需要在“反应式”dsl中重新构造一遍，有些sporting类拥有数百个方法。 因为，如上所述，大多数Java平台都假设执行上下文包含在一个线程中，一旦我们将任务与线程分离，所有上下文都将丢失: 异常堆栈跟踪不再提供有用的上下文，当单步调试时，我们发现自己处于调度程序代码中，从一个任务跳转到另一个任务，分析器在I/O负载下可能会向我们显示空闲线程池，因为等待I/O的任务不会通过阻塞占有线程，而是返回到池中。 这种风格现在被一些人使用，并不是因为它更容易理解——许多程序员报告说，对他们来说，这种风格更难理解; 不是因为它更容易调试或分析——而是更难; 不是因为它与语言的其他部分很好地契合，或者与现有代码很好地集成，或者可以隐藏在“专家专用代码”中——恰恰相反，它具有病毒侵入性，使得与普通同步代码的干净集成几乎成为不可能，而只是因为Java中线程在占用空间和性能上的实现都不足。异步编程风格时刻与Java平台的设计作斗争，并且在可维护性和可观察性方面付出了高昂的代价。但它这样做有一个很好的理由: 满足可伸缩性和吞吐量要求，并充分利用昂贵的硬件资源。 一些编程语言试图通过在线程之上构建一个新概念来解决棘手的异步代码问题: async/await。它的工作方式类似于线程，但是协作调度点显式地标记为await。这使得编写可伸缩的同步代码成为可能，并通过引入一种新的上下文来解决上下文问题，这种线程是一种除了名称以外与线程都不兼容的“新线程”。如果同步代码和异步代码不能混在一起——一个阻塞和另一个却返回某种类型的 Future或Flow —— async/await则创建了两个不同的“彩色”世界，即使它们都是同步的，也不能混合在一起。为了使问题更加复杂，异步的调用同步代码，尽管它们是同步的，但没有线程被阻塞。因此，在C#中暂停当前正在执行的代码的一段时间需要两个不同的api，Kotlin也是这样做的，一个用来暂停线程，另一个用来暂停类似于线程但不是线程的新线程。同样的道理也适用于所有新创建的同步api，从同步API到I/O。不仅仅是同一个概念的两个实现没有一个统一的抽象，而且这两个世界在语法上是分离的，要求程序员标记他的代码单元适合以一种模式或另一种模式运行，而不是两种模式都适合。 此外，显式的协作调度点在Java平台上几乎没有提供什么好处。VM是针对峰值性能进行优化的，而不是像实时操作系统那样具有确定性的最坏情况延迟，因此它可能会在程序的任意点引入各种暂停，更不用说操作系统的任意、不确定和不加限制的抢占。阻塞操作的持续时间可能比那些不确定的暂停时间长几个数量级，也可能短几个数量级，因此明确标记它们帮助不大。在更适当的粒度上控制延迟的一种更好的方法是deadlines。 将线程作为稀缺资源进行管理的机制是一个很不幸的案例，因为实现的运行时性能特征而放弃了一个很好的抽象，取而代之的是另一个在大多数情况下更糟糕的方案。这种状态对Java生态系统产生了巨大的不利影响。 程序员被迫在直接将域并发单元建模为线程和浪费其硬件可以支持的相当大的吞吐量之间做出选择，或者使用其他方法在非常细粒度的级别上实现并发，但放弃Java平台的优势。无论是在硬件方面，还是在开发和维护工作方面，这两种选择都有相当大的财务成本。 我们可以做得更好。 Loom项目旨在消除高效运行并发程序与高效编写、维护和观察程序之间令人沮丧的权衡。它利用了平台的优势，而不是与之斗争，同时也利用了异步编程的高效组件的优势。它可以让你以熟悉的风格编写程序，使用熟悉的api，并与平台及其工具——以及硬件——保持一致，以便在写入时间和运行时成本之间达到平衡，我们希望这将具有广泛的吸引力。它在不改变语言的情况下做到了这一点，并且只对核心库api做了很小的改动。一个简单的同步web服务器将能够处理更多的请求，而不需要更多的硬件。 大小合适的线程如果我们可以让线程更轻，我们可以有更多的线程。如果我们有更多这样的资源，它们就可以按预期的那样使用: 通过虚拟化稀缺的计算资源和隐藏管理这些资源的复杂性，直接表示并发的领域单元。这并不是一个新的想法，或许最为人所熟悉的就是Erlang和Go所采用的方法。 我们的基础是虚拟线程。虚拟线程是线程，但创建和阻塞它们的代价很低。它们由Java运行时管理，与现有的平台线程不同，它们不是OS线程的一对一包装，而是在JDK的用户空间中实现的。 OS线程是重量级的，因为它们必须支持所有语言和所有工作负载。线程要求具有暂停和恢复执行的能力。这需要保持它的状态，包括指令指针或程序计数器，它包含当前指令的索引，以及存储在堆栈上的所有本地计算数据。因为操作系统不知道一种语言如何管理它的堆栈，所以它必须分配一个足够大的堆栈。然后，我们必须通过将执行分配给某个空闲的CPU核心来安排它们何时可以运行(启动或未停放)。由于操作系统内核必须调度各种各样的线程，这些线程在处理和阻塞的混合过程中表现得非常不同ーー有些是处理HTTP请求，有些是播放视频ーー它的调度程序必须是一个充分的全方位妥协。 Loom增加了控制执行，挂起和恢复它的能力，通过具体化它的状态不是作为一个操作系统资源，而是作为一个虚拟机了解的Java对象，并由 Java Runtime直接控制。Java 对象安全有效地为各种状态机和数据结构建模，因此也非常适合于建模执行。Java Runtime知道Java代码如何使用堆栈，因此它可以更紧凑地表示执行状态。对执行的直接控制还可以让我们选择更适合我们工作负载的调度程序(普通的Java调度程序) ; 实际上，我们可以使用可插拔的自定义调度程序。因此，Java Runtime对Java代码的卓越洞察力使我们能够减少线程的成本。 尽管操作系统可以支持多达几千个活动线程，但 Java Runtime可以支持数百万个虚拟线程。应用程序域中的每个并发单元都可以由其自己的线程来表示，从而使并发应用程序的编程更加容易。忘记线程池吧，只需要生成一个新线程，每个任务一个线程。您已经产生了一个新的虚拟线程来处理传入的HTTP请求，但是现在，在处理请求的过程中，您希望同时查询数据库并向其他三个服务发出传出请求？没问题—- 创建更多的线程。你需要等待一些事情发生而不浪费宝贵的资源？忘记回调或反应式流ーー直接阻塞就好了。编写简单、无聊的代码。线程给我们带来的所有好处——控制流、异常上下文、调试流、分析组织——都被虚拟线程保留下来; 只有运行时占用空间和性能的成本没有了。与异步编程相比，灵活性没有损失，因为正如我们将看到的，我们还没有放弃对调度的细粒度控制。 迁移：从线程到虚拟线程有了新的功能，我们知道如何实现虚拟线程; 如何向程序员展示这些线程就不那么清楚了。 每一个新的Java特性都在保守和创新之间创造了一种张力。前向兼容性使现有代码可以享受新特性(一个很好的例子是使用单一抽象方法类型的旧代码如何与lambdas一起工作)。但我们也希望纠正过去的设计错误，重新开始。 java.lang.Thread可以追溯到Java 1.0，多年来积累了方法和内部字段。它包含的方法有suspend、resume、 stop和countStackFrames，这些方法已经被废弃了20多年; 还有getAllStackTraces这样的方法，它假定线程数量很小，是一些过时的概念，比如上下文类加载器(context-classloader) ，添加这些概念是为了支持某些应用程序容器的使用; 甚至还有一些更老的方法，比如ThreadGroup，它的原始用途似乎已经被历史遗忘，但仍然充斥着许多处理线程的内部代码和工具，包括一些过时的方法，比如Thread.enumerate。 实际上，Loom的早期原型是在一个新的Fiber类中表示我们的用户模式线程，它帮助我们检查现有代码对线程API的依赖性。实验中的几个观察结果帮助我们确定了我们的立场: 线程API的某些部分被广泛使用，特别是Thread.currentThread()和ThreadLocal。没有它们，几乎没有现有代码可以运行。我们尝试使ThreadLocal的意思是thread-or-fiber-local，并且让 Thread.currentThread()返回一些fiber的线程视图，但是这些都增加了复杂性。 Thread API 的其他部分不仅很少使用，而且很少向程序员公开。从 Java 5开始，程序员就被鼓励通过 ExecutorServices间接地创建和启动线程，这样Thread类中的混乱就不会带来极大的危害; 新的Java开发人员不需要接触到它的大部分，也不需要接触到它过时的残余。因此，保持 Thread API 的教学成本很小。 我们可以通过将Thread类中的元数据移动到一个“sidecar”对象来减少元数据的占用空间，只根据需要分配元数据。 新的弃用和删除策略将逐渐允许我们清理 Thread API。 我们想不出比Thread更好的东西来证明一个全新的API的合理性。 尽管仍然存在一些不便之处，比如不恰当的返回类型和中断机制，但是我们在实验中学到的——我们可以保留Thread API的一部分，而忽略另一部分——为了保留现有的API，我们移动了指针，并用现有Thread类来表示我们的用户模式线程。现在我们来看看: 虚拟线程就是线程，任何知道线程的库都已经知道虚拟线程。调试器和分析器使用它们的方式与当前的线程一样。与async/await不同，它们没有引入“语义鸿沟” : 程序员在屏幕上看到的代码行为在运行时被保留，并且对所有工具来说都是一样的。 如何使用虚拟线程编程（你已经知道）创建和启动一个虚拟线程可以这样做: Thread t = Thread.startVirtualThread(() -&gt; &#123; ... &#125;); 为了获得更大的灵活性，有一个新的 Thread. Builder，它可以做上面提到的同样的事情: Thread t = Thread.builder().virtual().task(() -&gt; &#123; ... &#125;).start(); 或创建一个未启动的虚拟线程: Thread t = Thread.builder().virtual().task(() -&gt; ...).build(); 没有公共或受保护的Thread构造函数来创建虚拟线程，这意味着Thread的子类不能是虚拟的。因为子类化平台类限制了我们发展它们的能力，这是我们想要阻止的。 构造器还可以创建一个 ThreadFactory, ThreadFactory tf = Thread.builder().virtual().factory(); 可以传递给java.util.concurrent。执行器来创建使用虚拟线程并照常使用的ExecutorServices。但是，由于我们不需要也不想集中虚拟线程，所以我们向执行器添加了一个新方法newUnboundedExecutor。它构造了一个ExecutorService，为每个提交的任务创建并启动一个新线程，而不需要进行池操作ーー当任务终止时，它的线程终止: ThreadFactory tf = Thread.builder().virtual().factory(); ExecutorService e = Executors.newUnboundedExecutor(tf); Future&lt;Result&gt; f = e.submit(() -&gt; &#123; ... return result; &#125;); // spawns a new virtual thread ... Result y = f.get(); // joins the virtual thread thread API 的包袱并不困扰我们，因为我们不直接使用它。 除了构造Thread对象之外，一切和之前一样，只是所有虚拟线程的残留ThreadGroup是固定的，不能枚举它的成员。ThreadLocals对虚拟线程的处理方式与对平台线程的处理方式一样，但是由于它们可能仅仅因为存在大量的虚拟线程而大大增加内存占用，Thread.Builder允许线程的创建者禁止在该线程中使用它们。我们正在探索ThreadLocal 的一个替代方案，在 Scope Variables 部分中有所描述。 引入虚拟线程并不移除操作系统支持的现有线程实现。虚拟线程只是线程的一种新的实现，它的占用空间和调度是不同的。两种类型都可以锁定相同的锁，通过相同的阻塞队列交换数据等等。可以使用一个新的方法Thread.isVirtual来区分两种实现，但只有低级别的同步或I/O代码可能会关心这种区分。 然而，与我们习惯使用的线程相比，线程的存在是如此轻量级，这确实需要一些心理调整。首先，我们不再需要避免阻塞，因为阻塞一个(虚拟)线程并不昂贵。我们可以使用所有熟悉的同步api，而不用为吞吐量付出高昂的代价。其次，创建这些线程是廉价的。在合理的范围内，每个任务都可以有完全属于自己的线程;永远不需要将它们组合在一起。如果我们不将它们集中起来，我们如何限制对某些服务的并发访问？我们没有将任务分解并在一个单独的、受限的池子中运行服务调用子任务，而是让整个任务在自己的线程中从头到尾运行，并在服务调用代码中使用信号量来限制并发性ーー应该这样做。 很好地使用虚拟线程并不需要学习新的概念，而是要求我们抛弃多年来形成的旧习惯，之前我们自动的将高成本与线程联系起来，仅仅因为我们只有一个实现。 在本文的其余部分，我们将讨论虚拟线程如何超越传统线程的行为，指出一些新的API点和有趣的用例，并观察一些实现挑战。但是，成功使用虚拟线程所需的所有内容都已经解释过了。 调度与必须非常通用的内核调度器不同，虚拟线程调度器可以为手头的任务定制化。虚拟线程也可以使用类似异步编程的灵活调度，不过由于线程和调度的细节被很好的隐藏起来了，你不需要了解它的工作原理，就像你不需要研究内核调度程序一样，除非你打算自己使用或编写一个定制的调度程序。这一部分完全是可选的。 在内核之外，我们不能直接访问CPU内核，所以我们使用内核线程作为接近它的一种方式:我们的调度器将虚拟线程调度到“物理”平台工作线程上。我们称调度器的工作线程为载体线程，因为它们上面承载着虚拟线程。像异步框架一样，我们最终会调度内核线程，只是我们将结果抽象为一个线程，而不是让调度的细节泄露到应用程序代码中。 当一个虚拟线程变得可运行时，调度程序将(最终)把它挂载到一个工作平台线程上，这个线程将在一段时间内成为虚拟线程的载体，并将一直运行它，直到它被取消调度——通常是在它阻塞时。然后，调度程序将从其载体中卸载该虚拟线程，并选择另一个线程进行挂载(如果有可运行的线程的话)。在虚拟线程上运行的代码无法观察其载体;Thread.currentThread 将始终返回当前(虚拟)线程。 默认情况下，虚拟线程由一个全局调度程序进行调度，其工作线程的数量与CPU内核的数量相同(或者显式地使用-djdk.defaultscheduler = n 进行设置)。大量的虚拟线程被安排在少量的平台线程上。这被称为 m: n 调度(m 用户模式线程被调度到n个内核线程上，其中 m &gt;&gt; n)。JDK 的早期版本也是在用户空间使用绿色线程实现的Thread; 然而，它们使用 m: 1调度，只使用一个内核线程。 工作窃取调度程序可以很好地工作于事务处理和消息传递中涉及的线程，这些线程通常以短时间爆发并经常阻塞为特点，就像我们在Java服务器应用程序中可能发现的那样。所以最初，默认的全局调度程序是具有工作窃取功能的ForkJoinPool。 虚拟线程是抢占式#PREEMPTIVE)的，而不是协作式的ー它们在调度(任务切换)点上没有明确的等待操作。相反，当它们阻塞I/O或线程同步时，它们会被抢占。如果平台线程占用CPU的时间超过了某个分配的时间片，那么它们会被内核抢占。当活动线程的数量不超过内核数量，并且只有极少数线程处理量很大时，分时作为一种调度策略很有效。如果一个线程占用CPU太长时间，它会被抢占以使其他线程做出响应，然后它会被再次调度到另一个时间片。当我们有数百万个线程时，这种策略就不那么有效了：如果其中许多线程对CPU的需求如此之大，以至于它们需要时间共享，那么我们的资源就有几个数量级的短缺，没有任何调度策略可以拯救我们。在所有其他情况下，要么工作窃取调度器会自动消除零星的CPU占用，要么我们可以将有问题的线程作为平台线程运行，并依赖内核调度器。出于这个原因，JDK的调度器目前都没有采用基于时间片的虚拟线程抢占，但这并不是说将来不会采用——参见强制抢占。 与今天的线程相比，您不能对调度点的位置做任何假设。即使没有强制抢占，您调用的任何JDK或库方法都可能引入阻塞，从而引入任务切换点。 虚拟线程可以使用任意的、可插拔的调度程序。一个自定义的调度程序可以在每个线程的基础上设置，例如: Thread t = Thread.builder().virtual(scheduler).build(); 或者每个工厂，就像这样: ThreadFactory tf = Thread.builder().virtual(scheduler).factory(); 线程从出生到消亡都被分配给调度程序。 自定义调度程序可以使用各种调度算法，甚至可以选择将其虚拟线程调度到特定的单个载体线程或一组载体线程上(尽管如果调度程序只使用一个工作线程，则更容易被锁定)。 定制调度器不需要知道它是用来调度虚拟线程的。它可以是实现java.util.concurrent.Executor的任何类型，只需要实现一个方法:execute。这个方法将在线程可运行时被调用，也就是说，在线程启动(started)或未停泊(unparked)时请求调度。但是传递给execute的可运行实例是什么呢？它是Thread.VirtualThreadTask。VirtualThreadTask允许调度程序查询虚拟线程的身份，并将虚拟线程执行的内部保留状态包装起来。当调度器将这个Runnable分配给某个工作线程，然后该工作线程调用run方法时，该方法将装载虚拟线程并成为它的载体，虚拟线程的挂起(suspended)将被神奇地恢复，它会在载体上继续恢复执行。对于调度程序来说，run方法的行为看起来和其他方法一样——它看起来在同一个线程中执行(事实上，它确实在同一个内核线程中运行)，表面上是在任务终止时返回，但“内部”运行的代码会观察到它在虚拟线程中运行，当虚拟线程阻塞时，run会返回调度程序，使VirtualThreadTask处于挂起状态。你可以把VirtualThreadTask当成一种可恢复的可运行的线程包装。这就是神奇的地方。这一过程将在关于这一新的虚拟机功能的单独文档中详细解释。 调度程序绝不能在多个载体线程上并发执行 VirtualThreadTask。实际上，在调用同一个VirtualThreadTask之前，必须先从run返回。 不管是哪种调度器，虚拟线程都具有与平台线程相同的内存一致性(由Java内存模型指定) ，但是定制调度器可以选择提供更强的保证。例如，使用单个工作平台线程的调度程序将使所有内存操作完全有序，不需要使用锁，并且允许使用HashMap代替 ConcurrentHashMap。然而，根据 JMM ，无竞争的线程在任何调度程序上都是无竞争的，但是依赖特定调度程序的保证可能导致该调度程序中的线程是无竞争的，而在其他调度程序中则不是。 性能和占用空间虚拟线程的任务切换开销以及它们的内存占用都将随着时间的推移、在第一次发布之前和之后而改善。 性能由VM挂载和卸载虚拟线程的算法以及调度程序的行为决定。对于那些希望尝试性能的用户，可以使用VM选项 -XX:[-/+ ] UseContinuationChunks 在两个基础算法之间进行选择。此外，缺省调度程序(ForkJoinPool)在线程未充分利用的情况不是最优的(提交的任务比工作线程少，即可运行的虚拟线程少) ，因此您可能需要测试缺省工作者线程池的大小(-djdk.defaultscheduler = n)。 内存占用主要取决于虚拟线程状态的内部VM表示(尽管比平台线程好得多，但仍不是最优的)以及线程局部变量的使用。 关于虚拟线程运行时特性的讨论最好在loom的开发邮件列表中进行。 线程锁定（Pinning）我们说，如果一个虚拟线程被挂载，但是处于无法卸载的状态，那么它就会被锁定到到其载体线程上。如果一个虚拟线程在锁定时阻塞，它就会阻塞它的载体线程。此行为仍然正确，但是在虚拟线程被阻塞期间，它将占用一个工作线程，使其他虚拟线程无法使用。 如果调度程序有多个工作线程，并且可以很好地利用其他工作线程，其中一些工作线程被虚拟线程锁定，偶尔的锁定是无害的。然而，过于频繁的锁定会影响吞吐量。 在当前的Loom实现中，可以在两种情况下固定一个虚拟线程: 当堆栈上有一个本地框架（native frame）时ーー当Java代码调用本地方法接口(JNI) ，然后再调用回 Java ーー以及当在一个同步块或方法中时。在这些情况下，阻塞虚拟线程将阻塞携带虚拟线程的物理线程。一旦本地方法调用完成或监视器释放(同步块/方法退出) ，线程将被取消锁定。 如果有一个普通的I/O操作由一个synchronized保护，那么将监视器替换为 ReentrantLock，即使在我们修复因监视器导致的线程锁定之前也可以让您的应用程序充分受益于Loom的可扩展性提升，(或者，如果可以的话，使用性能更高的 StampedLock)。 JDK 中两个常用的方法引入了一个锁定虚拟线程的本地框架: AccessController.doPrivileged 和 Method.invoke (+ 其构造函数的副本Constructor.newInstance)。用纯Java语言重写了doPrivileged。Method.invoke在某些迭代中使用本地调用，在预热后生成Java字节码;在Loom原型中，我们使用MethodHandles在Java中重新实现了它。静态类初始化器也被本机方法代码调用，但是它们运行得很少，所以我们不用担心它们。 此外，在进入synchronized或调用Object.wait时阻塞本地方法代码或试图获取不可用的监视器也会阻塞本地载体线程。 synchronized 的局限性最终会消失，但本地框架锁定仍然存在。我们认为它不会产生任何重大的负面影响，因为这种情况在Java中很少出现，但是Loom将添加一些诊断来检测锁定线程。 所有阻塞由我们来负责将线程表示为“纯” Java 对象是第一步。第二是让所有的代码和库都使用新的机制; 否则它们将阻塞OS线程而不是虚拟线程。幸运的是，我们不需要改变所有的库和应用程序。无论何时在Spring或Hibernate中运行阻塞操作，它最终都会使用JDK中的核心库 API ーjava.* 包裹。JDK 控制了应用程序与操作系统或外部世界之间的所有交互点，因此我们所需要做的就是使它们适配虚拟线程。构建在JDK之上的所有内容现在都可以使用虚拟线程。具体地说，我们需要调整JDK中阻塞发生的所有点; 这些点有两种类型: 同步(想象一下锁或阻塞队列)和 I/O。特别是，当在虚拟线程上调用同步I/O操作时，我们希望阻塞虚拟线程，在底层执行异步文件文件操作，并设置它，当操作完成时，它将解除对虚拟线程的阻塞。 同步 synchronized/Object.wait的局限见线程锁定。 所有其他形式的同步，通常在java.util.concurrent以及调用它的程序库中，使用LockSupport.park/unpark方法阻止和取消阻止线程。我们已经做了适配，所以java.util.concurrent是虚拟线程友好的。 仍然需要进一步调优java.util.concurrent中的策略，以获得最佳的虚拟线程性能。 I/O java.nio.channels 类—— SocketChannel、 ServerSocketChannel和 DatagramChannel ——被改造为虚拟线程友好型。当它们的同步操作，比如read和write，在一个虚拟线程上执行时，在底层只会使用异步I/O。 “老式” I/O 网络接口ー java.net.Socket、 ServerSocket 和DatagramSocket已经在NIO之上的Java中重新实现，因此它立即可以从NIO 的虚拟线程友好特性中受益。 用户DNS查找的java.net.InetAddress的方法：getHostName, getCanonicalHostName, getByName仍然会委托给操作系统。因为它只提供一个操作系统线程阻塞的API。替代方案正在探索中。 进程管道也将类似地实现虚拟线程友好，除了在Windows上，这需要更大的努力。 控制台I/O也已经改装。 对Http(s)URLConnection以及TLS/SSL的实现进行了更改，以使其依赖于j.u.c锁而避免锁定。 文件I/O有问题。在内部，JDK 对文件使用缓冲 I/O，即使读取将被阻塞，它也总是报告可用。在Linux上，我们计划对异步文件I/O使用 io _ uring，同时我们正在使用 ForkJoinPool.ManagedBlocker机制，通过在工作线程被阻塞时向工作线程池添加更多的操作系统线程来缓和阻塞文件I/O操作。 因此，使用JDK的网络原语的库(无论是在JDK核心库中还是在其外部)也会自动变成非(OS-thread -)阻塞; 这包括JDBC驱动程序，以及HTTP客户机和服务器。 调试和分析可服务性和可观察性一直是Java平台的高优先级关注点，也是其显著特性之一。对我们来说，在第一天就拥有良好的虚拟线程调试和分析经验是很重要的，尤其是在这些方面，虚拟线程可以比异步编程提供更多的好处，而异步编程的调试和分析体验尤其糟糕，这正是它自己的显著特征。 为Java调试器使用的Java调试器连线协议(JDWP)和Java调试器接口(JDI)提供动力的调试器代理程序，支持断点、单步执行、变量检查等普通调试操作。单步执行阻塞操作的行为与预期的一样，而且单步执行不会像调试异步代码那样从一个任务跳到另一个任务，或跳到调度程序代码。在JVM TI 级别支持虚拟线程的更改为此提供了便利。我们还与IntelliJ IDEA 和NetBeans调试器团队进行合作测试在这些ide中调试虚拟线程。 在当前的EA中，并非所有的调试器操作都支持虚拟线程。一些操作带来了特殊的挑战。例如，调试器通常列出所有活动线程。如果您有一百万个线程，那么这既缓慢又无用。实际上，我们没有提供任何机制来枚举所有虚拟线程。正在探讨一些想法，比如仅列出在调试会话期间遇到某些调试器事件(如命中断点)的虚拟线程。 异步代码最大的问题之一是几乎不可能很好地分析。对于分析器来说，没有一种好的通用方法可以根据上下文对异步操作进行分组，即整理同步管道中处理传入请求的所有子任务。因此，当您尝试分析异步代码时，您经常会看到空闲线程池，即使应用程序处于负载状态，因为没有办法跟踪等待异步I/O的操作。 虚拟线程解决了这个问题，因为同步操作与它们阻塞的线程相关联(即使在底层使用异步I/O)。我们已经修改了JDK Flight Recorder (JFR)—— JDK 中分析和结构化日志的基础——以支持虚拟线程。阻塞的虚拟线程可以显示在分析器中，并且可以度量和计算在I/O上花费的时间。 另一方面，虚线程给可观测性带来了一些挑战。例如，如何理解一个100万线程的线程转储（thread dump）？我们相信结构化的并发可以帮助解决这个问题。 为什么是“虚拟” ？在该项目的前几次迭代中，我们将我们的轻量级用户模式线程称为“纤程” ，但发现自己反复解释说，它们不是一个新概念，而是一个熟悉的线程的不同实现。此外，这个术语已经被用于那些相似但又足够不同以至于引起混淆的结构。“绿线程”也同样受到其他实现的污染。我们考虑了非特定的“轻量级线程” ，但“轻量级”是相对的，我们设想未来的jdk拥有“微线程” ，因此我们决定采用 Brian Goetz 的建议，称它们为“虚拟线程” ，这在会议上也得到了很好的测试。这个名字是为了唤起与虚拟内存的联系: 通过将虚拟结构映射到具体结构(物理内存、 OS 线程)上，我们得到了更多的东西(地址空间、线程)。 第二部分：进一步的工作","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"}]},{"title":"简明Java反射教程1：类（Classes）","slug":"简明Java反射教程1：类（Classes","date":"2020-03-07T03:44:19.000Z","updated":"2020-09-12T03:14:00.591Z","comments":true,"path":"2020/03/07/简明Java反射教程1：类（Classes/","link":"","permalink":"https://pingao777.github.io/2020/03/07/%E7%AE%80%E6%98%8EJava%E5%8F%8D%E5%B0%84%E6%95%99%E7%A8%8B1%EF%BC%9A%E7%B1%BB%EF%BC%88Classes/","excerpt":"","text":"Java反射历来是迈入高级Java开发者的必备科目，网上教程是五花八门，有的失于不够全面，有的失于谬误百出。看过之后不懂的更不懂了，懂得也有点蒙了，偶然看到Oracle的官方教程页面，仿佛打开了新的世界，里面的教程不仅简明易懂而且非常权威，毕竟是官方出品，里面有篇反射教程，非常不错，翻译一下，推荐给大家。由于篇幅相对于一篇博客来说还是有点长了，我将其分为三个部分：类､成员以及数组和枚举类型。本篇是第一篇，类的反射。 反射用途反射通常用来修改Java虚拟机应用程序的运行时行为。这是一个相对高级的功能，只应由对语言基础有很深了解的开发人员使用。考虑到这一点，反射是一种强大的技术，可以使应用程序执行原本不可能的操作。 扩展功能应用程序可以通过使用其完全限定名创建外部用户定义类的实例。 类浏览器和可视化开发环境类浏览器需要枚举类的成员。可视化开发环境可以利用反射中可用的类型信息来帮助开发人员编写正确的代码。 调试和测试工具调试工具需要检查类的私有成员。测试工具可以利用反射来系统地调用在类上定义的可发现的API集合，以确保代码的高覆盖率。 反射弊端反射功能强大，但不应任意使用。如果可以在不使用反射的情况下实现需要的操作，那么最好避免使用它。通过反射访问代码时应牢记以下问题。 性能开销由于反射涉及动态解析的类型，因此无法执行某些Java虚拟机优化。因此，反射操作的性能要比非反射操作慢，因此，在性能敏感的应用程序中经常调用的代码段中，应避免使用反射。 安全限制反射需要运行时许可，而在安全管理器下运行时可能不存在这种许可。对于必须在受限的安全上下文（例如Applet）中运行的代码，这是一个重要的考虑因素。 内部暴露由于反射允许执行在非反射代码中非法的操作，例如访问私有字段和方法，因此使用反射可能会导致意外的副作用，这可能会使代码无法正常工作并可能破坏可移植性。反射代码破坏了抽象，因此可能会随着平台的升级而改变行为。 教程章节本教程涵盖了反射在访问和操作类、字段、方法和构造函数方面的常见用法。每节课均包含代码示例，技巧和故障排除信息。 主要章节为： 类 成员 数组和枚举类型 类本课说明了获取Class对象并使用它检查类的属性的各种方法，包括其声明和内容。 类型要么是引用类型，要么是原始类型。类，枚举和数组（都继承自java.lang.Object）以及接口都是引用类型。引用类型包括java.lang.String，原始类型的所有包装器类，例如java.lang.Double，接口 java.io.Serializable和枚举javax.swing.SortOrder。原始类型有：布尔值(boolean)，字节(byte)，短型(short)，整数(int)，长型(long)，字符(char)，浮点型(float)和双精度型(double)。 对于每种类型的对象，Java虚拟机都会实例化一个不可变的java.lang.Class实例，该实例提供检查对象的运行时属性（包括其成员和类型信息）的方法。Class还提供了创建类和对象的能力。最重要的是，它是所有反射API的入口点。本课涵盖了涉及类的最常见的反射操作： 获取类对象描述了获取类的方式。 检查类修饰符和类型显示如何访问类声明信息。 发现类成员说明了如何在类中列出构造函数，字段，方法和嵌套类。 故障排除描述了使用类时遇到的常见错误。 获取类对象所有反射操作的入口点是java.lang.Class。除了java.lang.reflect.ReflectPermission之外，java.lang.reflect包下的所有类都没有公共构造函数。要获得这些类，必须在Class上调用相应的方法。根据代码是否可以访问对象，类的名称，类型或现有的类，有几种获取类的方法。 Object.getClass()如果对象的实例可用，则获取其类的最简单方法是调用Object.getClass()。当然，这仅适用于全部继承自Object的引用类型。以下是一些示例。 Class c = &quot;foo&quot;.getClass(); 返回字符串(String)的类(Class) Class c = System.console().getClass(); 与虚拟机关联的唯一控制台由静态方法System.console()返回。getClass()返回的值是与getClass()对应的Class。 enum E &#123; A, B &#125; Class c = A.getClass(); A是枚举E的实例；因此，getClass()返回与枚举类型E相对应的Class。 byte[] bytes = new byte[1024]; Class c = bytes.getClass(); 由于数组是对象(Object)，因此也可以在数组的实例上调用getClass()。返回的Class对应于组件类型为byte的数组。 import java.util.HashSet; import java.util.Set; Set&lt;String&gt; s = new HashSet&lt;String&gt;(); Class c = s.getClass(); 在这种情况下，java.util.Set是类型为java.util.HashSet的对象的接口。getClass()返回的值是对应于java.util.HashSet的类。 .class如果类的实例不可用，那么可以使用.class的方式获取Class。这也是基本类型获取Class最简单的方式。 boolean b; Class c = b.getClass(); // compile-time error Class c = boolean.class; // correct 请注意，语句boolean.getClass()会产生编译时错误，因为布尔值是基本类型且无法取消引用。.class语法返回与布尔类型相对应的Class。 Class c = java.io.PrintStream.class; 变量c是与类型java.io.PrintStream对应的Class。 Class c = int[][][].class; .class语法可用于获取多维数组相对应的Class。 Class.forName()如果一个类的完全限定名可用，可以使用静态方法Class.forName()获取相应的Class。数组的完全限定名不能用于基本类型。数组的限定名可以使用Class.getName()获取。Class.getName()适用于引用和基本类型。 Class c = Class.forName(&quot;com.duke.MyLocaleServiceProvider&quot;); 该语句将从给定的完全限定名称创建一个类。 Class cDoubleArray = Class.forName(&quot;[D&quot;); Class cStringArray = Class.forName(&quot;[[Ljava.lang.String;&quot;); 变量cDoubleArray对应于基本类型为double的数组的Class（即与double[].class相同）。变量cStringArray对应String二维数组的Class（和String[][].class一样）。 基本类型包装类的类型对于基本类型，.class是最容易的一种方式，不过还有一种方式可以获取Class。每个基本类型和void在java.lang中都有一个包装器类，用于将原始类型装箱到引用类型。每个包装器类都包含一个名为TYPE的字段，该字段对应于包装的基本类型的Class。 Class c = Double.TYPE; 有一个类java.lang.Double，用于在需要Object时包装基本类型double。 Double.TYPE的值与double.class的值相同。 Class c = Void.TYPE; Void.TYPE与void.class相同。 返回Class的方法Class.getSuperclass() 返回给定类的超类。 Class c = javax.swing.JButton.class.getSuperclass(); javax.swing.JButton的超类是javax.swing.AbstractButton。 Class.getClasses() 返回属于该类成员的所有公共类，接口和枚举，包括继承的成员。 Class&lt;?&gt;[] c = Character.class.getClasses(); Character 包含两个成员类 Character.Subset 和Character.UnicodeBlock。 Class.getDeclaredClasses() 返回所有类接口，以及在该类中显式声明的枚举。 Class&lt;?&gt;[] c = Character.class.getDeclaredClasses(); Character包含两个公共成员类： Character.Subset和Character.UnicodeBlock，一个私有类：Character.CharacterCache。 Class.getDeclaringClass()java.lang.reflect.Field.getDeclaringClass()java.lang.reflect.Method.getDeclaringClass()java.lang.reflect.Constructor.getDeclaringClass() 返回这些成员的声明类。 匿名类没有声明类但但有封闭类。 import java.lang.reflect.Field; Field f = System.class.getField(&quot;out&quot;); Class c = f.getDeclaringClass(); // System 字段 out是在System中声明的。 public class MyClass &#123; static Object o = new Object() &#123; public void m() &#123;&#125; &#125;; static Class&lt;c&gt; = o.getClass().getEnclosingClass(); &#125; o代表的匿名类的声明类为null。 Class.getEnclosingClass() 返回该类的直接封闭类。 Class c = Thread.State.class().getEnclosingClass(); 枚举Thread.State的封闭类是Thread。 public class MyClass &#123; static Object o = new Object() &#123; public void m() &#123;&#125; &#125;; static Class&lt;c&gt; = o.getClass().getEnclosingClass(); &#125; o定义的匿名类包含在MyClass中。 检查类的修饰符和类型一个类在声明时可能会有一个或多个修饰符影响它的运行时行为： 访问修饰符：public,protected,private 需要覆盖的修饰符：abstract 仅限一个实例的修饰符：static 禁止修改值的修饰符：final 执行严格浮点行为的修饰符：strictfp 注解 并非所有类都允许使用所有修饰符，例如，接口不能为final，而枚举不能为abstract。java.lang.reflect.Modifier包含所有可能的修饰符的声明。它还包含用于解码Class.getModifiers()返回的修饰符集的方法。 ClassDeclarationSpy示例演示如何获取类的声明组件，包括修饰符，泛型类型参数，已实现的接口和继承路径。由于Class 实现了java.lang.reflect.AnnotatedElement接口，因此也可以查询运行时注解。 import java.lang.annotation.Annotation; import java.lang.reflect.Modifier; import java.lang.reflect.Type; import java.lang.reflect.TypeVariable; import java.util.Arrays; import java.util.ArrayList; import java.util.List; import static java.lang.System.out; public class ClassDeclarationSpy &#123; public static void main(String... args) &#123; try &#123; Class&lt;?&gt; c = Class.forName(args[0]); out.format(&quot;Class:%n %s%n%n&quot;, c.getCanonicalName()); out.format(&quot;Modifiers:%n %s%n%n&quot;, Modifier.toString(c.getModifiers())); out.format(&quot;Type Parameters:%n&quot;); TypeVariable[] tv = c.getTypeParameters(); if (tv.length != 0) &#123; out.format(&quot; &quot;); for (TypeVariable t : tv) out.format(&quot;%s &quot;, t.getName()); out.format(&quot;%n%n&quot;); &#125; else &#123; out.format(&quot; -- No Type Parameters --%n%n&quot;); &#125; out.format(&quot;Implemented Interfaces:%n&quot;); Type[] intfs = c.getGenericInterfaces(); if (intfs.length != 0) &#123; for (Type intf : intfs) out.format(&quot; %s%n&quot;, intf.toString()); out.format(&quot;%n&quot;); &#125; else &#123; out.format(&quot; -- No Implemented Interfaces --%n%n&quot;); &#125; out.format(&quot;Inheritance Path:%n&quot;); List&lt;Class&gt; l = new ArrayList&lt;Class&gt;(); printAncestor(c, l); if (l.size() != 0) &#123; for (Class&lt;?&gt; cl : l) out.format(&quot; %s%n&quot;, cl.getCanonicalName()); out.format(&quot;%n&quot;); &#125; else &#123; out.format(&quot; -- No Super Classes --%n%n&quot;); &#125; out.format(&quot;Annotations:%n&quot;); Annotation[] ann = c.getAnnotations(); if (ann.length != 0) &#123; for (Annotation a : ann) out.format(&quot; %s%n&quot;, a.toString()); out.format(&quot;%n&quot;); &#125; else &#123; out.format(&quot; -- No Annotations --%n%n&quot;); &#125; // production code should handle this exception more gracefully &#125; catch (ClassNotFoundException x) &#123; x.printStackTrace(); &#125; &#125; private static void printAncestor(Class&lt;?&gt; c, List&lt;Class&gt; l) &#123; Class&lt;?&gt; ancestor = c.getSuperclass(); if (ancestor != null) &#123; l.add(ancestor); printAncestor(ancestor, l); &#125; &#125; &#125; 下面是输出的一些样本。用户输入以斜体显示。 $ java ClassDeclarationSpy java.util.concurrent.ConcurrentNavigableMap Class: java.util.concurrent.ConcurrentNavigableMap Modifiers: public abstract interface Type Parameters: K V Implemented Interfaces: java.util.concurrent.ConcurrentMap&lt;K, V&gt; java.util.NavigableMap&lt;K, V&gt; Inheritance Path: -- No Super Classes -- Annotations: -- No Annotations -- 这是实际的源代码 java.util.concurrent.ConcurrentNavigableMap中的实际声明： public interface ConcurrentNavigableMap&lt;K,V&gt; extends ConcurrentMap&lt;K,V&gt;, NavigableMap&lt;K,V&gt; 注意，由于这是一个接口，因此它是隐式abstract的。编译器为每个接口添加此修饰符。另外，此声明包含两个泛型参数K和V。示例代码仅打印这些参数的名称，但是可以使用java.lang.reflect.TypeVariable中的方法获取有关它们的其他信息。接口也可以实现其他接口，如上所示。 $ java ClassDeclarationSpy &quot;[Ljava.lang.String;&quot; Class: java.lang.String[] Modifiers: public abstract final Type Parameters: -- No Type Parameters -- Implemented Interfaces: interface java.lang.Cloneable interface java.io.Serializable Inheritance Path: java.lang.Object Annotations: -- No Annotations -- 由于数组是运行时对象，因此所有类型信息均由Java虚拟机定义。特别是，数组实现 Cloneable和 java.io.Serializable ，其直接超类始终是Object。 $ java ClassDeclarationSpy java.io.InterruptedIOException Class: java.io.InterruptedIOException Modifiers: public Type Parameters: -- No Type Parameters -- Implemented Interfaces: -- No Implemented Interfaces -- Inheritance Path: java.io.IOException java.lang.Exception java.lang.Throwable java.lang.Object Annotations: -- No Annotations -- 从继承路径可以推断出java.io.InterruptedIOException是一个检查的异常，因为RuntimeException 没有出现。 $ java ClassDeclarationSpy java.security.Identity Class: java.security.Identity Modifiers: public abstract Type Parameters: -- No Type Parameters -- Implemented Interfaces: interface java.security.Principal interface java.io.Serializable Inheritance Path: java.lang.Object Annotations: @java.lang.Deprecated() 输出表明java.security.Identity拥有注释java.lang.Deprecated是一个不推荐使用的API。反射代码可以使用它来检测已弃用的API。 注意：并非所有注释都可以通过反射获得。只有具有RUNTIME的java.lang.annotation.RetentionPolicy的那些注解才可访问。在 @Deprecated，@Override和@SuppressWarnings语言中预定义的三个注释中，只有@Deprecated在运行时可用。 发现类成员类提供了用于访问字段，方法和构造函数的两类方法：枚举这些成员的方法和搜索特定成员的方法。与在超接口和超类中搜索继承的成员的方法相比，直接在类上访问成员方法不太一样。下表总结了所有成员定位方法及其特点。 定位字段的类方法 Class API 是否成员列表？ 是否包含继承成员？ 是否包含私有成员？ getDeclaredField() 否 否 是 getField() 否 是 否 getDeclaredFields() 是 否 是 getFields() 是 是 否 定位方法的类方法 Class API 是否成员列表？ 是否包含继承成员？ 是否包含私有成员？ getDeclaredMethod() 否 否 是 getMethod() 否 是 否 getDeclaredMethods() 是 否 是 getMethods() 是 是 否 定位构造方法的类方法 Class API 是否成员列表？ 是否包含继承成员？ 是否包含私有成员？ getDeclaredConstructor() 否 N/A 是 getConstructor() 否 N/A 否 getDeclaredConstructors() 是 N/A 是 getConstructors() 是 N/A 否 N/A：构造函数不能继承。 给定一个类名并指出感兴趣的成员，ClassSpy示例使用get*s()方法确定所有公共成员的列表，包括任何继承的成员。 import java.lang.reflect.Constructor; import java.lang.reflect.Field; import java.lang.reflect.Method; import java.lang.reflect.Member; import static java.lang.System.out; enum ClassMember &#123; CONSTRUCTOR, FIELD, METHOD, CLASS, ALL &#125; public class ClassSpy &#123; public static void main(String... args) &#123; try &#123; Class&lt;?&gt; c = Class.forName(args[0]); out.format(&quot;Class:%n %s%n%n&quot;, c.getCanonicalName()); Package p = c.getPackage(); out.format(&quot;Package:%n %s%n%n&quot;, (p != null ? p.getName() : &quot;-- No Package --&quot;)); for (int i = 1; i &lt; args.length; i++) &#123; switch (ClassMember.valueOf(args[i])) &#123; case CONSTRUCTOR: printMembers(c.getConstructors(), &quot;Constructor&quot;); break; case FIELD: printMembers(c.getFields(), &quot;Fields&quot;); break; case METHOD: printMembers(c.getMethods(), &quot;Methods&quot;); break; case CLASS: printClasses(c); break; case ALL: printMembers(c.getConstructors(), &quot;Constuctors&quot;); printMembers(c.getFields(), &quot;Fields&quot;); printMembers(c.getMethods(), &quot;Methods&quot;); printClasses(c); break; default: assert false; &#125; &#125; // production code should handle these exceptions more gracefully &#125; catch (ClassNotFoundException x) &#123; x.printStackTrace(); &#125; &#125; private static void printMembers(Member[] mbrs, String s) &#123; out.format(&quot;%s:%n&quot;, s); for (Member mbr : mbrs) &#123; if (mbr instanceof Field) out.format(&quot; %s%n&quot;, ((Field)mbr).toGenericString()); else if (mbr instanceof Constructor) out.format(&quot; %s%n&quot;, ((Constructor)mbr).toGenericString()); else if (mbr instanceof Method) out.format(&quot; %s%n&quot;, ((Method)mbr).toGenericString()); &#125; if (mbrs.length == 0) out.format(&quot; -- No %s --%n&quot;, s); out.format(&quot;%n&quot;); &#125; private static void printClasses(Class&lt;?&gt; c) &#123; out.format(&quot;Classes:%n&quot;); Class&lt;?&gt;[] clss = c.getClasses(); for (Class&lt;?&gt; cls : clss) out.format(&quot; %s%n&quot;, cls.getCanonicalName()); if (clss.length == 0) out.format(&quot; -- No member interfaces, classes, or enums --%n&quot;); out.format(&quot;%n&quot;); &#125; &#125; 这个例子比较紧凑。但是printMembers()方法有点尴尬，因为反射最早的实现中就存在java.lang.reflect.Member接口了，所以后来引入泛型时无法对其进行修改以包含更有用的getGenericString()方法。唯一的选择就是如上面那样进行测试和转换，使用独立的方法如printConstructors()、printFields()、printMethods()进行打印。 输出样本及其解释如下。用户输入以斜体显示。 $ java ClassSpy java.lang.ClassCastException CONSTRUCTOR Class: java.lang.ClassCastException Package: java.lang Constructor: public java.lang.ClassCastException() public java.lang.ClassCastException(java.lang.String) 由于构造函数不能继承，因此找不到在直接超类RuntimeException和其他超类中定义的异常链接机制构造函数（具有 Throwable参数的那些）。 $ java ClassSpy java.nio.channels.ReadableByteChannel METHOD Class: java.nio.channels.ReadableByteChannel Package: java.nio.channels Methods: public abstract int java.nio.channels.ReadableByteChannel.read (java.nio.ByteBuffer) throws java.io.IOException public abstract void java.nio.channels.Channel.close() throws java.io.IOException public abstract boolean java.nio.channels.Channel.isOpen() java.nio.channels.ReadableByteChannel定义了read()方法。其余方法是从超接口继承的。通过将get * s()替换为getDeclared * s()，这个代码稍作修改，就可以只列出那些在类中实际声明的方法。 $ java ClassSpy ClassMember FIELD METHOD Class: ClassMember Package: -- No Package -- Fields: public static final ClassMember ClassMember.CONSTRUCTOR public static final ClassMember ClassMember.FIELD public static final ClassMember ClassMember.METHOD public static final ClassMember ClassMember.CLASS public static final ClassMember ClassMember.ALL Methods: public static ClassMember ClassMember.valueOf(java.lang.String) public static ClassMember[] ClassMember.values() public final int java.lang.Enum.hashCode() public final int java.lang.Enum.compareTo(E) public int java.lang.Enum.compareTo(java.lang.Object) public final java.lang.String java.lang.Enum.name() public final boolean java.lang.Enum.equals(java.lang.Object) public java.lang.String java.lang.Enum.toString() public static &lt;T&gt; T java.lang.Enum.valueOf (java.lang.Class&lt;T&gt;,java.lang.String) public final java.lang.Class&lt;E&gt; java.lang.Enum.getDeclaringClass() public final int java.lang.Enum.ordinal() public final native java.lang.Class&lt;?&gt; java.lang.Object.getClass() public final native void java.lang.Object.wait(long) throws java.lang.InterruptedException public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedException public final void java.lang.Object.wait() hrows java.lang.InterruptedException public final native void java.lang.Object.notify() public final native void java.lang.Object.notifyAll() 在上面结果的field部分中，枚举的常量值都列了出来。While these are technically fields, it might be useful to distinguish them from other fields.可以使用java.lang.reflect.Field.isEnumConstant()达到这个木得。本教程的后续部分Examining Enums中示例EnumSpy给出了一个可能的实现。 在结果的method部分，包含声明类的方法名。因此方法toString()是在Enum中实现的，而不是继承自Object。通过使用Field.getDeclaringClass()，可以对代码进行修改以使其更加明显。以下片段说明了潜在解决方案的一部分。 if (mbr instanceof Field) &#123; Field f = (Field)mbr; out.format(&quot; %s%n&quot;, f.toGenericString()); out.format(&quot; -- declared in: %s%n&quot;, f.getDeclaringClass()); &#125; 故障排除以下示例显示了在类上使用反射时可能会遇到的典型错误。 编译器警告：”Note: … uses unchecked or unsafe operations”调用方法时，将检查并可能转换参数值的类型。 ClassWarning 调用getMethod()会造成一个未受检异常。 import java.lang.reflect.Method; public class ClassWarning &#123; void m() &#123; try &#123; Class c = ClassWarning.class; Method m = c.getMethod(&quot;m&quot;); // warning // production code should handle this exception more gracefully &#125; catch (NoSuchMethodException x) &#123; x.printStackTrace(); &#125; &#125; &#125; $ javac ClassWarning.java Note: ClassWarning.java uses unchecked or unsafe operations. Note: Recompile with -Xlint:unchecked for details. $ javac -Xlint:unchecked ClassWarning.java ClassWarning.java:6: warning: [unchecked] unchecked call to getMethod (String,Class&lt;?&gt;...) as a member of the raw type Class Method m = c.getMethod(&quot;m&quot;); // warning ^ 1 warning 很多库的方法已经使用泛型声明进行了改进。由于c被声明为原始类型（没有类型参数），而getMethod()的相应参数是参数化类型，因此发生了未经检查的转换。需要编译器生成警告（参见The Java Language Specification, Java SE 7 Edition的Unchecked Conversion 和 Method Invocation Conversion部分） 有两种可能的解决方案。最好修改c的声明以包含适当的泛型类型。在这种情况下，声明应为： Class&lt;?&gt; c = warn.getClass(); 或者，可以使用预定义的注解@SuppressWarnings放置在问题语句的前面来明确禁止警告。 Class c = ClassWarning.class; @SuppressWarnings(&quot;unchecked&quot;) Method m = c.getMethod(&quot;m&quot;); // warning gone Tip：作为一般原则，不应忽略警告，因为警告可能表明存在错误。应适当使用参数化的声明。如果这是不可能的（也许是因为应用程序必须与库供应商的代码进行交互），请使用 @SuppressWarnings注释违规行。 构造函数不可访问时的InstantiationException如果尝试创建该类的新实例并且零参数构造函数不可见，则Class.newInstance()将引发InstantiationException。 ClassTrouble示例说明了生成的堆栈记录。 class Cls &#123; private Cls() &#123;&#125; &#125; public class ClassTrouble &#123; public static void main(String... args) &#123; try &#123; Class&lt;?&gt; c = Class.forName(&quot;Cls&quot;); c.newInstance(); // InstantiationException // production code should handle these exceptions more gracefully &#125; catch (InstantiationException x) &#123; x.printStackTrace(); &#125; catch (IllegalAccessException x) &#123; x.printStackTrace(); &#125; catch (ClassNotFoundException x) &#123; x.printStackTrace(); &#125; &#125; &#125; $ java ClassTrouble java.lang.IllegalAccessException: Class ClassTrouble can not access a member of class Cls with modifiers &quot;private&quot; at sun.reflect.Reflection.ensureMemberAccess(Reflection.java:65) at java.lang.Class.newInstance0(Class.java:349) at java.lang.Class.newInstance(Class.java:308) at ClassTrouble.main(ClassTrouble.java:9) Class.newInstance()行为非常类似于new关键字，new失败方法也会失败。反射中的典型解决方案是利用java.lang.reflect.AccessibleObject类，该类提供了抑制访问控制检查的功能。但是这种方法不适用于本例，因为java.lang.Class没有继承AccessibleObject。唯一的解决方式就是修改代码使用继承AccessibleObject的Constructor.newInstance()方法。 Tip：由于本教程成员章节创建新的类实例 部分所说的原因，一般情况下，使用Constructor.newInstance()会好一些。 更多的栗子参见本教程成员章节创建新的类实例 部分。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"},{"name":"反射","slug":"反射","permalink":"https://pingao777.github.io/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"中国真的越来越老了吗","slug":"中国真的越来越老了吗","date":"2020-02-21T13:24:36.000Z","updated":"2020-09-12T03:14:00.586Z","comments":true,"path":"2020/02/21/中国真的越来越老了吗/","link":"","permalink":"https://pingao777.github.io/2020/02/21/%E4%B8%AD%E5%9B%BD%E7%9C%9F%E7%9A%84%E8%B6%8A%E6%9D%A5%E8%B6%8A%E8%80%81%E4%BA%86%E5%90%97/","excerpt":"","text":"中国真的老了吗？老龄化是今年提得比较多的一个词，中国人真的老龄化了吗？从下图可以直观的看到，从1982年到2010年五次人口普查中，中国人口的年龄分布确实有增大的趋势。 下面的表格给出了精确的数字，可以看到1982年30岁以下人口占到了62.8%，而这一数字到了2010年只有41.2%，而60岁以上的人口却从7.5%增加到了13.3%，由此看来中国的老龄化确实不是耸人听闻，确实是当前的发展趋势。 时间 比例：0-30岁 比例：30-60岁 比例：60-100岁 1982 62.79321 29.69685 7.509944 1987 60.05553 31.80970 8.134770 1990 58.66278 32.75971 8.577509 2000 48.26399 41.27596 10.460051 2010 41.23902 45.43618 13.324804 男女比例真的失调了吗？现在娶媳妇越来越难了，特别是农村，长期以来大家都将原因归结为男女比例失调，农村为了争夺宅基地和从事大量体力劳动，重男轻女更为严重，事实是这样吗？ 从上图可以看出，随着时间的推移，男女比例确实有增加的趋势，前三次普查男女比例在1.12左右，后两次普查这个比例上涨到1.2左右，而且农村男女比例与城市男女比例相差不大。另外还可以看到一个有意思的现象是男的寿命确实不如女的。1982年62岁以上的人口中女大于男，2010年这一拐点提高到了75岁，也就是到了到了2010年75岁以上的老人中女比男多。图中的数字表示男女比例为1/2的年龄，这一数字随着年代的发展也在提高，可见对于男人来说，社会发展该有多么重要，知道为啥男的喜欢看新闻了吧。 城里人越来越多了吗？ 城里人真的越来越多了，从1982年的2亿到了2010年的接近7亿，农村人口略有减少，从8亿降到了7亿。值得一提的是1987年有一波农村人口增加，城市人口减少的特异值，发生了什么？","categories":[{"name":"生活生活","slug":"生活生活","permalink":"https://pingao777.github.io/categories/%E7%94%9F%E6%B4%BB%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://pingao777.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"name":"R","slug":"R","permalink":"https://pingao777.github.io/tags/R/"}]},{"title":"螃蟹不好吃","slug":"螃蟹不好吃","date":"2019-11-16T03:59:02.000Z","updated":"2020-09-12T03:14:00.592Z","comments":true,"path":"2019/11/16/螃蟹不好吃/","link":"","permalink":"https://pingao777.github.io/2019/11/16/%E8%9E%83%E8%9F%B9%E4%B8%8D%E5%A5%BD%E5%90%83/","excerpt":"","text":"带上这次，我已经尝试了三次，老实讲，螃蟹不好吃。 作为北方内陆人士，从小没怎么接触过这玩意。","categories":[{"name":"生活杂记","slug":"生活杂记","permalink":"https://pingao777.github.io/categories/%E7%94%9F%E6%B4%BB%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"螃蟹","slug":"螃蟹","permalink":"https://pingao777.github.io/tags/%E8%9E%83%E8%9F%B9/"}]},{"title":"Windows用户Ocaml入坑指南","slug":"Windows用户Ocaml入坑指南","date":"2019-11-02T02:33:32.000Z","updated":"2020-09-12T03:14:00.584Z","comments":true,"path":"2019/11/02/Windows用户Ocaml入坑指南/","link":"","permalink":"https://pingao777.github.io/2019/11/02/Windows%E7%94%A8%E6%88%B7Ocaml%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97/","excerpt":"","text":"第一次听说Ocaml是看到Ocaml写的quicksort算法： let rec quicksort = function | [] -&gt; [] | x::xs -&gt; let smaller, larger = List.partition (fun y -&gt; y &lt; x) xs in quicksort smaller @ (x::quicksort larger);; List.iter (fun x -&gt; Printf.printf &quot;%d &quot; x) (quicksort [2; 3; 1; 1; 7; 10]) Java语言的实现相信大家都看过，这里我把Algorithms 4th中的源码贴一下： public class Quick &#123; public static void sort(Comparable[] a) &#123; StdRandom.shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125; private static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo; int j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j; &#125; private static boolean less(Comparable v, Comparable w) &#123; if (v == w) return false; return v.compareTo(w) &lt; 0; &#125; private static void exch(Object[] a, int i, int j) &#123; Object swap = a[i]; a[i] = a[j]; a[j] = swap; &#125; &#125; 两下一对比，被震撼到了。这么说吧，看Ocaml写的快排算法很容易看到算法的本质，而Java的实现则是“一团糟”，算法的本质隐藏到琐碎的细节中了，通篇都是if分支和数组索引。Ocaml强大的模式匹配和immunable数据结构可以让你写出清晰简洁的代码。难能可贵的是，和曲高和寡的Lisp不同，Ocaml虽然崇尚函数式编程，但并不排斥命令式编程。另外，Ocaml是一门非常实用的语言，尤其适合编译方面的工作，所以如果你对DSL感兴趣，相信Ocaml会是你的菜，要知道大名鼎鼎的Rust语言在自举前编译器就是用Ocaml写的。 怀着激动的心情一通谷歌，发现只支持Linux和OSX，这就蛋疼了。尝试了官网安装说明中几种Windows安装方式，效果都不理想，顶多就一个黑框框，毕竟自己不是大神，还是需要代码提示和代码格式化这样的功能的，所以尝试了几次，只好忍痛割爱。一个偶然的机会，接触了Windows上的Wsl系统，感觉不错，又想起心心念念的Ocaml了，自然就想到了结合Wsl是否可以搭建一个理想的Ocaml环境？摸索了一段时间，终于找到一种比较理想的方法。 首先安装Wsl，在Windows开始中搜索：“程序与功能”，勾选“适用于Linux的Windows子系统”。下载Archlinux镜像，解压到文件夹，打开Arch.exe，等待安装完成。 Archlinux刚开始只有一个root，我习惯先新建一个用户，你也可以直接使用root。新建用户命令如下： useradd -m -G wheel -s /bin/bash [用户名] passwd [用户名] visudo 找到这么一行#%wheel ALL=(ALL) ALL，将全面的#去掉，用户就创建好了，然后使用下面的命令切换到此用户的主目录： su [用户名] cd ~ 下面配置pacman， sudo pacman-key --init sudo pacman-key --populate sudo vim /etc/pacman.d/mirrorlist 找到mirrorlist里China那一组，找几个离你比较近的源，把前面的#去掉，然后用下面的命令更新软件包缓存： sudo pacman -Syy 下面安装Ocaml必须的软件， sudo pacman -S ocaml # opam是ocaml的包管理工具，类似python的pip，java的maven sudo pacman -S opam sudo pacman -S patch sudo pacman -S m4 sudo pacman -S make sudo pacman -S gcc 接着，初始化opam， # wsl系统需要加上--disable-sandboxing选项 opam init --disable-sandboxing # 可以将下面的命令加到.bashrc文件中，不用每次手动执行了 eval $(opam env) # 下面是ocaml格式化和代码提示所需的工具 opam install merlin opam user-setup install opam install ocp-indent opam user-setup install opam install utop 这些都成功后下载vscode，在Windows上安装，完成后回到Linux执行下面的命令： code . 下面推荐一下几个插件： OCaml and Reason IDE，注意还有一个插件叫OCaml and Reason IDE For Wsl，选那个不带For Wsl Code Runner插件可以方便的运行单文件程序，推荐大家装一下。 ocaml-reason-format，用来格式化代码，OCaml and Reason IDE本身的格式化不太好。 最终的settings.json如下： &quot;editor.fontSize&quot;: 18, &quot;reason.path.ocamlmerlin&quot;: &quot;/home/user/.opam/default/bin/ocamlmerlin&quot;, &quot;reason.path.ocpindent&quot;: &quot;/home/user/.opam/default/bin/ocp-indent&quot;, &quot;editor.formatOnType&quot;: true, &quot;reason.codelens.enabled&quot;: false, // 不显示类型提示 &quot;ocaml-reason-format.ocamlformat&quot;: &quot;/home/user/.opam/default/bin/ocamlformat&quot;, &quot;[ocaml]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;rustykey.vscode-ocaml-reason-format&quot; &#125;, 最后一步了，大家加油！新建一个文件test.ml，将开头的那段Ocaml代码拷进去，新建另一个文件dune，输入下面的内容： (executables (names test)) 在vscode的terminal中执行dune exec ./test.bc，如果看到1 1 2 3 7 10，就说明配置成功了，接下来尽情享受Ocaml带给你不一样的感觉吧！","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Ocaml","slug":"Ocaml","permalink":"https://pingao777.github.io/tags/Ocaml/"},{"name":"函数式","slug":"函数式","permalink":"https://pingao777.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F/"}]},{"title":"Java多线程交替打印字符","slug":"Java多线程交替打印字符","date":"2019-06-05T02:13:15.000Z","updated":"2020-09-12T03:14:00.583Z","comments":true,"path":"2019/06/05/Java多线程交替打印字符/","link":"","permalink":"https://pingao777.github.io/2019/06/05/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E5%AD%97%E7%AC%A6/","excerpt":"","text":"有这样一个面试题：多线程打印AB字符 这玩意但凡有点Java基础的人，都会想到这是考察线程wait和notify，那么具体怎么做呢？如果长时间不写多线程程序，冷不丁的来一下，还真写不出。 先来复习下wait、notify的概念： wait: Causes the current thread to wait until either another thread invokes the notify() method or the notifyAll() method for this object, or a specified amount of time has elapsed.The current thread must own this object’s monitor. notify: Wakes up a single thread that is waiting on this object’s monitor. If any threads are waiting on this object, one of them is chosen to be awakened. The choice is arbitrary and occurs at the discretion of the implementation. A thread waits on an object’s monitor by calling one of the wait methods.This method should only be called by a thread that is the owner of this object’s monitor. notifyAll: Wakes up all threads that are waiting on this object’s monitor. 根据Javadoc的注释，可以看出wait将会让出锁，进入WAITING状态，直到其他线程调用notify(All)，进入AWAKENED状态，在wait最终返回之前，需要获取锁。这意味着，AWAKENED的线程将和BLOCKING状态的线程一起竞争锁，如果竞争不过，继续待在WAITING状态。有几点需要注意： 无论是wait，还是notify(All)，都必须在持有锁的状态下调用 notify(All)调用后不会释放锁，而是在离开syntronized区域后 AWAKENED线程在竞争锁时没有任何优势，和BLOCKING线程优先级一样 wait的使用范式如下： synchronized (obj) &#123; while (&lt;condition does not hold&gt;) obj.wait(); ... // Perform action appropriate to condition &#125; 之所以使用循环条件判断，是为了防止线程过早唤醒，也就是发出notify(All)时条件谓词为真，到wait返回时，谓词不为真了。另外Javadoc指出，WAITING线程会有一定的几率自己醒来，而不是收到notify(All)的通知，虽然这极少发生。 回到最初的问题，可以启动两个线程，为他们分配一个名字name，分别为A和B，设置一个变量ticket保存着下一个可运行的线程名，只有name == ticket的线程才有权运行，这样只要改变ticket的值就可以控制线程的运行了，具体代码如下： public class Main &#123; public static void main(String[] args) &#123; new PrintChar(&#39;A&#39;).start(); new PrintChar(&#39;B&#39;).start(); &#125; private static class PrintChar extends Thread &#123; private static final Object lock = new Object(); private static char running = &#39;A&#39;; private char name; public PrintChar(char name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 0; i&lt;10;i++) &#123; synchronized (lock) &#123; while (name != running) &#123; try &#123; // System.out.print(&quot; &lt;&quot; + name + &quot; waiting&gt; &quot;); lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.print(name); loop(); lock.notify(); &#125; &#125; &#125; private void loop() &#123; if (running == &#39;B&#39;) &#123; running = &#39;A&#39;; &#125; else &#123; running += 1; &#125; &#125; &#125; &#125; 为了观察线程的运行等待状态，我们将注释放开，得到下面的结果， A &lt;A waiting&gt; B &lt;B waiting&gt; A &lt;A waiting&gt; B &lt;B waiting&gt; A &lt;A waiting&gt; B ... 作为一个问题的延伸，考虑下面的问题： 多线程打印ABCDE 小伙伴们，你想到了吗？","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://pingao777.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java HotSpot虚拟机垃圾收集优化指南","slug":"Java HotSpot虚拟机垃圾收集优化指南","date":"2019-05-03T10:39:07.000Z","updated":"2020-09-12T03:14:00.582Z","comments":true,"path":"2019/05/03/Java HotSpot虚拟机垃圾收集优化指南/","link":"","permalink":"https://pingao777.github.io/2019/05/03/Java%20HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/","excerpt":"","text":"现在不懂点虚拟机都不好意思说是Java程序员了，这方面的文章不少，但质量参差不齐。在百度谷歌上看了一圈大部分是你抄我我抄你，要不就是泛泛而谈，看完之后还是一头雾水，看到Oracle官网上有一篇将虚拟机调优的文章Garbage Collection Tuning不错，有理论有实操，试着翻译下。 1 垃圾收集优化介绍从桌面上的小应用程序到大型服务器上的网络服务，各种各样的应用都在使用Java SE平台。为了支持多样化的部署，Java HotSpot虚拟机提供了多种垃圾收集器，每个都是为了满足不同的需要而设计的。Java SE根据运行应用程序的计算机的类别选择最合适的垃圾收集器。然而，这种选择并不是对每个应用都是最佳的。具有严格性能或其他要求的用户、开发人员和管理员可能需要显式选择合适的垃圾收集器，并调整某些参数以达到所需的性能水平。本文档提供了帮助完成这些任务的信息。 首先，垃圾收集器的一般特性和基本的调优选项将在串行stop-the-world收集器一节描述。然后介绍其他收集器的具体特征以及选择收集器时要考虑的因素。 本节主题： 什么是垃圾收集器？ 垃圾收集器的选择为什么重要？ 文档中支持的操作系统 什么是垃圾收集器？垃圾收集器用来自动管理应用程序的动态内存分配请求。 垃圾收集器通过以下操作执行自动动态内存管理: 从操作系统分配内存和将内存返还给操作系统。 根据应用程序的请求，将内存分配给它。 确定哪些内存还在使用。 回收未使用的内存供应用程序重用。 Java HotSpot垃圾收集器采用各种技术来提高这些操作的效率: 将年代清理与老化结合使用，将精力集中在堆中最有可能包含大量可回收内存的区域。 使用多线程并行操作，或者在应用程序的后台并行执行一些长期运行的操作。 通过压缩存活对象，尝试恢复更大的连续可用内存。 垃圾收集器的选择为什么重要？垃圾收集器的目的是将应用程序开发人员从手动动态内存管理中解放出来。开发人员无需关心内存的分配与回收，也不用关注分配的动态内存的生存期。这完全消除了一些与内存管理相关的错误，代价是增加了一些运行时开销。Java HotSpot虚拟机提供了一系列垃圾收集算法可供选择。 垃圾收集器的选择什么时候重要？对于某些应用，答案是永远不会。也就是说，一些应用程序的垃圾收集运行良好，暂停的频率和持续时间适中。然而，对于一大类应用程序，尤其是那些具有大量数据(几十亿字节)、许多线程和高事务率的应用程序，情况并非如此。 Amdahl定律(给定问题中的并行加速受问题串行部分的限制)意味着大多数工作负载不能完全并行化；有些部分总是串行的，并没有从并行中获益。在Java平台中，目前有四种支持的垃圾收集替换方案，除了其中一种串行垃圾收集器serial GC，其他的都能并行化以提高性能。尽可能降低垃圾收集的开销是非常重要的。这可以在下面的例子中看到。 图1-1中的图表模拟了一个理想的系统，除了垃圾收集之外，它是完全可伸缩的。红线表示在单处理器系统上只花费1%时间进行垃圾收集的应用程序。这意味着在拥有32个处理器的系统上，吞吐量损失超过20%。洋红色线显示，对于垃圾收集时间为10%的应用程序(在单处理器应用程序中，垃圾收集时间不算太长)，当扩展到32个处理器时，会损失75%以上的吞吐量。 该图显示，在小型系统上开发时，可以忽略的吞吐量问题可能会成为扩展到大型系统时的主要瓶颈。然而，在减少这种瓶颈方面的微小改进可以带来巨大的性能提升。对于一个足够大的系统，选择合适的垃圾收集器并在必要时对其进行调整变得很有价值。 串行垃圾收集器对于大多数小型应用已经足够了，尤其是那些堆空间约100兆字节的应用。其他收集器有额外的开销或复杂性，这是高级特性的代价。如果应用程序不需要其他收集器的高级特性，使用串行垃圾收集器就可以了。串行垃圾收集器不是最佳选择的一种情况是运行在具有大量内存和两个或更多处理器的机器上的大型多线程应用程序。当应用程序在这样的服务器级计算机上运行时，默认情况下会选择垃圾优先(G1)收集器；参见工效学。 文档中支持的操作系统本文档及其建议适用于JDK 12支持的所有系统配置，受某些垃圾收集器特定配置实际可用性的限制。请参阅甲骨文JDK认证系统配置。 2 工效学工效学是指Java虚拟机(JVM)使用启发式垃圾收集方法以(如基于行为的试探法)提高应用程序性能的过程。 JVM为垃圾收集器、堆大小和运行时编译器提供了依赖于平台的默认选择。这些选择兼顾不同类型应用程序的需求，同时只需要较少的命令行调整。此外，基于行为的动态堆大小优化，以满足应用程序的特定行为。 本节描述这些默认选择和基于行为的调整。在使用后续章节中描述的更详细控制之前，使用这些默认值。 本节主题： 垃圾收集器、堆和运行时编译器默认选择 基于行为的优化 最大暂停时间 吞吐量 占用量 调优策略 垃圾收集器、堆和运行时编译器默认选择下面是重要的垃圾收集器、堆大小和运行时编译器默认选择: 垃圾优先(G1)收集器 垃圾收集线程的最大数量受堆大小和可用CPU资源的限制 堆的初始容量为1/64物理内存 堆的最大容量为1/4物理内存 分层编译器，使用C1和C2 基于行为的优化Java HotSpot虚拟机垃圾收集器可以配置为优先满足两个目标之一:最大暂停时间和吞吐量。如果达到了首选目标，收集者将尝试最大化另一个目标。当然，这些目标并不总是能够实现的:应用程序需要至少能保存所有存活数据的最小堆，而其他配置可能会阻止实现一些或所有的期望目标。 最大暂停时间暂停时间是指垃圾收集器停止应用程序并回收非使用空间的持续时间。最大暂停时间目的是限制这些暂停的最长时间。 垃圾收集器维护着暂停时间的平均值和方差。平均值是从应用开始执行时取的，但是它是加权的，所以最近的暂停权重更大。如果暂停时间的平均值加上方差大于最大暂停时间，则垃圾收集器认为目标没有实现。 最大暂停时间是用命令行选项-XX:MaxGCPauseMillis=&lt;nnn&gt;指定的。这被解释为向垃圾收集器提示需要&lt; nnn &gt;毫秒或更少的暂停时间。垃圾收集器会调整Java堆大小和其他与垃圾收集相关的参数，以使垃圾收集暂停时间短于&lt; nnn &gt;毫秒。最大暂停时间的默认值因垃圾收集器而异。这些调整可能会导致垃圾收集的更加频繁，从而降低应用程序的整体吞吐量。然而，在某些情况下，期望的暂停时间目标可能无法实现。 吞吐量吞吐量目标是以收集垃圾花费的时间来衡量的，垃圾收集之外的时间就是应用程序时间。 吞吐量通过命令选项-XX:GCTimeRatio=nnn指定。垃圾收集时间与应用时间之比为1/ (1+nnn)。例如，-XX:GCTimeRatio=19设置了垃圾收集时间占总时间的1/20或5%。 垃圾收集花费的时间是所有垃圾收集暂停的总时间。如果没有达到吞吐量目标，那么垃圾收集器的一个可能的操作是增加堆的大小，以便在垃圾收集之间的应用程序时间可以更长。 占用量如果吞吐量和最大暂停时间目标已经达到，那么垃圾收集器会减小堆的大小，直到其中一个目标(总是吞吐量目标)无法达到为止。垃圾收集器可以分别使用-Xms=&lt;nnn &gt;和-Xmx=&lt;mmm &gt;设置为最小和最大堆大小。 调优策略堆增长或收缩到以支持所选吞吐量。了解堆优化策略，如选择最大堆大小和选择最大暂停时间目标。 除非您确定需要大于堆大小默认值的堆，否则不要为堆选择最大值。为您的应用选择一个足够的吞吐量即可。 应用程序行为的改变会导致堆增长或收缩。例如，如果应用程序开始以更高的速率分配内存，那么堆就会增长以保持相同的吞吐量。 如果堆增长到其最大大小，并且没有达到吞吐量目标，则最大堆大小对于吞吐量目标来说太小。将最大堆大小设置为接近平台上总物理内存但不会导致应用程序交换的值。再次执行应用程序。如果仍然没有达到吞吐量目标，那么应用程序时间的目标对于平台上的可用内存来说太高了。 如果可以达到吞吐量目标，但暂停时间过长，则选择更小的最大暂停时间。选择更小的最大暂停时间可能意味着您的吞吐量无法实现，因此请选择对应用程序来说可以接受的折衷值。 垃圾收集器试图满足竞争目标时，堆的大小通常会发生波动。即使应用程序已经达到稳定状态，也是如此。实现吞吐量目标(可能需要更大的堆)的压力与最大暂停时间和最小占用空间(两者都可能需要更小的堆)的目标相竞争。 3 垃圾收集器实现Java SE平台的一个优势是它保护开发人员免受内存分配和垃圾收集复杂性的困扰。 然而，当垃圾收集成为主要瓶颈时，理解实现的某些方面是有用的。垃圾收集器对应用程序使用对象的方式进行假设，这些假设反映在可调参数中，这些参数可以在不牺牲抽象能力的情况下进行调整以提高性能。 本节主题： 分代垃圾收集 分代 性能考虑 吞吐量和占用量考量 分代垃圾收集当运行程序中的任何其他存活对象的任何引用不能再访问一个对象时，它就是一个垃圾，虚拟机可以重用它的内存。 理论上，最简单的垃圾收集算法每次运行时都会遍历每个可到达的对象。其余的对象都被认为是垃圾。这种方法花费的时间与活动对象的数量成正比，这对维护大量存活数据的大型应用程序来说是禁止的。 Java HotSpot虚拟机包含许多不同的垃圾收集算法，这些算法都使用一种称为分代收集的技术。虽然简单的垃圾收集每次都会检查堆中的每个存活对象，但是分代收集利用了在大多数应用程序中观察到的几个经验特性来最小化回收未使用(垃圾)对象所需的工作。这些观察到的特性中最重要的是弱分代假说(weak generational hypothesis)，它指出大多数对象只能存活很短的一段时间。 图3-1中的蓝色区域是对象寿命的典型分布。x轴显示的是对象生命周期。y轴显示的是存活对象的字节数。左边的尖峰代表分配后不久可以回收的对象(换句话说，已经“死亡”)。例如，迭代器对象通常只在单个循环期间有效。 有些对象确实寿命更长，所以分布向右侧延伸。例如，通常有一些在初始化时分配的对象会一直存在，直到虚拟机退出。在这两个极端之间是在运算期间的中间值，在这里被视为初始峰值右侧的块。一些应用程序具有非常不同的分布，但令人惊讶的是，大量应用程序具有这种一般性的形状。通过关注大多数对象“朝生夕死”的事实，有效的收集成为可能。 分代为了针对这种情况进行优化，内存分几代进行管理(内存池保存不同年龄的对象)。垃圾收集发生在每一代填满时。 绝大多数对象被分配到一个专门用于年轻对象(新生代，young generation)的池中，大多数对象死在那里。当新生代填满时，它会导致一个小规模垃圾收集(minor collection)，它只收集新生代；其他分代的垃圾不会被回收。这种收集的成本首先与被收集的存活对象的数量成比例；充满死亡对象的新生代收集的很快。 通常，在每一次小规模的收集过程中，新生代幸存下来的一些对象会被转移到老年代(old generation)。最后，老年代也会填满并且必须被收集，从而产生一个大规模垃圾收集(major collection)，它将收集整个堆。大规模垃圾收集的持续时间通常比小规模垃圾收集长得多，因为涉及的对象数量要大得多。图3-2显示了串行垃圾收集器(serial garbage collector)中的默认分代排列: 启动时，Java HotSpot虚拟机将整个Java堆保留在地址空间中，除非需要，否则不会为其分配任何物理内存。Java堆的整个地址空间在逻辑上分为新生代和老年代。为对象内存保留的完整地址空间也分为新生代和老年代。 新生代由eden和两个survivor空间组成。大多数对象最初分配在eden中。在任何时候都有一个survivor空间是空的，并且在垃圾收集期间充当eden和另一个survivor空间中存活对象的目标空间；垃圾收集后，eden和源survivor空间是空的。在下一次垃圾收集中，两个survivor空间的角色交换。最近填充的survivor空间将会把存活对象复制到另一个survivor空间。对象以这种方式在两个survivor空间之间来回复制，直到它们被复制了一定次数或者没有足够的空间了。这些对象被复制到老年代。这个过程也被称为老化(aging)。 性能考虑垃圾收集的主要指标是吞吐量和时延。 吞吐量是指未花费在垃圾收集上的总时间的百分比(即应用程序所占用的时间，译者注)。吞吐量包括分配内存所花费的时间(但通常不需要调整分配速度)。 时延是应用程序的响应能力。垃圾收集会暂停应用程序进而会影响应用程序的响应能力。 用户对垃圾收集有不同的要求。例如，有些人认为网络服务器的正确度量是吞吐量，因为垃圾收集期间的暂停可能是可以容忍的，或者会因为网络延迟而变得模糊不清。然而，在交互式图形程序中，即使短暂的暂停也会对用户体验产生负面影响。 一些用户对其他考虑很敏感。占用空间是一个进程的工作集，以页面和缓存行来衡量。在物理内存有限或进程众多的系统上，占用空间可能决定可伸缩性。及时性(Promptness)是指对象死亡和内存可用之间的时间，对于包括远程方法调用(Remote Method Invocation, RMI)在内的分布式系统来说，这是一个重要的考虑因素。 一般来说，为特定一代选择大小就是在这些因素之间作权衡。例如，非常大的新生代可能最大化吞吐量，但这样做是以空间占用、及时性和暂停时间为代价的。相反，可以通过减小新生代的空间来换取小的垃圾收集暂停时间，但这会牺牲吞吐量。一代的空间不会影响另一代的收集频率和暂停时间。 没有一种通用的方法可以选择一代的最优空间大小。最佳选择取决于应用程序使用内存的方式以及用户需求。因此，虚拟机对垃圾收集器的选择并不总是最佳的，可以通过命令行选项修改；请参见影响垃圾收集性能的因素。 吞吐量和占用量考量吞吐量和占用量最好使用特定于应用的指标来衡量。 例如，可以使用客户端负载生成器测试网络服务器的吞吐量，可以使用pmap命令在Solaris操作系统上测量服务器的占用空间。通过检查虚拟机本身的诊断输出，可以轻松估计垃圾收集导致的暂停时间。 命令行选项-verbose:gc在每次垃圾收集中打印关于堆和垃圾收集的信息。下面是一个例子: [15,651s][info ][gc] GC(36) Pause Young (G1 Evacuation Pause) 239M-&gt;57M(307M) (15,646s, 15,651s) 5,048ms [16,162s][info ][gc] GC(37) Pause Young (G1 Evacuation Pause) 238M-&gt;57M(307M) (16,146s, 16,162s) 16,565ms [16,367s][info ][gc] GC(38) Pause Full (System.gc()) 69M-&gt;31M(104M) (16,202s, 16,367s) 164,581ms 输出显示了两次新生代的垃圾收集，之后是应用程序调用System.gc()启动的完整垃圾收集(Full GC)。这些行以时间戳开始，该时间戳表示应用程序启动的时间。接下来是关于该行的日志级别(信息)和标签(gc)的信息。随后是垃圾收集识别号。在这种情况下，有三个编号为36、37和38的垃圾收集。然后记录的是垃圾收集类型和原因。之后，会记录一些关于内存消耗的信息。该日志使用“在垃圾收集之前使用堆大小”-&gt;“在垃圾收集之后使用堆大小”的格式。 在示例的第一行中，是239兆-&gt;57M(307兆)，这意味着在垃圾收集清除大部分内存之前使用了239兆字节，但是收集之后保留了57兆字节。堆大小为307兆字节。请注意，在此示例中，完整的垃圾收集将堆从307兆字节缩减到104兆字节。在内存使用信息之后，将记录垃圾收集的开始和结束时间以及持续时间(结束-开始)。 -verbose:gc命令是-Xlog:gc的别名。-Xlog是用于HotSpot JVM的通用日志配置选项。这是一个基于标签的系统，其中gc是标签之一。要获得更多关于垃圾收集正在做什么的信息，您可以配置日志来打印任何带有垃圾收集标签和任何其他标签的消息。该命令的命令行选项是-Xlog:gc*。 下面是一个用-Xlog:gc*配置的G1收集器新生代垃圾收集的例子: [10.178s][info][gc,start ] GC(36) Pause Young (G1 Evacuation Pause) [10.178s][info][gc,task ] GC(36) Using 28 workers of 28 for evacuation [10.191s][info][gc,phases ] GC(36) Pre Evacuate Collection Set: 0.0ms [10.191s][info][gc,phases ] GC(36) Evacuate Collection Set: 6.9ms [10.191s][info][gc,phases ] GC(36) Post Evacuate Collection Set: 5.9ms [10.191s][info][gc,phases ] GC(36) Other: 0.2ms [10.191s][info][gc,heap ] GC(36) Eden regions: 286-&gt;0(276) [10.191s][info][gc,heap ] GC(36) Survivor regions: 15-&gt;26(38) [10.191s][info][gc,heap ] GC(36) Old regions: 88-&gt;88 [10.191s][info][gc,heap ] GC(36) Humongous regions: 3-&gt;1 [10.191s][info][gc,metaspace ] GC(36) Metaspace: 8152K-&gt;8152K(1056768K) [10.191s][info][gc ] GC(36) Pause Young (G1 Evacuation Pause) 391M-&gt;114M(508M) 13.075ms [10.191s][info][gc,cpu ] GC(36) User=0.20s Sys=0.00s Real=0.01s 注意：由-Xlog:gc*生成的输出格式可能会在未来版本中发生变化。 4 影响垃圾收集性能的因素影响垃圾收集性能的两个最重要的因素是总的可用内存和新生代的比例。 本节内容： 总的可用内存 影响分代大小的选项 堆的默认大小 通过最小化Java堆大小来节省动态占用空间 新生代 新生代大小选项 survivor空间大小 总的可用内存影响垃圾收集性能的最重要因素是总可用内存。因为收集发生在分代空间占满时，吞吐量与可用内存量成反比。 注意：以下关于堆的增长和收缩、堆布局和默认值的讨论以串行垃圾收集器为例。虽然其他收集器使用类似的机制，但这里提供的细节可能不适用于其他收集器。有关其他收集器的类似信息，请参考各自的主题。 影响分代大小的选项许多选项会影响分代大小。图4-1展示了堆中提交空间和虚拟空间之间的区别。虚拟机初始化时，堆的整个空间都会被保留。保留空间的大小可以用-Xmx选项指定。如果-Xms参数的值小于-Xmx参数的值，则不是所有保留的空间都会立即提交给虚拟机。在此图中，未提交的空间标记为“虚拟”。堆的不同部分，即新生代和老年代，可以根据需要增加到虚拟空间的极限。 一些参数可以设置堆的一部分与另一部分的比率。例如，参数–XX:NewRatio表示老年代与新生代的相对大小。 堆的默认大小默认情况下，虚拟机会在每次垃圾收集时增大或缩小堆，以尝试将每次收集中存活对象的可用空间比例维持在特定范围内。 该范围为选项-XX:MinHeapFreeRatio= &lt;最小值&gt;和-XX:MaxHeapFreeRatio= &lt;最大值&gt;设置的百分比，堆的总大小以–Xms &lt;最小值&gt;为界，以–Xmx &lt;最大值&gt;为界。64位Solaris操作系统(SPARC平台版)的默认选项如表4-1所示。 选项 默认值 -XX:MinHeapFreeRatio 40 -XX:MaxHeapFreeRatio 70 -Xms 6656 KB -Xmx 计算得到 有了这些选项，如果某一代的可用空间低于40%，则会扩展堆空间以保持40%的可用空间，一直到这一代的最大允许大小。类似地，如果空闲空间超过70%，那么这一代空间将收缩，使得只有70%的空间是空闲的，这取决于这一代空间的最小尺寸。 如表4-1所示，默认的最大堆大小是由JVM计算的值。Java SE中用于并行收集器(Parallel collector)的计算现在被用于所有垃圾收集器。计算的一部分是64位平台的最大堆大小上限。请参见大小并行垃圾收集器默认堆。客户端模式的JVM也有类似的计算，只不过最大堆大小小于服务器模式的JVM。 以下是关于服务器应用程序堆大小的一般准则: 除非暂停有问题，否则请尝试向虚拟机授予尽可能多的内存。默认大小通常太小。 将-Xms和-Xmx设置为相同的值可以通过从虚拟机中删除最重要的规模调整策略来提高可预测性。但是，如果您做出错误的选择，虚拟机将无法进行补偿。 通常，增加处理器数量同时也要增加内存，因为内存分配可以并行进行。 通过最小化Java堆大小来节省动态占用空间如果您需要最小化应用程序的动态内存占用(执行期间消耗的最大内存)，那么您可以通过最小化Java堆大小来实现这一点。Java SE嵌入式应用程序可能需要这一点。 通过降低命令行选项-XX:MinHeapFreeRatio(默认值为40%)和-XX:MaxHeapFreeRatio(默认值为70%)的值，从而最小化Java堆大小。将-XX:MaxHeapFreeRatio降低到低至10%，-XX:MinHeapFreeRatio已证明能够成功地减小堆大小，而且不会造成太大的性能降低；但是，最终的结果可能取决于你的应用。 此外，您可以指定-XX:-ShrinkHeapInSteps，它会立即将Java堆减小到目标大小(由参数-XX:MaxHeapFreeRatio指定)。此设置可能会导致性能下降。默认情况下，Java运行时会逐渐将Java堆减小到目标大小；这个过程需要多个垃圾收集周期。 新生代在总可用内存之后，影响垃圾收集性能的第二个最大影响因素是专用于新生代的比例。 新生代越大，小规模收集就越少。然而，对于给定的堆大小，较大的新生代意味着较小的老年代，这将增加大规模收集的频率。最佳选择取决于应用程序对象的生命周期分布。 新生代大小选项默认情况下，新生代的大小由选项-XX:NewRatio控制。 例如，设置-XX:NewRatio=3意味着新生代和老年代之间的比率是1:3。换句话说，eden和survivor空间总的大小将是总堆大小的四分之一。 选项-XX:NewSize和-XX:MaxNewSize指定了新生代的大小下界和上界。将它们设置为相同的值新生代就是固定值，正如将-Xms和-Xmx设置为相同的值可以固定总的堆大小一样。这有助于以比-XX:NewRatio更精细的粒度调整新生代。 survivor空间大小您可以使用选项-XX:SurvivorRatio来调整survivor空间的大小，但这通常对性能并不重要。 例如，-XX:SurvivorRatio=6将eden和survivor空间之间的比率设置为1:6。换句话说，每个survivor空间将是eden大小的六分之一，也就是新生代大小的八分之一(不是七分之一，因为有两个survivor空间)。 如果survivor空间太小，那么将会直接复制到老年代。如果幸存者空间太大，那么将会有很多空间永远不会使用。在每次垃圾收集时，虚拟机都会选择一个阈值，即一个对象在其转移到老年代之前可以复制的次数。选择这个阈值是为了让survivor保持半饱和状态。您可以使用日志配置-Xlog:gc，age可以用来显示这个阈值和新生代对象的年龄。它对于观察应用程序的生命周期分布也很有用。 表4-2提供了64位Solaris的默认值。 选项 默认值 -XX:NewRatio 2 -XX:NewSize 1310 MB -XX:MaxNewSize not limited -XX:SurvivorRatio 8 新生代的最大大小是根据总堆的最大大小和-XX:NewRatio参数的值计算的。-XX:MaxNewSize参数的“无限制”意味着计算不限制，除非命令行上指定了-XX:MaxNewSize的值。 以下是服务器应用程序的一般指南: 首先决定您可以为虚拟机提供的最大堆大小。然后，根据新生代的规模制定您的性能指标，以找到最佳设置。 请注意，最大堆大小应始终小于机器上安装的内存量，以避免过多的页面错误和抖动。 如果总堆大小是固定的，那么增加新生代的大小需要减少老年代的大小。保持老一代足够大，以容纳应用程序在任何给定时间使用的所有存活数据，加上一定量的富余空间(10%到20%或更多)。 根据前面提到的对老年代的限制: 给予新生代足够的内存。 增加处理器数量的同时增加新生代的规模，因为分配可以并行化。 5 可用收集器本节主题： 串行收集器(Serial Collector) 并行收集器(Parallel Collector) 主要并发收集器(The Mostly Concurrent Collectors) 选择收集器 串行收集器(Serial Collector)串行收集器使用单个线程来执行所有垃圾收集工作，这使得它相对高效，因为线程之间没有通信开销。 它最适合单处理器机器，尽管它对于具有小数据集(大约100兆字节)的应用程序在多处理器上很有用，但它不能利用多处理器硬件的优势。默认情况下，串行收集器是在某些硬件和操作系统配置上的默认选择，或者通过选项-XX:+UseSerialGC显式启用。 并行收集器(Parallel Collector)并行收集器也称为吞吐量收集器，它是与串行收集器相似的一代收集器。串行收集器和并行收集器之间的主要区别是并行收集器有多个线程用于加快垃圾收集。 并行收集器适用于运行在多处理器或多线程硬件上具有大中型数据集的应用程序。您可以通过使用-XX:+UseParallelGC选项来启用它。 并行压缩是一项使并行收集器能够并行执行大规模垃圾收集的功能。如果没有并行压缩，大规模垃圾收集是使用单个线程来执行的，这可能会极大地限制可伸缩性。如果指定了选项-XX:+UseParallelGC，则默认情况下启用并行压缩。您可以通过使用-XX:-UseParallelOldGC选项来禁用它。 主要并发收集器(The Mostly Concurrent Collectors)并发标记清除(CMS)收集器和垃圾优先(G1)垃圾收集器是两个主要并发收集器。大多数并发收集器并发执行一些代价较高应用程序工作。 G1垃圾收集器:这种服务器风格的收集器是为具有大内存、多处理器机器设计的。为了满足垃圾收集暂停时间目标的同时实现高吞吐量。 在某些硬件和操作系统配置上默认选择G1，或者可以使用-XX:+UseG1GC显式启用。 CMS收集器:这个收集器是为那些更喜欢较短垃圾收集暂停时间的应用程序设计的，并且能够与垃圾收集共享处理器资源。使用-XX:+UseConcMarkSweepGC启用CMS收集器。 CMS收集器在JDK 9中被标记为弃用。 Z收集器Z垃圾收集器(ZGC)是一个可扩展的低延迟垃圾收集器。ZGC同时执行所有代价高昂的工作，同时不停止应用程序线程的执行。 ZGC适用于需要低时延(暂停时间不到10 ms)和/或特大堆(几T字节)的应用。您可以通过使用-XX:+UseZGC选项来启用。 从JDK 11开始，ZGC作为一个实验的特性的出现。 选择收集器除非您的应用程序有相当严格的暂停时间要求，否则首先运行您的应用程序，并允许虚拟机选择收集器。 如有必要，调整堆大小以提高性能。如果性能仍然达不到您的目标，请使用以下准则作为选择收集器的出发点: 如果应用程序有一个小数据集(高达大约100兆字节)，则使用选项-XX:+UseSerialGC选择串行收集器。 如果应用程序将在单个处理器上运行，并且没有暂停时间要求，则选择带有选项-XX:+UseSerialGC的串行采集器。 如果(a)应用程序性能峰值是第一优先事项，并且(b)没有暂停时间要求，或者一秒钟或更长的暂停时间是可接受的，则让虚拟机选择收集器或使用-XX:+UseParallelGC选择并行收集器。 如果响应时间比总吞吐量更重要，并且垃圾收集暂停时间必须保持在大约一秒钟以内，则选择一个具有-XX:+UseG1GC或-XX:+UseConcMarkSweepGC的主要并发收集器。 如果响应时间是一个高优先级，和/或您正在使用一个非常大的堆，那么选择一个具有-XX:UseZGC的完全并发收集器。 这些准则只是选择收集器的出发点，因为性能取决于堆的大小、应用程序维护的存活数据量以及可用处理器的数量和速度。 如果推荐的收集器没有达到期望的性能，那么首先尝试调整堆和各个分代的大小以满足期望的目标。如果性能仍然不足，请尝试不同的收集器:使用并发收集器减少暂停时间，使用并行收集器增加多处理器硬件上的总吞吐量。 6 并行收集器(The Parallel Collector)并行收集器(这里也称为吞吐量收集器)是一个类似于串行收集器的分代收集器。串行收集器和并行收集器之间的主要区别是并行收集器有多个线程用于加快垃圾收集。 并行收集器通过命令行选项-XX:+UseParallelGC启用。默认情况下，使用此选项，大规模收集和小规模收集并行运行，以进一步减少垃圾收集开销。 本节主题： 并行收集器垃圾收集器线程的数量 并行收集器中的分代排列 并行收集器工效学 指定并行收集器行为选项 并行收集器指标的优先级 并行收集器各个分代空间调整 并行收集器默认堆大小 并行收集器初始和最大堆大小的规范 过多的并行收集器时间和内存不足错误 并行收集器度量 并行收集器垃圾收集器线程的数量在硬件线程数N大于8(感觉这里应该说的是CPU的个数，译者加)的机器上，并行收集器使用硬件线程数的固定比例作为垃圾收集器线程数。 对于较大的N值，比例为5/8。当小于8时，线程等于N。在特定的平台上，这一比例降至5/16。垃圾收集器线程的具体数量可以通过命令行选项进行调整(将在后面描述)。在只有一个处理器的主机上，由于并行执行(例如同步)所需的开销，并行收集器的性能可能不如串行收集器。但是，当具有中型到大型堆的应用程序时，运行在具有两个处理器的计算机上，它通常比串行收集器性能略好，并且当有两个以上的处理器可用时，它通常比串行收集器性能好得多。 垃圾收集器线程的数量可以通过命令行选项-XX:ParallelGCThreads=&lt;N&gt;来控制。如果使用命令行选项调整堆，那么并行收集器获得良好性能所需的堆大小与串行收集器所需的大小相同。但是，启用并行收集器应该会缩短收集暂停时间。因为多个垃圾收集线程同时参与一个小规模收集，所以在收集过程中，从新生代到老年代的升级可能会导致一些碎片。大规模收集中涉及的每个垃圾收集线程都会保留老年代的一部分用于升级，将可用空间划分到这些“升级缓冲区”会导致碎片效应。减少垃圾收集器线程的数量和增加老年代的大小将减少这种碎片效应。 并行收集器中的分代排列在并行收集器中，分代的排列是不同的。 这种布置如图6-1所示: 并行收集器人机工程学当使用-XX:+UseParallelGC选择并行收集器时，它启用了一种自动优化方法，允许您指定行为，而不是分代大小和其他低级优化细节。 指定并行收集器行为的选项您可以指定最大垃圾收集暂停时间、吞吐量和占用空间(堆大小)。 最大垃圾收集暂停时间:最大暂停时间是用命令行选项-XX:MaxGCPauseMillis=&lt;N&gt;指定的。这被解释为需要N毫秒或更少的暂停时间；默认情况下，没有最大暂停时间。如果指定了暂停时间，将调整堆大小和其他与垃圾收集相关的参数，以使垃圾收集暂停时间短于指定值；然而，期望的暂停时间目标可能并不总能实现。这些调整可能会导致垃圾收集器降低应用程序的总吞吐量。 吞吐量:吞吐量目标是根据垃圾收集花费的时间与垃圾收集之外花费的时间(称为应用程序时间)来衡量的。目标由命令行选项-XX:GCTimeRatio=&lt;N&gt;指定，该选项将垃圾收集时间与应用程序时间的比率设置为1 / (1 + N)(感觉应该是垃圾收集与总时间的比率，译者注)。例如，-XX:GCTimeRatio=19设置了垃圾收集总时间的1/20或5%的目标。默认值为99，因此垃圾收集的时间目标为1%。 占用空间:最大堆占用空间是使用选项-Xmx指定的。此外，收集器有一个隐含的目标，只要满足其他目标，就要最小化堆的大小。 并行收集器指标的优先级目标按最大暂停时间指标、吞吐量指标和最小占用空间指标顺序排列：首先要满足最大暂停时间指标，只有当最大暂停时间指标达到后才会去实现吞吐量的指标，同样只有前两个指标满足后才会考虑占用空间的指标。 并行收集器各个分代空间调整收集器保存的平均暂停时间等统计信息会在每次收集结束时更新。 进行测试以确定目标是否已经实现，并对一代的空间进行任何必要的调整。例外情况是显式垃圾收集，例如，在保存统计信息和调整代的大小方面，将会忽略System.gc()调用的影响。 各代大小的增加和缩小是通过各代大小的固定百分比的增量来完成的，以便各个分代朝着其期望的大小递增或递减。默认情况下，一代以20%的增量增长，以5%的增量收缩。新生代和老年代的增长比例分别可以通过-XX:YoungGenerationSizeIncrement=&lt;Y&gt;和-XX:TenuredGenerationSizeIncrement=&lt;T&gt;指定。收缩比例通过-XX:AdaptiveSizeDecrementScaleFactor=&lt;D&gt;进行调整，如果增长比例是X%，那么收缩比例为X/D%。 如果收集器在启动时增加一代的大小，那么增量中会添加一个额外的百分比。这个百分比将会随着垃圾收集次数的增加而衰减，并不会长期存在。补充的目的是提高启动性能。收缩的百分比没有补充。 如果没有达到最大暂停时间目标，那么一次只能缩小一代的规模。如果两代的暂停时间都超过了目标，那么暂停时间较长的一代的规模将首先缩小。 如果吞吐量目标没有实现，那么两代的规模都会增加。每一个都按其对总垃圾收集时间的贡献比例增加。例如，如果新生代的垃圾收集时间是总收集时间的25%，如果新生代的完整增量是20%，那么新生代将增加5%。 并行收集器默认堆大小除非命令行中指定了初始堆大小和最大堆大小，否则它们是根据计算机上的内存量计算的。默认的最大堆大小是物理内存的四分之一，而初始堆大小是物理内存的六分之一。分配给新生代的最大空间量是总堆大小的三分之一。 并行收集器初始和最大堆大小的规范您可以使用选项-Xms(初始堆大小)和-Xmx(最大堆大小)指定初始和最大堆大小。 如果您知道您的应用程序需要多少堆才能正常工作，那么您可以将-Xms和-Xmx设置为相同的值。如果您不知道，那么JVM将从使用初始堆大小开始，然后增加Java堆，直到找到堆使用和性能之间的平衡。 其他参数和选项会影响这些默认值。要验证默认值，请使用-XX:+PrintFlagsFinal选项，并在输出中查找-XX:MaxHeapSize。例如，在Linux或Solaris上，您可以运行以下程序: java -XX:+PrintFlagsFinal &lt;GC options&gt; -version | grep MaxHeapSize 过多的并行收集器时间和内存不足错误如果在垃圾收集中花费了太多时间，并行收集器将抛出OutOfMemoryError。 如果总时间的98%以上花在垃圾收集上，并且回收的堆少于2%，则抛出OutOfMemoryError。此功能旨在防止应用程序长时间运行，同时由于堆太小而几乎没有进展。如有必要，可以通过向命令行添加选项-XX:-UseGCOverheadLimit来禁用此功能。 并行收集器度量并行收集器的详细垃圾收集器输出与串行收集器的输出基本相同。 7 主要并发收集器主要并发收集器对应用程序并发执行收集工作，因此得名。Java HotSpot虚拟机包括两个主要并发的收集器: 并发标记清除(CMS)收集器:该收集器适用于那些更喜欢较短垃圾收集暂停时间并且能够与垃圾收集共享处理器资源的应用程序。 垃圾优先(G1)垃圾收集器:这种服务器风格的收集器适用于具有大量内存的多处理器机器。它旨在满足垃圾收集暂停时间目标，同时实现高吞吐量。 主要并发收集器的开销主要并发收集器会占用处理器资源(原本应用程序可以使用这些资源)，以缩短主要收集暂停时间。 最明显的开销是在收集的并发部分使用一个或多个处理器。在N处理器系统中，垃圾收集的并发部分可用处理器个数为K/N，其中1 &lt;= K &lt;=&#123;N/4&#125;。除了在并发阶段使用处理器之外，启用并发还会产生额外的开销。因此，虽然并发收集器的垃圾收集暂停时间通常要短得多，但应用程序吞吐量也往往比其他收集器略低。 在具有多个处理核心的机器上，处理器在收集的并发部分也可用于应用程序线程，因此并发垃圾收集器线程不会暂停应用程序。这通常会导致更短的暂停时间，但是应用程序可用的处理器资源也更少，而且会有一些减速，尤其是在应用程序最大限度地使用所有处理核心的情况下。随着N的增加，由于并发垃圾收集导致的处理器资源减少变得更小，并发收集的好处也增加了。请参阅并发模式故障，其中讨论了这种模式的潜在限制。 因为在并发阶段至少有一个处理器用于垃圾收集，所以并发收集器通常在单处理器(单核)机器上不会提供任何好处。 8 并发标记清除收集器并发标记清除(CMS)收集器是为那些喜欢较短垃圾收集暂停时间的应用程序设计的，并且能够在应用程序运行时与垃圾收集器共享处理器资源。 典型地，具有相对较大的长寿命数据集(大的老年代)并且运行在具有两个或更多处理器的机器上的应用程序倾向于受益于该收集器的使用。CMS收集器使用-XX:+UseConcMarkSweepGC启用。 不推荐使用CMS收集器。强烈考虑改用垃圾优先收集器。 本节主题： 并发标记清除收集器的性能和结构 并发模式故障 过多的垃圾收集时间过长和内存不足错误 并发标记清除收集器和浮动垃圾 并发标记清除收集器暂停 并发标记清除收集器并发阶段 启动并发收集周期 计划暂停 并发标记清除收集器度量 并发标记清除收集器的性能和结构与其他可用的收集器相似，CMS收集器是分代的；因此，小规模收集和大规模收集都会发生。CMS收集器试图通过使用单独的垃圾收集线程，在执行应用程序线程的同时，跟踪可到达的对象来减少大规模收集的暂停时间。 在每次大规模收集中，CMS收集器会在收集开始时暂停所有应用程序线程一段时间，在收集期间再次暂停。第二次暂停往往比第一次长。多个线程在两次暂停期间执行收集工作。一个或多个垃圾收集线程完成剩余的收集工作(包括大部分对存活对象的跟踪和对不可达对象的清除)。小规模收集可以与正在进行的大规模收集交叉进行，并且以类似于并行收集的方式完成(特别是小规模收集暂停期间)。 并发模式故障CMS收集器使用一个或多个垃圾收集器线程，这些线程与应用程序线程同时运行，目的是在老年代变满之前完成老年代的收集。 如前所述，在正常操作中，CMS收集器在应用程序线程仍在运行的情况下执行大部分跟踪和扫描工作，因此应用程序线程只能看到短暂的暂停。但是，如果CMS收集器无法在老年代填满之前回收不可访问的对象，或者如果内存分配不能满足老年代中的可用空闲空间，则应用程序会暂停，并且收集会在所有应用程序线程停止的情况下完成。无法并发完成收集被称为并发模式故障(concurrent mode failure)，意味着需要调整CMS收集器参数。如果并发收集被显式垃圾收集(System.gc())或为诊断工具的垃圾收集中断，则报告一个并发模式中断。 过多的垃圾收集时间过长和内存不足错误如果在垃圾收集中花费了太多时间，如果总时间的98%以上花费在垃圾收集中，并且恢复的堆少于2%，则抛出OutOfMemoryError。 此功能旨在防止应用程序长时间运行，同时由于堆太小而几乎没有进展。如有必要，可以通过向命令行添加选项-XX:-UseGCOverheadLimit来禁用此功能。 该策略与并行收集器中的策略相同，只是执行并发收集所花费的时间不计入98%的时间限制。换句话说，只有在应用程序停止时执行的收集才会计入过多的垃圾收集时间。这种收集通常是由于并发模式故障或显式收集请求(例如，对System.gc()的调用)。 并发标记清除收集器和浮动垃圾同Java HotSpot虚拟机中的所有其他收集器一样，CMS收集器是一个跟踪收集器，它需要标识堆中所有可到达的对象。 理查德·琼斯和拉斐尔·林在他们的出版物《垃圾收集:自动动态内存算法》中说，这是一个增量更新收集器。因为应用程序线程和垃圾收集器线程在主要收集过程中同时运行，垃圾收集器线程跟踪的对象可能随后在收集过程结束时变得不可访问。这种尚未被回收的不可达对象被称为浮动垃圾。浮动垃圾的数量取决于并发收集周期的持续时间和应用程序引用更新的频率，也称为突变(mutations)。此外，因为新生代和老年代是独立收集的，彼此互为可达性分析的根(root)。作为一个粗略的指导方针，试着将老年代的空间增加20%，以解决漂浮垃圾的问题。一个并发收集周期结束时堆中的浮动垃圾将在下一个收集周期中收集。 并发标记清除收集器暂停CMS收集器在并发收集周期内暂停应用程序两次。第一个暂停是将从根(例如，来自应用程序线程堆栈和寄存器的对象引用、静态对象等)和堆中其他地方(例如，新生代)直接可达对象标记为存活对象。 第一次暂停称为初始标记暂停(initial mark pause)。第二次暂停发生在并发跟踪阶段的末尾，并在CMS收集器完成对对象的跟踪后，查找由于应用程序线程更新对象中的引用而被并发跟踪遗漏的对象。第二次暂停称为备注暂停(remark pause)。 并发标记清除收集器并发阶段可达对象图的并发跟踪发生在初始标记暂停和备注暂停之间。 在这个并发跟踪阶段，一个或多个并发垃圾收集器线程可能在使用处理器，原本这些资源对于应用程序是可用的。因此，即使应用程序线程没有暂停，在此阶段和其他并发阶段，应用程序的吞吐量也会相应降低。备注暂停后，并发清理阶段收集不可达的对象。收集周期完成后，CMS收集器等待，几乎不消耗计算资源，直到下一个主要收集周期开始。 启动并发收集周期对于串行收集器，每当老年代变满，所有应用程序线程都停止，开始一次大规模收集。相比之下，CMS收集器中并发收集的开始时间必须确保收集能够在老年代变满之前完成；否则，由于并发模式故障，应用程序会观察到较长的暂停时间。有几种方法可以开始并发收集。 根据最近的历史记录，CMS收集器会对老年代耗尽之前剩余的时间以及并发收集周期所需的时间进行估计。使用这些动态估计，开始并发收集周期，目的是在老年代耗尽之前完成收集周期。为了安全起见，对这些估计留有余量，因为并发模式故障的代价可能非常高。 如果老年代的占用率超过初始占用率(老年代的百分比)，并发收集也会开始。启动并发周期的默认值约为92%，但该值会随版本的不同而变化。该值可以使用命令行选项-XX:CMSInitiatingOccupancyFraction=&lt;N&gt;手动调整，其中N是老年代大小的整数百分比(0到100)。 计划暂停新生代和老年代的暂停是独立发生的。 它们不会重叠，但可能会快速连续发生，一次收集的暂停，紧接着另一次收集的暂停，看起来可能是一个更长的暂停。为了避免这种情况，CMS收集器试图将备注暂停安排在上一次和下一次新生代代暂停的中间。当前没有为初始标记暂停进行这种调度，初始标记暂停通常比备注暂停短得多。 并发标记清除收集器度量以下是带有选项-Xlog:gc的CMS收集器的输出: [121,834s][info][gc] GC(657) Pause Initial Mark 191M-&gt;191M(485M) (121,831s, 121,834s) 3,433ms [121,835s][info][gc] GC(657) Concurrent Mark (121,835s) [121,889s][info][gc] GC(657) Concurrent Mark (121,835s, 121,889s) 54,330ms [121,889s][info][gc] GC(657) Concurrent Preclean (121,889s) [121,892s][info][gc] GC(657) Concurrent Preclean (121,889s, 121,892s) 2,781ms [121,892s][info][gc] GC(657) Concurrent Abortable Preclean (121,892s) [121,949s][info][gc] GC(658) Pause Young (Allocation Failure) 324M-&gt;199M(485M) (121,929s, 121,949s) 19,705ms [122,068s][info][gc] GC(659) Pause Young (Allocation Failure) 333M-&gt;200M(485M) (122,043s, 122,068s) 24,892ms [122,075s][info][gc] GC(657) Concurrent Abortable Preclean (121,892s, 122,075s) 182,989ms [122,087s][info][gc] GC(657) Pause Remark 209M-&gt;209M(485M) (122,076s, 122,087s) 11,373ms [122,087s][info][gc] GC(657) Concurrent Sweep (122,087s) [122,193s][info][gc] GC(660) Pause Young (Allocation Failure) 301M-&gt;165M(485M) (122,181s, 122,193s) 12,151ms [122,254s][info][gc] GC(657) Concurrent Sweep (122,087s, 122,254s) 166,758ms [122,254s][info][gc] GC(657) Concurrent Reset (122,254s) [122,255s][info][gc] GC(657) Concurrent Reset (122,254s, 122,255s) 0,952ms [122,297s][info][gc] GC(661) Pause Young (Allocation Failure) 259M-&gt;128M(485M) (122,291s, 122,297s) 5,797ms 注意：CMS收集器的输出(GC标识657)与小规模收集的输出(GC标识658、659和660)穿插在一起；通常，会有多次小规模收集发生在并发收集周期中。初始标记暂停(Pause Initial Mark)表示并发收集周期的开始。以Concurrent为开头的行表示并发阶段的开始和结束。Pause Remark是备注暂停。前面没有讨论预清洗阶段。预清洗是指在准备备注暂停阶段可以同时完成的工作。最后阶段由并发重置指示(Concurrent Reset)，并为下一个并发收集做准备。 初始标记暂停通常相对于小规模收集暂停时间较短。并发阶段(并发标记、并发预清洗和并发清除)通常持续的时间比小规模收集暂停时间长得多，如CMS收集器输出示例所示。但是，请注意，在这些并发阶段，应用程序不会暂停。备注暂停的长度通常相当于一次小规模收集。备注暂停受某些应用程序特征(例如，对象修改率提高会增加暂停)和自上次小规模收集以来的时间(例如，新生代中的更多对象可能会增加暂停)的影响。 9 垃圾优先收集器本节介绍垃圾优先(G1)收集器。 本节主题： 垃圾优先收集器简介 启用垃圾优先收集器 基本概念 堆布局 垃圾收集周期 深入垃圾优先收集器内部 确定初始堆占用率 标记 堆资源紧张下的行为 大对象 纯新生代收集阶段规模 空间回收阶段收集规模 G1的工程学默认值 与其他收集器的对比 垃圾优先收集器简介垃圾优先(G1)收集器针对具有大量内存的多处理器机器。它试图高概率地达到垃圾收集暂停时间目标，同时无需配置就能实现高吞吐量。G1旨在利用应用程序和环境在延迟和吞吐量之间实现最佳平衡，这些应用程序和环境的功能包括: 堆大小高达几十GB或更大，超过50%的Java堆被存活数据占据。 随着时间的推移，对象分配和升级的速率可能会有很大变化。 堆中有大量碎片。 可预测的暂停时间，不超过几百毫秒，避免长时间的垃圾收集暂停。 G1取代了并发标记清除(CMS)收集器。它也是默认的收集器。 G1采集器实现了高性能，并试图通过以下几节中描述的几种方式来实现暂停时间目标。 启用垃圾优先收集器垃圾优先垃圾收集器是默认收集器，因此通常您不必执行任何额外的操作。您可以通过在命令行上提供-XX:+UseG1GC来显式启用它。 基本概念G1是一个分代的、渐进的、并发的、疏散垃圾收集器，它监控每次stop-the-world暂停中的暂停时间目标。与其他收集器一样，G1将这堆分成(虚拟的)新生代和老年代。空间回收工作集中在最有效的新生代，而老年代偶尔才会进行空间回收。 为了提高吞吐量，有些操作总是在stop-the-world时执行。其他操作(如全局标记等整体堆操作)可能需要更多时间将与应用程序并行执行。为了让空间回收时stop-the-world的时间更短，G1逐步并行地进行空间回收。G1通过跟踪关于先前应用程序行为和垃圾收集暂停的信息来建立相关成本的模型，从而实现可预测性。它使用这些信息来调整暂停中完成的工作。例如，G1首先回收最高效区域的空间(即大部分被垃圾填满的区域，因此得名)。 G1主要通过疏散来回收空间:将选定存储区域中的存活对象复制到新的存储区域中，在这个过程中对它们进行压缩。疏散完成后，先前由存活对象占据的空间将重新分配给应用程序。 垃圾优先收集器不是实时收集器。它试图在更长的时间内高概率地达到设定的暂停时间目标，但对于给定的暂停并不总是能达到的。 堆布局G1将堆分成一组大小相等的堆区域(region)，每个区域都是一个连续的虚拟内存范围，如图9-1所示。区域是内存分配和内存回收的单位。在任何给定的时间，这些区域中的每一个都可以是空的(浅灰色)，或者分配给特定的一代，新生的或老年的。当内存请求进来时，内存管理器会分配空闲区域。内存管理器将它们分配给一代，然后将它们作为空闲空间返给应用程序，应用程序可以将它们分配给自己。 新生代包含eden区域(红色)和survivor区域(红色带“S”)。这些区域提供了与其他收集器中连续空间相同的功能，不同之处在于，在G1，这些区域通常在内存中以不连续的模式排列。(浅蓝色)组成了老年代。对于跨越多个区域的对象，老年代区域可能非常大(浅蓝色，带“H”)。 一个应用程序总是先分配给新生代，也就是eden区域，除了那些被直接分配给老年代的巨大对象。 垃圾收集周期在高层次上，G1收集器在两个阶段之间交替。纯年轻阶段(young-only)包含垃圾收集，这些垃圾收集逐渐用老年代中的对象填充当前可用的内存。空间回收阶段(space-reclamation)，G1除了处理新生代的事务外，还逐步回收老年代的空间。然后，循环从一个纯新生代的阶段重新开始。 图9-2给出了这个循环的概述，并举例说明了可能发生的垃圾收集暂停序列: 下面的列表详细描述了G1垃圾收集周期的各个阶段、它们的暂停以及各个阶段之间的过渡: 纯年轻阶段:这个阶段从几个普通的收集开始，这些收集将对象升级到老年代。纯年轻阶段和空间回收阶段之间的过渡开始于老年代占用率达到某个阈值(启动堆占用率阈值)时。此时，G1计划启动并发新生代收集(Concurrent Start young collection)，而不是普通新生代收集(Normal young collection)。 并发开始(Concurrent Start):这种类型的收集除了执行普通的收集之外，还开始标记过程。并发标记决定了老年代中所有当前可达(活动)的对象将被保留到下一个空间回收阶段。普通的新生代收集可能会出现在标记尚未完成时。标记结束时有两个特殊stop-the-world暂停:备注(Remark)和清理(Cleanup)。 备注(Remark)：这种暂停完成标记本身，执行全局引用处理和类卸载，回收完全空的区域并清理内部数据结构。在“备注”和“清理”之间，G1计算能够同时回收的选定老年代区域可用空间，这将在“清理”暂停中完成。 清理(Cleanup)：这一暂停决定了空间回收阶段是否会真正到来。如果随后是空间回收阶段，则纯年轻阶段将以一个有准备的混合新生代收集来完成。 空间回收阶段：该阶段包括多个混合收集，除新生代区域外，还疏散老年代区域集合中的活动对象。当G1确定疏散更多的老年代空间性价比不高时，空间回收阶段就结束了。 空间回收后，收集周期从另一个纯年轻阶段重新开始。作为备份，如果应用程序在收集活动信息时耗尽内存，G1会像其他收集器一样执行一次就地完整堆压缩(完整垃圾收集, Full GC)。 垃圾收集暂停和收集集合G1在stop-the-world暂停时进行垃圾收集和空间回收。存活对象通常从源区域复制到堆中的一个或多个目标区域，并调整对这些移动对象的现有引用。 对于非大型区域，对象的目标区域由该对象的源区域确定: 新生代的对象(eden和survivor区域)被复制到survivor或老年代，这取决于他们的年龄。 老年代区域的对象被复制到其他老年代区域。 巨大区域中的对象被区别对待。G1只决定他们的活跃度，如果它们死掉，收回它们占据的空间。大区域内的物体不会被G1移动。 收集集合是要从中回收空间的源区域集。根据垃圾收集的类型，收集集合由不同类型的区域组成: 在纯年轻阶段，集合仅由新生代中的区域和具有潜在可回收对象的巨大区域组成。 在空间回收阶段，由新生代的区域、具有潜在可回收对象的巨大区域以及收集组候选区域中的一些老年代区域组成。 G1在并发周期中准备垃圾收集的候选区域。在备注暂停期间，G1选择占用空间占用低的区域，这些区域包含大量可用空间。然后，在“备注”和“清理”暂停之间同时准备这些区域，以便以后收集。清理暂停会根据效率对其进行排序。在随后的混合收集中，优先选择包含更多空闲空间的高效区域，这些区域收集时间更少。 深入垃圾优先收集器内部本节描述了垃圾优先(G1)垃圾收集器的一些重要细节。 确定初始堆占用率G1在调整Java堆的大小时遵守标准规则，使用-XX:InitialHeapSize作为最小Java堆大小，-XX:MaxHeapSize作为最大Java堆大小，-XX:MinHeapFreeRatio代表最小可用内存比率，-XX:MaxHeapFreeRatio用于确定调整大小后最大可用内存百分比。G1收集器在备注暂停和完整收集中调整Java堆的大小。此过程可能会向操作系统返还内存或从操作系统分配内存。 纯新生代收集规模G1总是在下一个突变阶段的普通新生代收集结束时对新生代进行评估。通过对实际暂停时间长时间的观察，G1可以达到-XX:MaxGCPauseTimeMillis和-XX:PauseTimeIntervalMillis设置的暂停时间目标。它会考虑相似大小的新生代疏散需要多长时间。这包括在收集过程中需要复制多少对象，以及这些对象之间的关联程度等信息。 如果没有其他约束，那么G1自适应地将年轻一代的大小调整在-XX:G1NewSizePercent和-XX:G1MaxNewSizePercent设定的暂停时间之间。有关如何修复长暂停的更多信息，请参见垃圾优先垃圾收集器优化。 或者，-XX:NewSize与-XX:MaxNewSize的组合可以分别用于设置最小和最大新生代大小。 空间回收阶段收集规模在空间回收阶段，G1试图在一次垃圾收集暂停中最大化老年代回收的空间量。新生代的大小被设置为允许的最小值，通常由-XX:G1NewSizePercent决定。 在此阶段的每个混合收集开始时，G1从候选收集集合中选择一组区域。这组额外的老年代区域由三部分组成: 老年代区域的最小集合，以确保疏散进度。这组老年代区域由候选区域的数量除以空间回收阶段的长度决定，空间回收阶段的长度由-XX:G1MixedGCCountTarget决定。 如果G1预测在收集完上述最小集合后还会有时间，则收集集合中的其他老年代区域将成为候选区域。添加老年代区域，直到预计将使用80%的剩余时间。 一组可选的收集集合区域，在上面两个部分被疏散后，G1会逐渐疏散这些集合区域，如果在此暂停中还有时间。 前两组区域在初始收集过程中收集，如有剩余的暂停时间再收集可选区域。由于可选集合的管理，这种方法确保了空间回收的进展，同时提高了达到暂停时间的概率，并且使开销最小。 当候选区域中的剩余可回收空间小于-XX:G1HeapWastePercent设定的值，空间回收阶段结束。 有关G1将使用多少老年代区域以及如何避免长时间混合收集暂停的更多信息，请参见垃圾优先垃圾收集器优化。 定期垃圾收集如果由于应用程序不活动而长时间没有垃圾收集，虚拟机可能会长时间保留大量未使用的内存，这些内存可能在其他地方使用。为了避免这种情况，G1可能会被迫使用-XX:G1PeriodicGCInterval选项进行常规垃圾收集。此选项确定G1考虑执行垃圾收集的最小时间间隔(毫秒)。如果自上次垃圾收集暂停后经过了这段时间，并且没有正在进行的并发循环，G1会触发额外的垃圾收集，可能会产生以下影响: 在纯年轻阶段:G1使用并发开始暂停(Concurrent Start)来开始并发标记，或者，如果指定了-XX:-G1PeriodicGCInvokesConcurrent，则为完整GC。 在空间回收阶段:G1会触发适合当前进度的垃圾收集暂停类型来继续空间回收阶段。 -XX:G1PeriodicGCSystemLoadThreshold选项可用于优化垃圾收集是否被触发:如果JVM主机系统(例如，容器)上的getloadavg()调用返回的平均一分钟系统负载值高于该值，则不会运行定期垃圾收集。 有关定期垃圾收集的更多信息，请参见JEP 346:立即从G1返回未使用的已提交内存。 确定初始堆占用率初始堆占用率(IHOP，Initiating Heap Occupancy Percent)是触发初始标记收集(Initial Mark)的阈值，定义为老年代大小的百分比。默认情况下，G1通过观察标记需要多长时间以及在标记周期中老年代通常分配多少内存来自动确定最佳IHOP。这一特性被称为自适应IHOP。如果此功能被激活，在没有足够的观察结果来对启动堆占用率阈值进行良好的预测时，选项-XX:InitiatingHeapOccupancyPercent将作为老年代大小的百分比的初始值。使用选项-XX:-G1UseAdaptiveIHOP关闭G1的此行为。在这种情况下，值-XX:InitiatingHeapOccupancyPercent决定这个阈值。 在内部，自适应IHOP尝试设置初始堆占用，以便当老年代占用处于当前最大老年代大小减去作为额外缓冲区的-XX:G1HeapReservePercent值时，开始空间回收阶段的第一次混合垃圾收集。 标记G1标记使用了一种叫做开始快照(Snapshot-At-The-Beginning，SATB)的算法。它在初始标记暂停时获取堆的虚拟快照，只要标记开始时活动的对象在标记的剩余时间都被认为是存活的。这意味着，为了空间回收的目的(除了一些例外)，在标记过程中变死(不可到达)的物体仍然被认为是活的。与其他收集器相比，这可能会导致一些额外的内存被错误地保留。然而，这可能会让SATB在备注暂停期间提供更好的时延。在该标记过程中过于保守考虑的活动对象将在下一个标记过程中被回收。有关标记问题的更多信息，请参见主题垃圾优先垃圾收集器优化。 堆资源紧张下的行为当应用程序占据如此多的内存以至于疏散无法找到足够的空间来复制时，就会发生疏散失败。疏散失败意味着G1只复制已经移动的对象到新位置来完成当前的垃圾收集，而不复制任何尚未移动的对象，只调整它们之间的引用。疏散失败可能会产生一些额外的开销，但通常和其他新生代收集一样快。在这次垃圾收集和疏散失败后，G1将恢复正常应用，没有任何其他措施。G1会假设疏散失败发生在垃圾收集接近结束时；也就是说，大多数对象已经被移动，并且还有足够的空间继续运行应用程序，直到标记完成和空间回收开始。 如果这个假设不成立，那么G1最终将安排一个完整垃圾收集。这种类型的收集对整个堆执行就地压缩。这可能很慢。 请参阅垃圾优先垃圾收集器优化，了解有关分配失败或在发出内存不足信号之前发生完全垃圾收集器故障的更多信息。 大对象大对象是大于或等于半个区域大小的对象。除非使用-XX:G1HeapRegionSize选项进行设置，否则当前区域大小是按照G1工效学默认值部分中所述进行的。 这些大对象有时会被特殊对待: 在老年代中，每个大对象都被分配为一系列连续的区域。对象本身的起点总是位于序列中第一个区域的起点。在整个对象被回收之前，序列最后一个区域中的任何剩余空间都不会被分配。 一般来说，只有在清理暂停(Cleanup)期间标记结束时，或者在完整垃圾收集期间大对象无法访问的情况下，才会回收大对象。然而，对于原始类型数组(例如bool、各种整数和浮点值)的大对象有一个特殊的规定。如果在任何垃圾收集暂停期间，这样的大对象没有被多个对象引用，G1将会回收它。这种行为默认是启用的，你可以使用-XX:G1EagerReclaimHumongousObjects禁用它。 大对象的分配可能会导致垃圾收集过早发生。G1在每个大对象分配中检查初始堆占用率阈值，如果当前占用率超过该阈值，可能会立即强制进行初始的新生代垃圾收集标记。 大对象从不移动，即使在完整的垃圾收集也是如此。这可能会导致过早的慢速完整垃圾收集或大量区域空间碎片而导致的内存不足情况。 G1的工程学默认值本主题概述了G1特有的最重要的设置及其默认值。他们给出了没有附加选项G1的预期行为和资源使用的粗略概述。 选项和默认值 描述 -XX:MaxGCPauseMillis=200 最大暂停时间 -XX:GCPauseTimeInterval=&lt;ergo&gt; 最大暂停时间间隔。默认情况下，G1没有设定任何值，允许G1在极端情况下连续收集垃圾。 -XX:ParallelGCThreads=&lt;ergo&gt; 垃圾收集期间用于并行工作的最大线程数。规则如下:如果进程可用的CPU线程数少于或等于8，使用相等的线程数。否则，为线程数的5/8。在每次暂停开始时，使用的最大线程数还会受到总的堆大小的限制:每个-XX:HeapSizePerGCThread不会多于一个线程。 -XX:ConcGCThreads=&lt;ergo&gt; 用于并发工作的最大线程数。默认情况下，该值为-XX:ParallelGCThreads除以4。 -XX:+G1UseAdaptiveIHOP -XX:InitiatingHeapOccupancyPercent=45 控制初始堆占用率的默认值，表示自适应IHOP已打开，并且在最初的几个收集周期中，G1将使用45%作为老年代标记开始的阈值。 -XX:G1HeapRegionSize=&lt;ergo&gt; 堆区域大小。堆包含大约2048个堆区域。堆区域的大小可以从1到32 MB不等，必须是2的幂。 -XX:G1NewSizePercent=5-XX:G1MaxNewSizePercent=60 新生代总的大小，在这两个值之间，总的堆空间的百分比。 -XX:G1HeapWastePercent=5 候选收集集合未回收空间的百分比。如果候选集合中的可用空间低于该值，G1将停止空间回收阶段。 -XX:G1MixedGCCountTarget=8 空间回收阶段的预期长度。 -XX:G1MixedGCLiveThresholdPercent=85 在空间回收阶段，不会收集存活对象占用率高于这个百分比的老年代区域。 注意：&lt;ergo&gt;意味着实际值是根据环境确定的。 与其他收集器的对比这里总结一下G1和其他收集齐之间主要区别: 并行收集器将老年代空间作为一个整体来压缩和回收。G1逐渐将这项工作分解为多个更小的垃圾收集工作。这大大缩短了暂停时间，但这可能会牺牲吞吐量 和CMS收集器类似，G1并发的执行老年代空间的收集。然而除非进行完整垃圾收集，CMS不能整理老年代的碎片。 由于其并发性，G1的开销可能高于上述收集器，进而影响吞吐量。 ZGC的目标是特大型堆，旨在牺牲更高的吞吐量来提供更短的暂停时间。 由于其工作原理，G1有一些独特的机制来提高垃圾收集效率: 在任何收集过程中，G1都可以回收一些空的老年代空间。这可以避免许多其他不必要的垃圾收集，轻易就可以释放大量空间。 G1可以选择性的消除堆上的重复字符串。 从老一代回收空的大对象默认是启用的。您可以使用选项-XX:-G1EagerReclaimHumongousObjects禁用此功能。默认情况下，字符串重复数据消除处于禁用状态。您可以使用选项-XX:+G1EnableStringDeduplication来启用它。 10 垃圾优先垃圾收集器优化本节描述了如何在垃圾优先垃圾收集器(G1垃圾收集器)不符合您的要求的情况下调整它的行为。 本节主题： 对G1的一般性建议 从其他收集器迁移到G1 改进G1的性能 观察完整垃圾收集 大对象碎片 时延优化 异常系统或实时使用 引用对象处理时间过长 纯年轻阶段纯新生代垃圾收集时间过长 混合收集时间过长 更新记忆集和扫描记忆集时间过高 吞吐量优化 堆的大小优化 默认值优化 对G1的一般性建议一般建议使用G1的默认设置即可，然后给它一个不同的暂停时间设置，并根据需要使用-Xmx设置最大的Java堆大小。 与其他收集器不同，G1的默认值做了不同的平衡。默认配置中，G1的目标既不是最大吞吐量，也不是最低时延，而是在高吞吐量下提供相对较小、均匀的暂停。然而，G1递增式的空间回收机制和暂停时间控制会在应用程序线程和空间回收效率方面产生一些开销。 如果您想要高吞吐量，那么可以使用-XX:MaxGCPauseMillis来放宽暂停时间目标，或者提供一个更大的堆。如果时延是主要要求，则修改暂停时间设置。避免使用-Xmn，-XX:NewRatio等选项将新生代的规模限制在特定值，因为新生代的规模是G1用来满足暂停时间的主要手段。将新生代的大小设置为固定值会覆盖并实际上禁用暂停时间控制。 从其他收集器迁移到G1通常，当从其他收集器(尤其是CMS收集器)迁移到G1时，首先要删除所有影响垃圾收集的选项，只需要设置暂停时间以及使用-Xmx和可选的-Xms设置总堆大小。 对于其他收集器，许多选项对其响应很有用，但它们对于G1起来说，要么根本不起作用，要么甚至降低吞吐量和达到暂停时间目标的可能性。一个例子是设定新生代的规模，这完全阻止了G1调整新生代的规模以达到设置的暂停时间目标。 改进G1性能G1旨在提供良好的整体性能，而无需指定其他选项。然而，有些情况下，默认的启发式方法或默认配置效果可能不是最优的。本节给出了一些诊断和改善这些情况的指南。本指南仅描述了在给定一组应用程序的情况下，G1在给定指标下提高垃圾收集器性能的可能性。在具体案例上，应用程序级优化可能比试图调整虚拟机性能更好更有效，例如，通过使用寿命较短的对象完全避免一些有问题的情况。 出于诊断目的，G1提供全面的日志。一个好的开始是使用-Xlog:gc*=debug选项，然后在必要时从中提炼输出内容。日志提供了关于垃圾收集活动暂停期间和暂停之外的详细概述。这包括收集的类型和在暂停的特定阶段花费的时间的细节。 以下小节探讨了一些常见的性能问题。 观察完整垃圾收集完整堆垃圾收集(Full GC)通常非常耗时。老年代占用率过高导致的完整收集可以在日志中查找单词”Pause Full (Allocation Failure)”得到。完整收集通常紧跟在一个”to-space exhausted”标签标示的垃圾收集之后。 发生完整垃圾回收的原因是应用程序分配了太多无法快速回收的对象。通常并发标记不能及时完成，以开始空间回收阶段。许多大对象的分配可能会增加进入完整收集的可能性。由于这些对象在G1的分配方式，它们可能会占用比预期多得多的内存。 目标应该是确保并发标记按时完成。这可以通过降低老年代的分配率或者给并发标记更多的时间来完成。 G1给了你几个选项来更好地处理这种情况: 您可以使用gc+heap=info日志来确定Java堆上大对象占据的区域数量。”Humongous regions: X-&gt;Y”行中的Y表示大对象占据的区域数量。如果与老年代的数量相比，该数较高，最好的选择是尝试减少区域的数量。您可以通过使用-XX:G1HeapRegionSize选项增加区域大小来实现这一点。当前选择的堆区域大小打印在日志的开头。 增加Java堆的大小。这通常会增加标记完成的时间。 通过显式设置-XX:ConcGCThreads，增加并发标记线程的数量。 迫使G1提前开始标记。G1根据应用程序行为自动确定IHOP阈值。如果应用程序行为改变，这些预测可能是错误的。有两种选择:通过修改-XX:G1ReservePercent来增加自适应IHOP计算中使用的缓冲区，从而降低何时开始空间回收的目标占用率；或者，通过使用-XX:-G1UseAdaptiveIHOP和-XX:InitiatingHeapOccupancyPercent手动设置IHOP的阈值。 除了内存分配失败完整收集通常是由应用程序或某个外部工具导致的。如果原因是System.gc()，并且没有办法修改应用程序源码，则可以通过使用-XX:+ExplicitGCInvokesConcurrent或通过设置-XX:+DisableExplicitGC让虚拟机完全忽略它们来减轻完整收集的影响。外部工具可能仍然会强制完整垃圾收集，不用它们的时候就把它们删除。 大对象碎片为了寻找连续区域，完整垃圾收集可能会在堆内存耗尽之前就进行。一个潜在的选项是提高-XX:G1HeapRegionSize的值，从而降低大对象占用的区域数，或者增加堆的整体大小。在极端情况下，即使可用内存足够G1却找不到充足的连续区域，这将会导致虚拟机退出。因此，除了前面提到的减少大对象分配或者增加堆之外，没有其他选择。 时延优化本节讨论了在常见时延问题(即暂停时间过高)的情况下如何改善G1行为。 异常系统或实时使用对于每一次垃圾收集暂停，gc+cpu=info日志输出都包含一行包含来自操作系统的信息，并附有垃圾收集时间明细。这种输出的一个例子是User=0.19s Sys=0.00s Real=0.01s。 用户时间(User)是在虚拟机代码中花费的时间，系统时间(Sys)是在操作系统中花费的时间，实时(Real)是在暂停期间经过的绝对时间量。如果系统时间相对较长，那么最常见的原因是环境。 系统时间过高的常见原因： 虚拟机从操作系统内存分配或返还内存可能会导致不必要的时延。通过使用选项-Xms和-Xmx将最小和最大堆大小设置为相同的值，并使用-XX:+AlwaysPreTouch预接触所有内存，将此工作移到虚拟机启动阶段，从而避免延迟。 特别是在Linux中，通过透明大页面(THP)功能将小页面合并成大页面往往会拖延随机进程，而不仅仅是在垃圾收集暂停期间。因为虚拟机分配并维护大量内存，所以虚拟机成为长时间停顿的进程的风险比通常情况下要高。请参考操作系统文档，了解如何禁用透明大页面功能。 日志写入输出可能会暂停一段时间，因为一些后台任务会间歇性地占用日志写入的硬盘的输入/输出带宽。考虑为日志或其他存储使用单独的磁盘，例如内存备份文件系统，以避免这种情况。 另一个需要注意的情况是实时比其他情况的总和大得多，这可能表明虚拟机在可能过载的机器上没有获得足够的CPU时间。 引用对象处理时间过长引用对象处理发生在引用处理阶段。在引用处理阶段，G1根据引用对象的类型更新引用。默认情况下，G1尝试使用以下启发式方法来并发进行引用处理:对于每-XX:ReferencesPerThread个引用对象启动一个线程，最多-XX:ParallelGCThreads个线程。默认情况下，可以通过将-XX:ReferencesPerThread设置为0来禁用此启发式算法，或者通过-XX:-ParallelRefProcEnabled完全禁用并行化。 纯年轻阶段纯新生代垃圾收集时间过长一般来说，任何新生代收集需要的时间大致与新生代的大小成比例，或者更具体地说，与其中需要复制的存活对象数量成比例。如果疏散收集(Evacuate Collection Set)花费的时间太长，特别是对象复制子阶段(Object Copy)，则减少-XX:G1NewSizePercent。这减少了新生代的最小尺寸，停顿的时间可能更短。 如果应用程序性能，特别是幸存的对象数量突然改变，新生代的规模可能会导致垃圾收集暂停时间激增。通过使用-XX:G1MaxNewSizePercent来减小新生代的规模可能是有用的。这限制了新生代的最大尺寸，因此也限制了垃圾收集需要处理的对象数量。 混合收集时间过长混合收集用来回收老年代的空间。混合收集区域包含新生代和老年代区域。通过启用gc+ergo+cset=trace打印日志输出，您可以获得新生代或老年代区域的疏散时间对暂停时间的影响。分别查看新生代区域和老年代区域的暂停时间。 如果新生代时间太长，则查看上一节纯年轻阶段纯新生代垃圾收集时间过长。否则，为了减少老年代对暂停时间的贡献，G1提供了三种选择: 增加-XX:G1MixedGCCountTarget将垃圾收集扩散到更多的老年代区域 通过使用-XX:G1MixedGCLiveThresholdPercent，避面将占用率高的区域放入候选收集集合中。在许多情况下，高占用率的区域需要大量时间来收集。 尽早停止老年代的空间回收，这样G1就不会收集那么多高度占用的区域。在这种情况下，增加-XX:G1HeapWastePercent百分比。 请注意，后两个选项减少了当前空间回收阶段可回收空间候选区域的数量。这可能意味着G1可能无法在老年代中回收足够的空间用于持续运营。然而，稍后的空间回收阶段可能收集它们。 更新记忆集和扫描记忆集时间过高为了使G1能够疏散单个老年代区域，G1跟踪跨区域引用(cross-region references)的位置，即从一个区域指向另一个区域的引用。指向给定区域的跨区域引用集称为该区域的记忆集(remembered set)。移动区域内容时，必须更新记忆集。区域记忆集的维护大多是同时进行的。出于性能考虑，当应用程序的两个对象之间建立新的跨区域引用时，G1不会立即更新。记忆集更新请求会被延迟并批量处理以提高效率。 G1需要完整的记忆集进行垃圾收集，因此垃圾收集的更新记忆集(Update RS)阶段会处理任何未完成的更新请求。扫描记忆集(Scan RS)阶段会搜索记忆集中引用的对象，移动区域的内容，更新到新的引用位置。根据应用程序的不同，这两个阶段可能会花较长的时间。 使用选项-XX:G1HeapRegionSize调整堆区域的大小会影响跨区域引用的数量以及记忆集的大小。处理区域的记忆集可能是垃圾收集工作的一个重要部分，因此这对最大暂停时间有直接影响。较大的区域往往具有较少的跨区域引用，因此处理这些引用所花费的相对工作量会减少，尽管与此同时，较大的区域可能意味着每个区域要疏散更多的存活对象，从而增加了其他阶段的时间。 G1尝试并发处理记忆集的更新，更新阶段花费时间大概是最大暂停时间的-XX:G1RSetUpdatingPauseTimePercent。通过降低该值，G1通常会以更高的并发进行记忆集更新工作。 批量更新记忆集可能会导致记忆集更新与大对象分配合并在一起，从而造成虚假的更新时间过长。如果批处理正好发生在垃圾收集之前，那么就需要处理记忆集更新的所有工作。使用-XX:-ReduceInitialCardMarks禁用这种行为，潜在的避免这种情况。 记忆集扫描时间还取决于G1保存记忆集的压缩量。记忆集在内存中存储得越紧凑，在垃圾收集过程中检索存储值所需的时间就越长。G1自动执行这种压缩，称为记忆集粗化(coarsening)，同时根据该区域记忆集的当前大小更新记忆集。特别是在最高压缩级别，检索数据可能会非常慢。使用-XX:G1SummarizeRSetStatsPeriod选项和gc+remset=trace日志级别可以显示是否有粗化发生。如果是这样，那么在Before GC Summary之前部分中的Did &lt;X&gt; coarsenings行中X显示一个高值。增加-XX:G1RSetRegionEntries选项可以显著的降低粗化量。避免在生产环境中使用详细的记忆集日志记录，因为收集此数据可能会花费大量时间。 吞吐量优化G1的默认策略试图在吞吐量和延迟之间保持平衡；然而，有些情况下需要更高的吞吐量。除了如前所述减少总暂停时间之外，暂停的频率也可以减少。主要思想是通过使用-XX:MaxGCPauseMillis来增加最大暂停时间。分代大小启发式算法将自动调整新生代的大小，这直接决定暂停的频率。如果这没有导致预期的行为，特别是在空间回收阶段，使用-XX:G1NewSizePercent增加新生代的规模将迫使G1这样做。 在某些情况下，-XX:G1MaxNewSizePercent：允许的新生代最大规模，可以通过限制新生代规模来限制吞吐量。这可以通过查看gc+heap=info日志来诊断。在这种情况下，eden区域和survivor区域总的百分比接近于-XX:G1MaxNewSizePercent。在这种情况下，考虑增加-XX:G1MaxNewSizePercent的值。 增加吞吐量的另一个选择是尝试减少并发工作量。特别是，并发更新记忆集通常需要大量的CPU资源。增加-XX:G1RSetUpdatingPauseTimePercent将并发操作挪到垃圾收集阶段。在最糟糕的情况下，通过设置-XX:-G1UseAdaptiveConcRefinement -XX:G1ConcRefinementGreenZone=2G -XX:G1ConcRefinementThreads=0可以完全禁用这种机制，将记忆集更新工作挪到下一次垃圾收集。 通过使用-XX:+UseLargePages启用大页面也可以提高吞吐量。请参考操作系统文档，了解如何设置大页面。 将选项-Xms和-Xmx设置为相同的值，您可以通过禁用堆大小调整。此外，您可以使用-XX:+AlwaysPreTouch将操作系统工作放在虚拟机的启动时间，虚拟机使用物理内存支持的虚拟内存。为了使暂停时间更加一致，这两种方法都是特别理想的。 堆的大小优化和其他收集器一样，G1将调整堆的大小使垃圾收集所花费的时间低于-XX:GCTimeRatio选项所设定的比率。调整此选项，使G1符合您的要求。 默认值优化本节介绍了默认值和本主题中介绍的命令行选项的一些附加信息。 选项和默认值 描述 -XX:+G1UseAdaptiveConcRefinement-XX:G1ConcRefinementGreenZone=&lt;ergo&gt;-XX:G1ConcRefinementYellowZone=&lt;ergo&gt;-XX:G1ConcRefinementRedZone=&lt;ergo&gt;-XX:G1ConcRefinementThreads=&lt;ergo&gt; 并发记忆集更新使用这些选项来控制并发线程的工作分配。G1为这些选项选择符合工效学的值，使用-XX:G1RSetUpdatingPauseTimePercent设置垃圾收集暂停中剩余工作花费时间，根据需要自适应的调整。更改时务必小心，因为这可能会导致非常长的暂停时间。 -XX:+ReduceInitialCardMarks 初始对象分配中记忆集并发修改 -XX:+ParallelRefProcEnabled-XX:ReferencesPerThread=1000 -XX:ReferencesPerThread决定并发的程度：每N个引用有一个线程进行引用处理，线程数最多-XX:ParallelGCThreads。值为0表示始终使用-XX:ParallelGCThreads值所指示的最大线程数。这决定了java.lang.Ref.*实例的处理是否应该由多个线程并发完成。 -XX:G1RSetUpdatingPauseTimePercent=10 这决定了G1在记忆集更新时间占垃圾收集总时间的百分比。G1使用此设置控制记忆集更新并发的数量。 -XX:G1SummarizeRSetStatsPeriod=0 控制多少次垃圾收集生成记忆集摘要报告。将此设置为零以禁用。生成记忆集摘要报告是一项成本很高的操作，因此只有在必要时才应该使用，并且要把值设的高一些。使用gc+remset=trace打印所有内容。 -XX:GCTimeRatio=12 这是垃圾收集上的时间与应用程序的时间之比。用于确定垃圾收集中可以花费的时间的目标分数的实际公式是1 / (1 + GCTimeRatio)。该默认值将会导致有大约8%的时间用于垃圾收集。 -XX:G1PeriodicGCInterval=0 检查G1是否应该触发定期垃圾收集的时间间隔(毫秒)。设置为零禁用。 -XX:+G1PeriodicGCInvokesConcurrent 如果设置，定期垃圾收集会触发并发标记或继续现有收集周期，否则会触发完整垃圾收集。 -XX:G1PeriodicGCSystemLoadThreshold=0.0 触发定期垃圾收集的系统负载阈值，当前系统负载可以通过调用getloadavg()获得。高于此值的系统负载不会进行定期垃圾收集。零值表示此阈值检查被禁用。 注意：&lt;ergo&gt;意味着实际值是根据环境确定的。 11 Z收集器Z垃圾收集器(ZGC)是一个可扩展的低延迟垃圾收集器。ZGC并发执行所有代价高昂的工作，停止应用程序线程的时间不会超过10ms，这使得它适用于需要低时延和/或特大堆(几T字节)的应用程序。 Z垃圾收集器是一个实验特性，并通过命令行选项-XX:+UnlockExperimentalVMOptions -XX:+UseZGC启用。 设置堆大小ZGC最重要的调整选项是设置最大堆大小(-Xmx)。由于ZGC是一个并发收集器，因此必须按如下方法选择最大堆大小，1)堆可以容纳应用程序的存活对象，2)即使在垃圾收集运行时也有足够的堆空间分配给应用程序。需要多少空间在很大程度上取决于应用程序的分配速率和存活对象大小。总的来说，你给ZGC的内存越多越好。但与此同时，浪费内存是不可取的，所以这一切都是为了在内存使用和垃圾收集运行频率之间找到平衡。 设置垃圾收集的并发数第二个可能需要考虑的调整选项是设置并发GC线程的数量(-XX:ConcGCThreads)。ZGC有启发式算法自动选择这个数。这种启发式方法通常运行良好，但是根据应用程序的特点，这可能需要调整。这个选项本质上决定了应该给垃圾收集多少CPU时间。给它太多，垃圾收集器会从应用程序中窃取太多的CPU时间。给它太少，应用程序产生垃圾的速度可能会比垃圾收集速度快。 12 其他情况本节涵盖影响垃圾收集的其他情况。 本节主题： 弱引用、软引用和幻像引用的终结 显式垃圾收集 软引用 类元数据 弱引用、软引用和幻像引用的终结一些应用程序通过使用弱引用、软引用和幻像引用的终结(Finalization)来与垃圾收集交互。 这些特性可能在Java编程语言级别造成性能隐患。这方面的一个例子是依赖于终结来关闭文件描述符，这使得外部资源(描述符)依赖于垃圾收集的及时性。依靠垃圾收集来管理内存以外的资源几乎总是一个坏主意。 请参见如何处理Java终结的内存保留问题，其中深入讨论了终结的一些陷阱以及避免它们的技术。 显式垃圾收集应用程序与垃圾收集交互的另一种方式是使用System.gc()显式调用完整的垃圾收集。 这可能会在不必要的时候强制进行大规模垃圾收集(例如，当小规模收集就足够了)，因此通常应该避免。显式垃圾收集的性能影响可以通过使用标志-XX:+DisableExplicitGC禁用它们来衡量，这将导致虚拟机忽略对System.gc()的调用。 显式垃圾收集最常见的一种用途是远程方法调用(RMI)的分布式垃圾收集(DGC)。使用RMI的应用程序引用其他虚拟机中的对象。如果不偶尔进行本地堆的垃圾收集，就无法收集这些分布式应用程序中的垃圾，因此RMI会强制定期进行完整垃圾收集。这些收集的频率可以通过属性来控制，如下例所示: java -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.rmi.dgc.server.gcInterval=3600000 ... 本示例指定每小时一次显式垃圾收集，而不是默认的每分钟一次。但是，这也可能导致一些对象需要更长时间才能被回收。如果不希望对DGC活动的及时性有上限，可以将这些属性设为Long.MAX_VALUE，这样显式收集时间间隔实际上是无限的。 软引用软引用在服务器模式的虚拟机中保持活动的时间比在客户端模式的虚拟机长。 清除速率可以通过命令行选项-XX:SoftRefLRUPolicyMSPerMB=&lt;N&gt;来控制，该选项为每兆字节的可用堆空间一个软引用保持活动状态的毫秒数(ms)(一旦它不可达)。默认值为每兆字节1000毫秒，这意味着对于堆中每兆字节的可用空间，软引用将保留1秒钟(在收集到对象的最后一个强引用之后)。这是一个大概的数字，因为软引用仅在垃圾收集期间被清除，垃圾收集可能偶尔发生。 类元数据Java类在Java Hotspot虚拟机中有一个内部表示，称为类元数据。 在先前版本的Java Hotspot虚拟机中，类元数据是在所谓的永久代(permanent generation)中分配的。从JDK 8开始，永久代被删除，类元数据被分配到本机内存中。默认情况下，可用于类元数据的本机内存量不受限制。使用选项-XX:MaxMetaspaceSize设置类元数据的上限。 Java Hotspot虚拟机显式地管理元数据空间。从操作系统请求空间，然后将其分成块。类加载器从其块中为元数据分配空间(块绑定到特定的类加载器)。当为类加载器卸载类时，它的块会被循环使用或返回到操作系统。元数据使用mmap而不是malloc分配的空间。 如果-XX:UseCompressedOops已打开，并且-XX:UseCompressedClassesPointers已使用，则本机内存的两个逻辑上不同的区域将用于类元数据。-XX:UseCompressedClassPointers使用32位偏移量来表示64位进程中的类指针，就像-XX:UseCompressedOops用于Java对象引用一样。这些压缩的类指针(32位偏移量)将分配一个区域。区域的大小可以用-XX:CompressedClassSpaceSize设置，默认为1gb。压缩类指针的空间在初始化时被保留为-XX:mmap分配的空间，并根据需要提交。-XX:MaxMetaspaceSize用于确定提交的压缩类空间和其他类元数据的空间之和。 当相应的Java类被卸载时，类元数据被回收。垃圾收集可能会导致Java类卸载和元数据被回收。当为类元数据提交的空间达到某个级别(高水位线)时，就会引发垃圾收集。垃圾收集后，高水位线可能会根据从类元数据中释放的空间量而升高或降低。高水位线可能会升高，以免过早引发另一次垃圾收集。高水位线初值为命令行选项-XX:MetaspaceSize的值，并根据选项-XX:MaxMetaspaceFreeRatio和-XX:MinMetaspaceFreeRatio升高或降低。如果类元数据的申请空间中可用空间百分比大于-XX:MaxMetaspaceFreeRatio，则高水位线将会降低。如果它小-XX:MinMetaspaceFreeRatio，那么高水位线将会升高。 为选项-XX:MetaspaceSize指定一个高一些的值，以避免引发过早的垃圾收集。为应用程序分配的类元数据的数量取决于应用程序，并且不存在选择-XX:MetaspaceSize的一般准则。-XX:MetaspaceSize的默认大小取决于平台，范围从12 MB到20 MB不等。 关于元数据所用空间的信息包含在堆的日志输出中。以下是典型输出: [0,296s][info][gc,heap,exit] Heap [0,296s][info][gc,heap,exit] garbage-first heap total 514048K, used 0K [0x00000005ca600000, 0x00000005ca8007d8, 0x00000007c0000000) [0,296s][info][gc,heap,exit] region size 2048K, 1 young (2048K), 0 survivors (0K) [0,296s][info][gc,heap,exit] Metaspace used 2575K, capacity 4480K, committed 4480K, reserved 1056768K [0,296s][info][gc,heap,exit] class space used 238K, capacity 384K, committed 384K, reserved 1048576K 在以Metaspace开头的行中，used是用于加载类的空间量。capacity是当前分配块中元数据的可用空间。committed是块的可用空间量。reserved是为元数据保留(但不一定提交)的空间量。以class space开头的行包含压缩类指针的元数据相应值。 附录：主要中英文名词翻译对照表 英文 中文 Minor Collection 小规模垃圾收集 Major Collection 大规模垃圾收集 Young Generation 新生代 Old Generation 老年代 Ergonomics 工效学 The Mostly Concurrent Collectors 主要并发收集器 Full GC 完整垃圾收集 Young-only Phase 纯年轻阶段 Space-reclamation Phase 空间回收阶段","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"},{"name":"垃圾收集","slug":"垃圾收集","permalink":"https://pingao777.github.io/tags/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://pingao777.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"MySQL事务隔离小记","slug":"MySQL事务隔离小记","date":"2019-03-31T05:28:34.000Z","updated":"2020-09-12T03:14:00.583Z","comments":true,"path":"2019/03/31/MySQL事务隔离小记/","link":"","permalink":"https://pingao777.github.io/2019/03/31/MySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%B0%8F%E8%AE%B0/","excerpt":"大家都知道事务系统有四大特征：原子性、一致性、隔离性、持久性。隔离性是其中重要的一环，什么是隔离呢，顾名思义就是事务之间啥时候可见啥时候不可见，这就是MySQL的四个隔离级别： 未提交读（read uncommited） 提交读（read commited） 可重复读（repeatable read） 串行读（serializable）","text":"大家都知道事务系统有四大特征：原子性、一致性、隔离性、持久性。隔离性是其中重要的一环，什么是隔离呢，顾名思义就是事务之间啥时候可见啥时候不可见，这就是MySQL的四个隔离级别： 未提交读（read uncommited） 提交读（read commited） 可重复读（repeatable read） 串行读（serializable） 其实前两种从名字上就能理解什么意思，未提交读是事务没提交呢，别的事务就读到了，也就是可以读取事务的中间状态，即常说的脏读，这违反了事务的原子性和一致性；提交读呢，只有事务提交了，其他事务才可以读取，提交读解决了脏读问题却存在如下问题，比如A事务和B事务并行执行，假设A事务第一次读取了字段name是“小明”，这个时候B事务修改了name为“小红”，接下来A事务又读取了这个字段，发现“小明”变成了“小红”，“小明”去哪了，说好的隔离呢，这种问题被称为不可重复读，所以有时候提交读也称为不可重复读。 可重复读就是为解决不可重复读问题而出现的另一个隔离级别，也是MySQL的默认事务隔离级别。但是可重复读也不是完美无缺的，比如A事务和B事务同时执行，A先查找name字段为“小红”的记录发现没有，这时候B添加name为“小红”的记录，A又执行一次查询，发现有“小红”这条记录了，即所谓的幻行，A像产生了幻觉一样，这种问题被称为幻读。 串行读就是所有的事务串行化执行，看似完美解决了所有的问题，却付出了加锁同步的代价。 总结四种级别的问题矩阵： 隔离级别 脏读 不可重复读 幻度 加锁读 未提交读 是 是 是 否 提交读 否 是 是 否 可重复读 否 否 是 否 串行读 否 否 否 是 综合来看，第一种隔离级别太低违反了原子性和一致性，最后一种串行读效率太低在实际项目中鲜见使用，第二第三种都有一个幻读的问题，接下来看看MySQL如何解决这个问题。 MySQL使用了一种称之为多版本并发控制（MVCC）的机制，通过在每行记录后面保存两个隐藏列，一个保存了行的创建时间，一个保存了行的删除时间，这里的“时间”实际上是版本号，说到版本号你可能会猜测这应该是一种类似于乐观锁的并发控制机制，没错，MySQL就是通过这两个列实现了一种乐观锁。每当开始一个事务，系统版本号自动递增，事务开始的版本号作为事务的版本号，下面分别看看各种操作下这两个版本号是如何控制并发的。 查询操作（select）时，读取创建时间小于等于事务版本且删除时间未定义或大于事务版本的那些行，翻译成人话就是只读取本次事务添加或之前就存在，并且至少截止到本次事务还没有删除的那些记录。 插入时（insert），行的创建时间设置为当前系统版本号。 删除时（delete），删除时间设为系统版本号。 修改时（update），将当前版本号作为新行的创建时间和旧行的删除时间，可见修改相当于删除和插入两个动作。 回过头看上面A第二次读取时如果按这种方式就不会出现幻行，因为A只会读取A之前就存在和A自身插入的行。但是MVCC如果工作在提交读的情况下，不就没法读取新提交的记录了，这与提交读的语义不是矛盾了？ 带着这个疑问去看MySQL官方说明，原来MySQL有一个consistent read的概念，MySQL通过快照（snapshot）给每个事务返回结果，在可重复读的情况下快照由本事务第一次读取操作决定，也就是快照在第一次读取操作时就定了（本事务如果更新或删除其他事务提交的记录将会更新快照），而提交读事务每次读取都会更新快照。那么问题来了，快照是如何生成的呢？其实MySQL增加的两列不是上面所述的“创建时间”和“删除时间”，而是DB_TRX_ID，即最后一个对本行进行操作的事务版本号，另一个是DB_ROLL_PTR，称为滚动指针，它指向undo log，undo log中包含了恢复到未修改前数据的必要信息，比方说insert了一条记录，undo log里就存上一条delete。MySQL就是利用这两个隐藏列和undo log来构建快照的，下面以一个简单的示例说明一下，假设当前隔离级别为可重复读： 事务1首先insert一条name为小红的记录，undo log里插入一条delete记录：事务：1：delete 小红，DB_TRX_ID为事务版本号：1，DB_ROLL_PTR指向undo log的第1条记录 事务2执行select name=小红操作，由于DB_TRX_ID小于当前事务版本2，所以小红这条记录对事务2可见，最终小红这条记录返回 在事务2执行过程中，事务3将小红更新成了小明，DB_TRX_ID需要更新成最新的事务版本号3，DB_ROLL_PTR指向undo log的第2条记录：事务：3：update 小明-&gt;小红 事务2又执行select name=小红操作，由于DB_TRX_ID大于2，也就是在当前事务之后修改的，所以需要借助undo log回滚构建快照（不是真正的回滚），执行DB_ROLL_PTR指向的记录：update：事务：3：update 小明-&gt;小红，name由小明变为小红，执行select语句还是返回这条记录 当然MySQL真正的实现肯定比这复杂的多，这只是我根据看到的文档抽象的一个简化模型。 参考资料： 高性能MySQL Consistent Nonlocking Reads InnoDB Multi-Versioning","categories":[{"name":"三言两语","slug":"三言两语","permalink":"https://pingao777.github.io/categories/%E4%B8%89%E8%A8%80%E4%B8%A4%E8%AF%AD/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://pingao777.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"MySQL","slug":"MySQL","permalink":"https://pingao777.github.io/tags/MySQL/"}]},{"title":"万锁之母AbstractQueuedSynchronizer","slug":"万锁之母AbstractQueuedSynchronizer","date":"2019-03-12T07:55:02.000Z","updated":"2020-09-12T03:14:00.585Z","comments":true,"path":"2019/03/12/万锁之母AbstractQueuedSynchronizer/","link":"","permalink":"https://pingao777.github.io/2019/03/12/%E4%B8%87%E9%94%81%E4%B9%8B%E6%AF%8DAbstractQueuedSynchronizer/","excerpt":"翻看Java“锁”记中提到的各种“锁”，其内部同步实现大多数都和一个类AbstractQueuedSynchronizer相关，这个类称得上“万锁之母”，所以今天就来扒一扒这个类。","text":"翻看Java“锁”记中提到的各种“锁”，其内部同步实现大多数都和一个类AbstractQueuedSynchronizer相关，这个类称得上“万锁之母”，所以今天就来扒一扒这个类。 整体脉络为了避免一头扎进去纠缠于各种细节出不来，可以先从宏观上来看一下这个类。首先大家思考一个问题：什么是同步器？假如把线程比作车辆，同步器的角色和警察叔叔差不多，警察的做的事无非是在合适的时机指挥车辆走和停，同步器呢，也是在选择合适的时间调度线程阻塞和执行。 对于车辆来说，什么时候走什么时候停呢，警察叔叔给你招手的时候啊，来来来小伙子，否则就老老实实排队，等警察叔叔给你招手；对于线程来讲也可以采用这种策略，获得许可可以执行，否则排队阻塞，等同步器给与你许可。如果前方交通比较疏松，警察可能一次会叫好几辆车一起走，如果比较拥堵，则会一辆一辆的来；同步器呢同样如此，它有两种模式：共享和独占，前者允许多个线程一起运行，后者只允许单一线程运行。 如果用伪代码表示上面的逻辑可能是这样子的： // 获得许可 while (不允许获得许可) &#123; 线程排队 停止执行 &#125; 从队伍里出来继续执行 // 释放许可 if (允许释放许可) &#123; 释放许可 叫醒排队的线程 &#125; 经过上面的分析大致可以提炼出同步器要解决这么几点： 许可怎么获取和释放 线程采用什么方法停止和继续执行 对于不能立马获得许可的线程得有排队机制 源码分析说是源码分析其实是自己在学习AbstractQueuedSynchronizer源码的一些学习笔记，并不是完整的源码分析。相信想了解AbstractQueuedSynchronizer运行机制的人多多少少都看过它的代码了，甚至看了一遍都不止，其实大部分代码一般人都能看懂，就是有那么几处难懂的代码，犹如芒刺在背不拔不快。本文就是为了这个目的而写的，并不是要面面俱到而是重点突破，给有心人一点启发。为了符合上下文的语义，下面描述的时候可能节点和线程交替使用，也会把阻塞停止，唤醒叫醒混用，大家留意就是了。 AbstractQueuedSynchronizer整体是利用模板模式，通过维护一个state变量状态配合tryAcquire，tryRelease以及tryAcquireShared，tryReleaseShared间接的影响许可获取和释放。 同步器使用CLH队列来维护排队的线程，CLH队列说白了就是一个单向链表，特性是后一个节点的状态是由前一个节点的状态决定的，每个节点都有一个pred指针指向前一个节点，AbstractQueuedSynchronizer在原生的CLH队列基础上进行了优化，加入了一个next指针，指向后继节点，用于提高寻找后继节点的性能，这就形成了一个双向链表。由于没有更新两个volatile的变量的CAS方法，所以next变量为null的时候并不表明没有后继节点，因为有可能一个节点入列的时候更新完pred指针，还没来得及更新next指针。具体结构如下： head和tail分别指向队列的头和尾，next我这里画成了虚线，表明其不可靠性。 AbstractQueuedSynchronizer的核心就是如何维护CLH队列的状态，所以我们把重点放在这一块。它提供了两套获取许可和释放许可的方法：acquire，release和acquireShared，releaseShared，分别对应独占和共享模式。下面分别看看这两套方法的签名： // 独占模式模板方法 public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; // 共享模式模板方法 public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 可以看到这两套方法是非常类似的，我们一个一个的看看，首先看看acquire方法： // acquire方法的逻辑粗看起来可能是先尝试获取下许可 // 如果成功，直接跳出，不用排队了； // 如果不成功就添加一个独占节点到队列中排队，如果 // 有中断响应中断，细节一个方法一个方法的进入看看 public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; // 尝试获取许可，成功返回true，这个方法没有实现 // 而是留给子类去实现，因为不同的锁获取和释放 // 许可的语义是不同的无法一概而论，所以交由 // 具体的子类去实现，这是典型的模板模式 // 之所以没有用抽象方法，是因为同步器 // 允许只实现独占和共享的一种，如果是 // 抽象方法，则需要实现两套模式的方法 protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; // 从名字上也可以看出这个方法就是往队伍里添加节点进行排队 private Node addWaiter(Node mode) &#123; // 以当前线程建立一个新的节点，准备插到队伍里 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 这句是原生英文注释，大意是先尝试快速的路径入队，如果失败 // 再用完整的入队方法，为什么这里是快呢？先别急，先往下看 Node pred = tail; // pred != null 说明队伍里已有排队者 if (pred != null) &#123; node.prev = pred; // 使用CAS操作将当前节点插到队伍里，注意这个时候可能 // 会有多个线程在同时往里插队，但是CAS操作能确保同一 // 时间只有一个线程会成功 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; // 这就是所谓的完整的入队方法 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 也就是队列还没有初始化呢，将head和 // tail都初始化为一个哑节点 if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 看这段代码是不是很眼熟了呢，对 // 这块和快速入队方法基本一样，对比快速和完整 // 两种入队方法，快速的没有初始化判断， // 少了循环，不会重试，相对来说会“快”点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; // 这个方法的大意是如果获得了许可，赶紧出队执行，否则告诉你的 // 前继节点轮到你时叫你，然后老老实实排队等待 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获得node的前继节点 final Node p = node.predecessor(); // 如果前继节点是头而且尝试获取许可成功 // 也就是轮到node出列执行了，即警察叔叔 // 给你招手了 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 这里是判断是否需要阻塞，需要的话就要调用 // park方法将线程歇一会，等unpark叫醒线程 // 的时候会检查中断状态，如果有中断就响应 // 中断 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 如果tryAcquire抛出异常 if (failed) cancelAcquire(node); &#125; &#125; // 这段代码的大意是节点node给前面的节点pred说哥们我先睡会，到站叫我，pred // 说好（设置为SIGNAL状态），到站之后叫你，你放心睡吧 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 如果前继节点的状态是SIGNAL，表明node已经告诉pred到站叫他， // 而且pred也已经答应了，所以node可以放心的去睡了 if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; // 这里是删除取消的节点，因为只有CANCEL的节点是大于0 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // node告诉pred到站叫它 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; // 这个方法很简单，没啥好说的，就是去睡觉，醒来 // 之后看看手机有没有人找你（中断） private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; acquire分析完了，再看看release // 如果释放许可成功，并且后面还有节点，叫醒它 // 返回 public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // 如果后面还有节点 // waitStatus会被设置成SIGNAL，忘记的话可以再 // 看看前面的shouldParkAfterFailedAcquire方法 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; // 叫醒后面的哥们一次 private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 如果ws小于0，也就是没有取消，将ws置位0 // 也就是打算叫醒后面的节点，同时把提醒 // 状态复位，免得叫醒多次 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 如果后面可能没节点了或者节点是取消的 // 就从后往前找，如果能找到紧随node之后 // 并且没有取消的节点就叫醒它。这里就是 // 利用next的优化了，即如果next不为空 // 且没有取消那么直接叫醒next，如果 // next为空，不能认定后面就没有节点了 // 因为next是不可靠的，要利用可靠的pred从后 // 往前找 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); &#125; 独占模式的获取和释放代码就分析完了，再来看看共享模式的。 public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; // 返回值小于0表示获取失败 // 等于0表示获取许可成功但是后面节点无法再获取了 // 大于0表示获取许可成功并且后面节点还可以再获取 protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; // 粗看doAcquireShared和acquireQueued非常相似， // 主要是两点不同，一是一个添加的是独占节点， // 一个添加的是共享节点，另一点不同是 // 一个是setHead，一个是setHeadAndPropagate private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; // 可以看到setHeadAndPropagate不光像独占模式那样修改了队列的头， // 还会在某些条件下调用一个doReleaseShared方法 private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); // 后续节点还有获取许可的机会或者节点没有取消 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 不知道s是什么类型或者s是共享节点 if (s == null || s.isShared()) doReleaseShared(); &#125; &#125; // 在并发的条件下叫醒队列头部的线程 private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 这部分代码和独占模式的release方法几乎一样 // 也是把队列头的线程叫醒继续执行，但要注意 // 一个重要区别是这里使用的是CAS操作，上面 // 独占不是，这是为什么呢？还记得独占和共享 // 的定义吗？对于共享模式多个线程同时执行 // 同时也有可能多个线程同时释放，所以必须 // 使用CAS操作保证线程安全 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; // 这个分支啥时候会满足呢？根据上面的分析在入队的时候 // 会调用shouldParkAfterFailedAcquire将前继节点的状态 // 修改为SIGNAL，这里为0应该发生在头节点没有后继节点 // 或者后继节点调用shouldParkAfterFailedAcquire // 还没返回的时候，再加上这个条件： // !compareAndSetWaitStatus(h, 0, Node.PROPAGATE) // 那么就剩下了一种情况：头结点的后继节点调用 // shouldParkAfterFailedAcquire还没把头节点 // 的状态修改成SIGNAL的时候。如果没有这个分支 // 只能等待下一次的doReleaseShared的调用才能 // 将头部的线程叫醒了 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 这句意思是头没变就跳出，那头啥时候变呢，就是出队的时候 // 也就是有线程已经出队，有责任叫醒新的头节点线程 if (h == head) // loop if head changed break; &#125; &#125; // 可以看到释放许可的主逻辑就是doReleaseShared // 上文已经分析过在此不再赘述 public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 运行图景经过上面的源码分析，估计大部分人心里有点数了，可能还形不成清晰的运行图景或者说直觉性的认识，那么接下来说下我自己的一点理解。 整个的图景是这样子的：对于独占模式，因为只有一个线程能获取许可，进而也只有一个线程释放许可，只会叫醒队伍头部的一个线程，这样整个队列是串行出列，并行入列，有点像排队坐公交，虽然队伍后面挤作一团，队伍前面还是有序的，一个一个的上车；对于共享模式而言，由于允许多个线程一起运行，也就是多个线程获得许可，同样也会有多个线程释放许可，这就需要叫醒队伍里多个线程，整个队列的样子是并行出列，并行入列。 忽略不必要的细节，来看看独占和共享模式下主逻辑的函数调用栈： 上图左边是独占模式的调用栈，右边是共享模式的调用栈。可以清晰看到为啥共享模式的可以唤醒多个节点，是因为它的调用栈形成了一个环，这样它就不会不停地叫醒后面的共享节点，就像一个连锁反应，并且获取许可和释放许可都会启动这个连锁反应；而独占模式没有形成环，叫醒一个节点就返回了，并且由于共享模式下获取和释放许可都会调用doReleaseShared，二者会形成竞争，这也是doReleaseShared内部使用CAS操作的一个原因。 参考资料： JAVA并发编程实战 Doug Lea, The java.util.concurrent Synchronizer Framework","categories":[{"name":"三言两语","slug":"三言两语","permalink":"https://pingao777.github.io/categories/%E4%B8%89%E8%A8%80%E4%B8%A4%E8%AF%AD/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://pingao777.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"分布式","slug":"分布式","permalink":"https://pingao777.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"}]},{"title":"Java“锁”记","slug":"Java“锁”记","date":"2019-03-07T06:12:29.000Z","updated":"2020-09-12T03:14:00.582Z","comments":true,"path":"2019/03/07/Java“锁”记/","link":"","permalink":"https://pingao777.github.io/2019/03/07/Java%E2%80%9C%E9%94%81%E2%80%9D%E8%AE%B0/","excerpt":"内置锁和显示锁内置锁其实是相对显示锁来说的，说白了内置锁就是synchronized所代表Java原生锁机制，Jdk5.0之后又引入了Lock及其子类ReentrantLock这样一种新的锁机制。从加锁和内存语义上二者一样，只不过后者添加了一些其他功能，可以实现诸如轮询锁、超时锁和中断锁的功能。","text":"内置锁和显示锁内置锁其实是相对显示锁来说的，说白了内置锁就是synchronized所代表Java原生锁机制，Jdk5.0之后又引入了Lock及其子类ReentrantLock这样一种新的锁机制。从加锁和内存语义上二者一样，只不过后者添加了一些其他功能，可以实现诸如轮询锁、超时锁和中断锁的功能。 public interface Lock &#123; void lock(); void lockInterruptibly() throw InterruptedException; boolean tryLock(); boolean tryLock(long timeout, TimeUnit unit) throw InterruptedException; void unlock(); Condition newCondition(); &#125; 如果内置锁是一个Lock的话，它只有lock()和unlock()方法。从锁的基本属性上说，内置锁和显示锁都是可重入的，内置锁是非公平的，显示锁还可以设置为公平的。 tryLock和lock的区别是前者获得锁返回true，获取不到返回false，都是立马返回，而后者如果获取不到将会阻塞到那里。 另外由于内置锁是自动释放，而显示锁必须手动释放，这就形成了显示锁的调用模式如下面这样： Lock lock = ...; lock.lock(); try &#123; // 逻辑 &#125; finally &#123; lock.unlock(); &#125; 也就是锁的释放必须放在finally中，确保锁可以释放。 从ReentrantLock衍生出来一个ReentrantReadWriteLock，为啥要有读写锁呢？其实是基于这样的原则，读写和写写是会引起线程安全问题的，所以都需要同步，前者是因为可见性，后者是因为一致性，但是读读是不需要同步的，所以讲读写拆分开来以提高性能。这就好比原来大家都排一个队，现在拆成两个队，自然排队等待的时间就短了。 闭锁闭锁就像一个门，等待一个“事件”开门（结束状态），在开门之前不允许任何人（线程）通过，在此之前大家只能在城门前面等待。只不过城门可以重复的开闭，闭锁只是一次性的。 具体到Java中，闭锁的实现就是CountDownLatch，它可以用来实现等待某种条件满足后才把线程放行的功能，比如资源就绪、服务启动、某个操作执行等等。 信号量信号量是用来控制同时访问某个资源的特定数量，或者同时执行某个操作的数量，有点像地铁中的限流。 从某种程度上讲，锁有点像一个二值的信号量，也就是初始值为1的信号量，不同之处是锁是可重入的，信号量不可。 栅栏栅栏和闭锁类似，它也能阻塞一组线程直到某个事件发生。区别在于栅栏要求线程都到达栅栏位置，才能继续执行，即所谓的闭锁等待的是事件，栅栏等待的是线程。如果对比现实中的例子，闭锁犹如大家去登山，商议好早晨8点出发，无论人齐不齐，到8点大家就出发，而栅栏就类似于大家登一段就在一个歇息点等一等人，等人齐再往上登。 原子变量原子变量实际上是一种乐观锁技术，即利用冲突检测来判断是否有来自其他线程的干扰，当进行修改操作时，先把变量的当前值current取出来，然后用一个原子的比较交换操作（CAS）对变量进行修改。有两种情况：如果变量的当前值还等于current说明这中间没有线程修改变量，修改变量值为新值；如果当前值不等于current了，说明中间有线程修改变量，重试。 以一个典型的count++为例，大家知道++这种操作实际上包括三步： 获取count当前值current 当前值加一newvalue 将newvalue赋值给count 如果两个线程同时修改count的值，假如两个线程的时序如下： =====1===========+1================= =========1===========+1============= 假设count的当前值为1，两个线程分别进行了++的操作，最后的值为2，第一个++操作被“覆盖”了。如果把上面2、3步换成一个CAS操作就不会发生上面的情况了，因为执行第二次操作时会拿count的旧值1和新值2对比，一对比发现不一样，说明其他线程修改了变量，这时候第二个线程会进入下一次的CAS操作，重新获取count值2，比较当前值2等于原来的值，修改为新值3。 原子变量作为一种非阻塞的锁技术，适用在读操作比较多、竞争不那么激烈的场景，这适用于大部分的业务场景。但同时原子变量也有其局限，原子锁只能保证单一变量的线程安全。","categories":[{"name":"三言两语","slug":"三言两语","permalink":"https://pingao777.github.io/categories/%E4%B8%89%E8%A8%80%E4%B8%A4%E8%AF%AD/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://pingao777.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"分布式","slug":"分布式","permalink":"https://pingao777.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"}]},{"title":"强烈推荐Andrew Ng的机器学习课程","slug":"强烈推荐Andrew-Ng的机器学习课程","date":"2019-01-21T10:11:07.000Z","updated":"2020-09-12T03:14:00.589Z","comments":true,"path":"2019/01/21/强烈推荐Andrew-Ng的机器学习课程/","link":"","permalink":"https://pingao777.github.io/2019/01/21/%E5%BC%BA%E7%83%88%E6%8E%A8%E8%8D%90Andrew-Ng%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/","excerpt":"从12.30到1.17修完了Coursera上的Andrew Ng的机器学习课程，计划上又可以划掉一件事了。 课程的主要内容大致如下： 监督学习：线性回归、逻辑回归、神经网络、支持向量机 非监督学习：K均值、主成分分析、异常检测 案例：垃圾邮件 特殊领域：推荐系统（协同过滤）、大规模机器学习（map-reduce） 方法论：偏差/方差问题、正则化、学习曲线、误差分析、如何收集样本数据、机器学习流水线、上限分析等等","text":"从12.30到1.17修完了Coursera上的Andrew Ng的机器学习课程，计划上又可以划掉一件事了。 课程的主要内容大致如下： 监督学习：线性回归、逻辑回归、神经网络、支持向量机 非监督学习：K均值、主成分分析、异常检测 案例：垃圾邮件 特殊领域：推荐系统（协同过滤）、大规模机器学习（map-reduce） 方法论：偏差/方差问题、正则化、学习曲线、误差分析、如何收集样本数据、机器学习流水线、上限分析等等 习题主要是两大类：选择题和编程题（matlab），选择题又分为单选和多选，只有答案没有解释，有些题难度还是有的。编程题自认为相对简单，只需了解简单的matlab编程和矩阵知识，上课好好听讲基本上就是满分。我的总成绩为98.4，编程题基本上100，选择题错了两个，想参考的可以戳这里。 课程用我自己的话总结就是：不装逼，说人话，循循善诱，详略得当。 记得Andrew Ng在讲到神经网络的反向传播算法时，花了大量的篇幅来介绍这一算法，尽管如此还是害怕有些学生不会影响自信心，他这样说道：作为多年的从业者，有时候猛然想起这个算法也得想好一会，这个算法不是那么直观。在讲到svm还是哪一课的时候，记不太清了，他又鼓励同学们：原理不懂也没有关系，事实上这些算法的原理直到最近我才搞明白，事实证明不了解算法的原理也能很好的使用它们。这一点比那些一瓶子不满半瓶子晃荡的老师强多了。 抛开老师的谦虚，在初学一样东西时，适当的忽略一些底层细节是一个很重要的学习方法。我发现不少同学包括我自己在学习机器学习的时候遇到一个算法，不由自主的想了解全部的数学细节，不这样心里就不踏实，以至于还没走到机器学习的门槛就已经倒在线性代数、概率论、数值分析的汪洋大海里了，其实这是一个本末倒置的学习方法。这就好比买了一辆汽车，难道你还要去修一门内燃机原理的课程？当然这不是鼓励大家囫囵吞枣，而是让大家抓住重点，不要把面铺的太广，否则收不回来。真正好的方法是学机器学习就把重点放在机器学习上，一些底层细节就当成既有的事实，等到学有余力再重点突破。所以学习的时候一定要控制自己那种无限扣细节的冲动。 另外一个其他课程没有或者很少提到的是这门课程Andrew Ng介绍了很多的机器学习方法论，比如学习曲线、误差分析、流水线、上线分析等等，这才是真正的金玉良言，可遇不可求的。众所周知，象棋的规则很简单，难的是如何开局，如何化解对手的攻势，如何一步一步积累自己的优势达到胜利，这些都是需要在实践中摸索，如果纯靠自己摸索，新手要走不少的弯路，而如果一开始别人把这些告诉你，你就可以事半功倍。 观察课程的主要内容可以看到这门课介绍的算法并不是很全面，比如常见的决策树、随机森林、贝叶斯算法等等都没有，有人可能觉得这是课程的缺点，我倒觉得这反而是优点，有道是一招鲜吃遍天，机器学习的算法是有固定的模式的，比如监督学习，基本上都是提出一个假设函数，然后去拟合现有数据，也就是生成一个代价函数，然后用数学方法找到使代价函数最小的参数，所以学会这些典型的算法再去学其他的算法没什么难度；另一个是影响机器学习性能的关键往往并不是算法本身而是你拥有的数据量、特征的选取、如何进行误差分析、如何进行模型的调优，这一点课程也有论述，我就不班门弄斧了。总之，这是一门我强烈推荐的课程，适合入门者进阶者。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://pingao777.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Coursera","slug":"Coursera","permalink":"https://pingao777.github.io/tags/Coursera/"}]},{"title":"2018年终总结","slug":"2018年终总结","date":"2019-01-01T09:59:47.000Z","updated":"2020-09-12T03:14:00.580Z","comments":true,"path":"2019/01/01/2018年终总结/","link":"","permalink":"https://pingao777.github.io/2019/01/01/2018%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","excerpt":"18年5月份的时候写了个中期计划，当时主要写了四件事： Coursera上Algorithms课程，现在已进行到上半部分第二周。 啃完计算机程序与构造，做一部分习题。 至少每隔一天跑一次步，身体革命本钱。 每周一篇博客，不限制长度。","text":"18年5月份的时候写了个中期计划，当时主要写了四件事： Coursera上Algorithms课程，现在已进行到上半部分第二周。 啃完计算机程序与构造，做一部分习题。 至少每隔一天跑一次步，身体革命本钱。 每周一篇博客，不限制长度。 这四件事目前看来只有1完成了，其他三件都没有完成。当时还说不要打脸，果然打脸了(/ □ \\)。我知道借口永远是逃避问题的最好方法，所以不打算找借口，计划没完成主因确实是自控力不够，所以只好不要脸的把没完成的计划放在19年了。新的计划为： Andrew Ng的机器学习学完，1月份 计算机程序与构造，2-4月份，三个月时间，习题尽量做 每周三次跑步，周五-周日，每天晚上 博客记得写，但最好有趣，有用 在执行计划的过程中，发现了一些计划太草率，所以进行了微调，比如“每周一篇博客，不限制长度”，在执行的过程中，发现想写一篇好的博客其实挺费心的，无病呻吟的文章又不想写，所以我稍微改了下，不要为了写而写。另外加了一条机器学习计划，因为人工智能确实越来越重要，自己对这方面也比较感兴趣。今年体检报告说肥胖，甘油三酯偏高，所以跑步这一条肯定需要更好的执行下去，但是在上年执行计划的时候，每隔一天的跑法受下班时间和下班状态影响比较大，所以我把时间调整到周末。 最后，祝大家新年快乐，心想事成吧~","categories":[{"name":"生活生活","slug":"生活生活","permalink":"https://pingao777.github.io/categories/%E7%94%9F%E6%B4%BB%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"2018","slug":"2018","permalink":"https://pingao777.github.io/tags/2018/"},{"name":"计划","slug":"计划","permalink":"https://pingao777.github.io/tags/%E8%AE%A1%E5%88%92/"},{"name":"2019","slug":"2019","permalink":"https://pingao777.github.io/tags/2019/"}]},{"title":"终于修完Algorithm了","slug":"终于修完Algorithm了","date":"2018-12-16T12:11:32.000Z","updated":"2020-09-12T03:14:00.591Z","comments":true,"path":"2018/12/16/终于修完Algorithm了/","link":"","permalink":"https://pingao777.github.io/2018/12/16/%E7%BB%88%E4%BA%8E%E4%BF%AE%E5%AE%8CAlgorithm%E4%BA%86/","excerpt":"磕磕绊绊，终于把Coursera上的Algorithm课修完了，中间有段时间中断了，因为工作太累，下班或者周末实在不愿意面对电脑了。Algorithm这门课整体难度不大，但是课时较长，所以需要能坚持下来。老师在理论和应用上做了比较好的平衡，不会太枯燥，不少习题也都是为了解决现实中的实际问题设计的，这点我非常喜欢，技术最终是为实际应用服务的，纯理论的东西确实提不起兴趣。","text":"磕磕绊绊，终于把Coursera上的Algorithm课修完了，中间有段时间中断了，因为工作太累，下班或者周末实在不愿意面对电脑了。Algorithm这门课整体难度不大，但是课时较长，所以需要能坚持下来。老师在理论和应用上做了比较好的平衡，不会太枯燥，不少习题也都是为了解决现实中的实际问题设计的，这点我非常喜欢，技术最终是为实际应用服务的，纯理论的东西确实提不起兴趣。 下面是本次课程的10次作业， Percolation Deques and Randomized Queues Collinear Points 8 Puzzle Kd-Trees WordNet Seam Carving Baseball Elimination Boggle Burrows–Wheeler 给我印象最深刻的是第八周的Baseball Elimination，这个作业的大概意思是根据棒球联赛积分表找出哪些球队已经被淘汰，说实话看过体育比赛的对这一点都是有感触的，有时候找出这样的球队不是那么容易，没想到在这里可以使用这么巧妙的一种方法解决，具体方法我就不剧透了。 这门课虽说修完了，但是自我感觉并不是里面的东西都理解了，甚至可以说是大部分都没有理解，或者说理解的不够深刻，那是不是白学了？肯定不是，我觉得最大的收获就是学到了一些问题有更好的解决方法这个事实，而不是解决方法本身，在上课之前可能某些问题我也知道一些方法，但都是一些笨办法，上完这门课相当于给了我一个更低的上界。总之，用大白话说就是增长了眼界。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Coursera","slug":"Coursera","permalink":"https://pingao777.github.io/tags/Coursera/"},{"name":"算法","slug":"算法","permalink":"https://pingao777.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"DrRacket使用技巧总结","slug":"DrRacket使用技巧总结","date":"2018-12-03T06:27:03.000Z","updated":"2020-09-12T03:14:00.580Z","comments":true,"path":"2018/12/03/DrRacket使用技巧总结/","link":"","permalink":"https://pingao777.github.io/2018/12/03/DrRacket%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/","excerpt":"引用其他文件的函数假设test.scm想引用max-two.scm中的一个函数max-two，可以这样， test.scm #lang sicp (#%require rackunit) (#%require &quot;max-two.scm&quot;) (max-two 2 3 4)","text":"引用其他文件的函数假设test.scm想引用max-two.scm中的一个函数max-two，可以这样， test.scm #lang sicp (#%require rackunit) (#%require &quot;max-two.scm&quot;) (max-two 2 3 4) max-two.scm #lang sicp ;; 千万别忘了这一句 (#%provide (all-defined)) (define (max-two x y z) (define (min-three x y z) (cond ((&gt;= x y) (if (&gt;= y z) z y)) (else (if (&gt;= x z) z x)))) (- (+ x y z) (min-three x y z))) Window10安装sicp包7.1版本ui界面安装pkg报错cadr: contract violation，可以使用命令行安装，命令如下： raco pkg install --auto sicp 从Vim中运行scheme程序可以做如下配置： augroup scheme autocmd! &quot; 加上&lt;esc&gt;可以避免弹出命令行必须按两次enter才能回到代码 autocmd filetype scheme nnoremap &lt;F9&gt; :w&lt;cr&gt;:! racket %&lt;cr&gt;&lt;esc&gt; augroup end 这样直接按下F9就能运行了","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"DrRacket","slug":"DrRacket","permalink":"https://pingao777.github.io/tags/DrRacket/"},{"name":"Lisp","slug":"Lisp","permalink":"https://pingao777.github.io/tags/Lisp/"}]},{"title":"Jsonp到底是个什么东西","slug":"JSONP到底是个什么东西","date":"2018-11-22T10:43:44.000Z","updated":"2020-09-12T03:14:00.581Z","comments":true,"path":"2018/11/22/JSONP到底是个什么东西/","link":"","permalink":"https://pingao777.github.io/2018/11/22/JSONP%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%AA%E4%BB%80%E4%B9%88%E4%B8%9C%E8%A5%BF/","excerpt":"这个世界上有好多事对你来说是模棱两可，可能是这样或者那样的原因你没有动力去了解它，以至于它久久萦绕在你的心头，Jsonp就是这么一件事。今天终于有动力想了解一番，经过一番热火朝天的谷歌百度后，发现Jsonp这东西说起来简单的很啊，我自己用一句话总结就是：使用script标签进行跨域访问。由于跨域请求返回的数据和JSON相关，故而得名Jsonp。","text":"这个世界上有好多事对你来说是模棱两可，可能是这样或者那样的原因你没有动力去了解它，以至于它久久萦绕在你的心头，Jsonp就是这么一件事。今天终于有动力想了解一番，经过一番热火朝天的谷歌百度后，发现Jsonp这东西说起来简单的很啊，我自己用一句话总结就是：使用script标签进行跨域访问。由于跨域请求返回的数据和JSON相关，故而得名Jsonp。 众所周知，javascript有同源策略的限制，是不允许跨域访问的，比如位于a.xxx.com下面的js代码， function print_log(json) &#123; console.log(json.name); &#125; var xhr = new XMLHttpRequest(); xhr.open(&#39;GET&#39;, &#39;http://b.xxx.com/test?callback=print_log&#39;, true); 假设/test?callback=print_log接口的返回值为： print_log(&#123;&quot;name&quot;: &quot;小明&quot;, &quot;id&quot; : 1823, &quot;rank&quot;: 7&#125;) /test接口返回了一段js代码，这段代码如果正常执行的话将会打印出“小明”，但是由于同源策略，位于a.xxx.com上的js想请求b.xxx.com上的test接口是无法通过的，这就是常说的“js无法跨域”。有没有办法实现跨域呢，大神们想了各种各样的办法，其中之一就是Jsonp，具体来说就是虽说js不能跨域，但是有个例外，那就是script标签可以，利用script标签的跨域特性访问其他域名上的接口，动态生成一段js代码，这样就绕过了同源策略，实现了跨域访问。具体代码如下， var script = document.createElement(&#39;script&#39;); script.setAttribute(&#39;src&#39;, &#39;http://b.xxx.com/test?callback=print_log&#39;); 这实际上相当于执行下面的代码， function print_log(json) &#123; console.log(json.name); &#125; print_log(&#123;&quot;name&quot;: &quot;小明&quot;, &quot;id&quot; : 1823, &quot;rank&quot;: 7&#125;) 不出意外的话可以看到打印出的“小明”了。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Jsonp","slug":"Jsonp","permalink":"https://pingao777.github.io/tags/Jsonp/"},{"name":"Javascript","slug":"Javascript","permalink":"https://pingao777.github.io/tags/Javascript/"}]},{"title":"阿汤哥不减当年啊","slug":"阿汤哥不减当年啊","date":"2018-09-16T04:55:23.000Z","updated":"2020-09-12T03:14:00.592Z","comments":true,"path":"2018/09/16/阿汤哥不减当年啊/","link":"","permalink":"https://pingao777.github.io/2018/09/16/%E9%98%BF%E6%B1%A4%E5%93%A5%E4%B8%8D%E5%87%8F%E5%BD%93%E5%B9%B4%E5%95%8A/","excerpt":"","text":"阿汤哥老了啊，昔日的小鲜肉也是满脸褶子了，岁月真是杀猪刀啊。两张活动送的电影券，晚上10点的场，里面总共6个人，碟中谍的套路没变，剧情也没怎么变，演员也没怎么变，只是时间变了，为情怀支持一波！","categories":[{"name":"七七八八","slug":"七七八八","permalink":"https://pingao777.github.io/categories/%E4%B8%83%E4%B8%83%E5%85%AB%E5%85%AB/"}],"tags":[{"name":"碟中谍","slug":"碟中谍","permalink":"https://pingao777.github.io/tags/%E7%A2%9F%E4%B8%AD%E8%B0%8D/"},{"name":"电影","slug":"电影","permalink":"https://pingao777.github.io/tags/%E7%94%B5%E5%BD%B1/"}]},{"title":"马上TI了，有一起玩的道友吗","slug":"马上TI了，有一起玩的道友吗","date":"2018-08-10T13:35:49.000Z","updated":"2020-09-12T03:14:00.592Z","comments":true,"path":"2018/08/10/马上TI了，有一起玩的道友吗/","link":"","permalink":"https://pingao777.github.io/2018/08/10/%E9%A9%AC%E4%B8%8ATI%E4%BA%86%EF%BC%8C%E6%9C%89%E4%B8%80%E8%B5%B7%E7%8E%A9%E7%9A%84%E9%81%93%E5%8F%8B%E5%90%97/","excerpt":"","text":"马上TI了，又到了神奇的偶数年，希望中国军团如愿以偿。老年dota玩家不能亲临现场加油助威，只能在家多玩几场游戏贡献点人气，求一起玩的d友，分数2000左右吧，娱乐局，主要周末玩。","categories":[{"name":"七七八八","slug":"七七八八","permalink":"https://pingao777.github.io/categories/%E4%B8%83%E4%B8%83%E5%85%AB%E5%85%AB/"}],"tags":[{"name":"Dota","slug":"Dota","permalink":"https://pingao777.github.io/tags/Dota/"}]},{"title":"谁说大象不能跳舞：基于Java的Markdown预览插件","slug":"谁说大象不能跳舞：基于Java的Markdown预览插件","date":"2018-08-04T03:49:59.000Z","updated":"2020-09-12T03:14:00.592Z","comments":true,"path":"2018/08/04/谁说大象不能跳舞：基于Java的Markdown预览插件/","link":"","permalink":"https://pingao777.github.io/2018/08/04/%E8%B0%81%E8%AF%B4%E5%A4%A7%E8%B1%A1%E4%B8%8D%E8%83%BD%E8%B7%B3%E8%88%9E%EF%BC%9A%E5%9F%BA%E4%BA%8EJava%E7%9A%84Markdown%E9%A2%84%E8%A7%88%E6%8F%92%E4%BB%B6/","excerpt":"Java一直以来都给人留下了笨重的印象，按说插件这种轻量的任务根本和Java没啥关系，但是这次我要霸王硬上弓，让大象跳次舞。 跳什么舞呢？这是个问题，突然想起写博客一直困扰自己的一个问题：我一直使用Vim编写Markdown，有时候难免想看看效果，欣赏下文字跳动的样子，但是Vim不支持预览，自己一直用Chrome一款插件Markdown Viewer进行预览，遗憾的是这款插件不支持动态刷新也不支持同步滚动，所以如果你没有一下点出十个信号的手速，这个操作是比较尴尬的。既然这样，能不能用Java整个插件呢？","text":"Java一直以来都给人留下了笨重的印象，按说插件这种轻量的任务根本和Java没啥关系，但是这次我要霸王硬上弓，让大象跳次舞。 跳什么舞呢？这是个问题，突然想起写博客一直困扰自己的一个问题：我一直使用Vim编写Markdown，有时候难免想看看效果，欣赏下文字跳动的样子，但是Vim不支持预览，自己一直用Chrome一款插件Markdown Viewer进行预览，遗憾的是这款插件不支持动态刷新也不支持同步滚动，所以如果你没有一下点出十个信号的手速，这个操作是比较尴尬的。既然这样，能不能用Java整个插件呢？ 整体思路既然现在Markdown Viewer只能显示不能滚动，那么通过程序将Vim的某种位置信息传给浏览器，然后调用js滚动到这个位置不就可以了吗？想让浏览器显示网页而且网页的内容还得不停的变，需要一个Web服务器，这正是Java的强项。从浏览器到Java的路走通了，但是Vim到Java的路怎么走呢？由于Vim不支持Java，二者怎么通信呢，这时看到著名的胶水语言，编程语言界的媒婆Python是被Vim支持的，方案有了：让Python与Java通信。好，这样整个流程就通了。整体框架如下所示： Java服务器Web这片领域简直就是Java的主场，自然一点问题没有。以前学过Netty，一直没有派上用场，这次终于可以小试牛刀了。 public class HttpRequestHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt; &#123; private MarkDownServer server; public HttpRequestHandler(MarkDownServer server) &#123; this.server = server; &#125; @Override public void channelRead0(ChannelHandlerContext ctx, FullHttpRequest request) &#123; String uri = request.uri(); if (uri.startsWith(&quot;/index&quot;)) &#123; index(ctx, request); &#125; else if (uri.startsWith(&quot;/ws&quot;)) &#123; ctx.fireChannelRead(request.retain()); &#125; else if (uri.startsWith(&quot;/js&quot;) || uri.startsWith(&quot;/css&quot;)) &#123; transferStaticFile(ctx, request); &#125; else if (uri.startsWith(&quot;/image&quot;)) &#123; image(ctx, request); &#125; else &#123; commonResponse(ctx, request, FileUtils.getBytes(&quot;How do you do&quot;), MiMeType.PLAIN); &#125; &#125; &#125; 上面即是Web服务的框架程序，细节就不贴了。但是有几个问题大家要注意： 服务器怎么和浏览器通信？ 网页里的js和css怎么返回？ Python怎么和Java通信？ 上面的程序处理的正是前两个问题。 先说服务器怎么和浏览器通信，最初定的是ajax，但是后来找到一种更好的方案WebSocket，WebSocket可以让浏览器和服务器保持长连接，有更好的流畅性和速度，这就是上面/ws所处理的内容。 第二个问题，网页中的静态文件js和css需要让服务器返回，就像tomcat这些通用服务器做的那样，这里没什么复杂的，就是一个简单的文件读写，只有一点需要注意：文件的编码，否则页面会乱码。 第三个问题，Python怎么和Java通信，最初采用的是py4j，优点是这个库可以直接在Python里调用Java程序，缺点是需要安装额外的库，对于有着代码洁癖的我不是一个完美的方案，后来一想既然已经有了Web服务器，直接使用Http不就可以了，所以将方案又改为使用Http与Java通信，经过实验，这个方案虽然不用安装额外的库了，但是由于Python的原装urllib库不能保持长连接，随着连接的增多，速度会慢慢降下来，看来还得另寻出路。 private class SocketServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; String string = in.toString(CharsetUtil.UTF_8); LOGGER.info(&quot;Server received: &quot; + string); String[] data = string.split(SEP); switch (data[0]) &#123; case &quot;start&quot;: server = MarkDownServer.getInstance(); server.setTheme(data[2]); server.start(Integer.parseInt(data[1])); break; case &quot;sync&quot;: server.broadcast(&quot;sync&quot;, data[1], Base64Utils.decode2String(data[2]), Integer.parseInt(data[3])); break; case &quot;close&quot;: server.broadcast(&quot;close&quot;, data[1], &quot;&quot;, 1); break; case &quot;stop&quot;: server.destroy(); System.exit(0); break; default: LOGGER.info(&quot;Command &#123;&#125; is unknown&quot;, data[0]); &#125; &#125; &#125; 这就是最终的解决方案：返璞归真，直接使用最底层的Socket与Java通信。经过实验，速度提升明显，而且由于Socket客户端和服务端可以保持长连接，没有运行一段时间，速度变慢的缺点。 通信主要包含四种情况： start：启动Http服务器 sync：同步内容和位置 close：关闭预览窗口 stop：停止Http服务器，退出系统 Java-&gt;浏览器var url = &#39;ws://127.0.0.1:&#39; + window.location.port + &#39;/ws&#39;; if (!WebSocket) &#123; console.warn(&#39;WebSocket is not support&#39;); &#125; else &#123; console.log(&#39;Try to connect &#39; + url); var ws = new WebSocket(url); ws.onclose = function () &#123; console.log(&#39;Disconnected&#39;); close(); &#125;; ws.onmessage = function (d) &#123; console.log(&#39;Response : &#39; + d.data.length); var data = JSON.parse(d.data); var path = $(&#39;#path&#39;); if (path.val() === &#39;&#39;) &#123; init(data); &#125; else &#123; if (path.val() === data.path) &#123; if (data.command === &#39;close&#39;) &#123; close() &#125; else if (data.command === &#39;sync&#39;) &#123; sync(data); &#125; &#125; &#125; &#125;; &#125; var init = function (data) &#123; $(&#39;title&#39;).html(data.path); $(&#39;#path&#39;).val(data.path); $(&#39;.markdown-body&#39;).html(&#39;&#39;); markdown_refresh(data.units); highlight_code(); scroll_if_possible(); &#125;; var sync = function (data) &#123; markdown_refresh(data.units); highlight_code(); scroll_if_possible(); &#125;; 前端就是一个WebSoket客户端，接受两种指令：close和sync，前者用于关闭页面，后者用于同步信息。 大致的流程是浏览器第一次收到服务器消息调用init进行初始化，它会将网页的title和页面元素#path置为文件的路径，将.markdown-body清空，因为浏览器刚启动时会启动一个index介绍页面，需要将其清空，然后调用markdown_refresh刷新显示新的内容，内容显示后hightlight_code负责高亮其中的代码，最后用scroll_if_possible滚动到指定位置。往后浏览器每收到服务器消息都会调用sync同步信息和位置，sync和init内部代码差不多，我就不再赘述了。 Vim-&gt;Java以上走通了Java到浏览器的路，下面看看如何走Vim到Java的路，在整体思路中提到Vim支持Python，所以这条路的主角就是Python，最初是发送Http请求与Java交互，后来又改为使用Socket，原因参看Java服务器那一节。最终的代码如下： SEP = &#39;\\r\\n\\r\\n&#39; EOF = &#39;$_@&#39; s = None def start(port, theme): global s s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((&#39;127.0.0.1&#39;, 23789)) s.send(&#39;start&#39; + SEP + str(port) + SEP + theme + EOF) def sync(path, content, bottom): s.send(&#39;sync&#39; + SEP + path + SEP + base64.b64encode(content) + SEP + str(bottom) + EOF) def close(path): s.send(&#39;close&#39; + SEP + path + EOF) def stop(): s.send(&#39;stop&#39; + EOF) s.close() 变量解释：path表示打开文件的路径，content为buffer内容，bottom为当前窗口的末行。 这里的函数和Java Socket服务器那一节里处理的四种情况一一对应，想不起来的可以回去再看下。你可能注意到每次发送消息后面都加了一个EOF，这是因为Tcp是基于流的通信协议，需要一种策略告诉接受方什么时候是一条完整的消息，这里采用的是终结符的形式，即每条消息后面都加了一个EOF告知接收方已经接受了一条完整的消息。另外需要对content进行base64编码，因为content里可能包含一些特殊字符，传输过程中对这些字符处理不一致会导致出错。 下一步就是在Vimscript里调用Python，我就不贴代码了。 一步之遥至此，插件就基本编写完成了，似乎离成功只有一步之遥了，但成功往往没那么简单。运行一下，乍看起来效果还可以，但是存在两个比较严重的问题： MathJax抖动每次滚动时，如果页面里包含MathJax表达式，页面就会一抖一抖的。这是因为所有的内容都存在一个&lt;article&gt;&lt;/article&gt;标签里，前端每次加载内容，都要刷新内容里所有的MathJax表达式，表达式加载需要时间，未加载完成时有一个空的占位，加载完成使用真正的元素替换，类似网页中的图片加载流程，占位和真正的元素大小不一致，这样给人的感觉就是页面一抖一抖的，最初用的代码如下： MathJax.Hub.Config(&#123; extensions: [&quot;tex2jax.js&quot;], jax: [&quot;input/TeX&quot;, &quot;output/SVG&quot;], tex2jax: &#123; inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&quot;\\\\(&quot;,&quot;\\\\)&quot;] ], displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&quot;\\\\[&quot;,&quot;\\\\]&quot;] ] &#125;, messageStyle: &quot;none&quot; &#125;); MathJax.Hub.Queue([&quot;Typeset&quot;, MathJax.Hub]); 那怎么解决呢？既然是因为刷新全部的MathJax表达式，那么不让它刷新全部，让它刷新的内容越少抖动不就越小了？查阅MathJax的文档，找到一个函数MathJax.Hub.Queue([&#39;Typeset&#39;, MathJax.Hub, element])，它只会刷新页面元素element里的表达式，修改服务器同步信息代码，改全量同步为增量同步，如果里面包含MathJax表达式就调用上述命令刷新。 新的前端代码如下： $.each(units, function (i, u) &#123; if (u.operate === &#39;REPLACE&#39;) &#123; if (u.id === &#39;toc_container&#39;) &#123; $(&#39;.markdown-body&#39;).css(&#39;padding-left&#39;, &#39;200px&#39;); var toc = $(&#39;#&#39; + u.id); toc.html(u.content); toc.show(); &#125; else &#123; $(&#39;#&#39; + u.id).replaceWith(u.content); &#125; &#125; else if (u.operate === &#39;APPEND&#39;) &#123; $(&#39;.markdown-body&#39;).append(u.content); &#125; else if (u.operate === &#39;REMOVE&#39;) &#123; if (u.id === &#39;toc_container&#39;) &#123; $(&#39;.markdown-body&#39;).css(&#39;padding-left&#39;, &#39;45px&#39;); var cot = $(&#39;#&#39; + u.id); cot.html(&#39;&#39;); cot.hide(); &#125; else &#123; $(&#39;#&#39; + u.id).remove(); &#125; &#125; if (u.isMathJax === 1) &#123; MathJax.Hub.Queue([&#39;Typeset&#39;, MathJax.Hub, u.id]); &#125; &#125;) 本地图片不显示由于浏览器安全策略的限制，页面的img标签不能打开本地图片，即形如&lt;img src=&#39;D:\\path-to-img.jpg&#39;/&gt;这种写法浏览器不会加载图片，而是提示“Not allowed to load local resource”。一般在文章未发布到网上时，图片地址往往写一个本地的绝对路径，如果不能显示本地图片的话将会大大影响方便性。那么该怎么办呢，第一种方法是写相对路径，即&lt;img src=&#39;/path-to-img.jpg&#39;/&gt;，这种方式有很大的局限性，即必须将图片放在一个位置，与网页呈一种相对关系；另一种是写的时候还是写绝对路径，经过程序转成服务器地址，然后通过服务器将图片返给浏览器。显然第二种方式更加灵活，核心代码如下： private static void transformLocalImgSrc(Element element) &#123; Elements images = element.select(&quot;img&quot;); for (Element img : images) &#123; String src = img.attr(&quot;src&quot;); if (!src.startsWith(&quot;http&quot;)) &#123; if (isWindows()) &#123; img.attr(&quot;src&quot;, &quot;/image?path=&quot; + src.replace(&quot;\\\\&quot;, &quot;\\\\\\\\&quot;)); &#125; else &#123; img.attr(&quot;src&quot;, &quot;/image?path=&quot; + src); &#125; &#125; &#125; &#125; 上面的代码将形如D:\\path-to-img.jpg的本地路径转成http://127.0.0.1:7788/image?path=D:\\\\path-to-img.jpg(windows系统，其他系统路径与此略有不同)，然后由服务器将图片内容返回。这样就绕过了浏览器的安全策略，实现本地图片的加载了。 阳光总在风雨后尽管经过了一些风雨，最后还是看到胜利的曙光了。这个项目够小，涵盖的语言和知识并不少，作为一个练手的项目还是不错的，如果碰巧还能给生活提供点便利，何乐而不为呢？想了解大象跳舞的更多细节请戳github。 参考资料： Netty in action write vim plugin in python","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"},{"name":"Vim","slug":"Vim","permalink":"https://pingao777.github.io/tags/Vim/"},{"name":"Markdown","slug":"Markdown","permalink":"https://pingao777.github.io/tags/Markdown/"},{"name":"Python","slug":"Python","permalink":"https://pingao777.github.io/tags/Python/"}]},{"title":"Vim Markdown预览插件markdown-preview-sync","slug":"Vim Markdown预览插件markdown-preview-sync","date":"2018-07-29T02:24:06.000Z","updated":"2020-09-12T03:14:00.584Z","comments":true,"path":"2018/07/29/Vim Markdown预览插件markdown-preview-sync/","link":"","permalink":"https://pingao777.github.io/2018/07/29/Vim%20Markdown%E9%A2%84%E8%A7%88%E6%8F%92%E4%BB%B6markdown-preview-sync/","excerpt":"花了大概两个星期整了个Vim预览插件markdown-preview-sync，主要参考了Markdown Viewer和markdown-preview.vim这两款插件，感谢这两款插件的作者。 支持如下特性： 代码高亮 MathJax 自定义CSS GFM-TABLE 目录TOC 运行效果如图：","text":"花了大概两个星期整了个Vim预览插件markdown-preview-sync，主要参考了Markdown Viewer和markdown-preview.vim这两款插件，感谢这两款插件的作者。 支持如下特性： 代码高亮 MathJax 自定义CSS GFM-TABLE 目录TOC 运行效果如图： 为了用户体验，预览并不是实时显示的，而是在换行时或保存时。这一点是有意为之的，毕竟大家对Markdown语法都了如指掌了，只是想偶尔看下效果。相信大家都有这样的体验，眼睛不停的在编辑屏和预览屏来回切换，眼睛很累，同时思路也很容易被打断，而且根据我个人的实验，同步频率太快会影响Vim的流畅性。 最后再啰嗦一句，欢迎大家使用并提出宝贵意见！","categories":[{"name":"七七八八","slug":"七七八八","permalink":"https://pingao777.github.io/categories/%E4%B8%83%E4%B8%83%E5%85%AB%E5%85%AB/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://pingao777.github.io/tags/Vim/"},{"name":"Markdown","slug":"Markdown","permalink":"https://pingao777.github.io/tags/Markdown/"}]},{"title":"Java的equals和hashCode方法浅谈","slug":"Java的equals和hashCode方法浅谈","date":"2018-07-02T08:20:39.000Z","updated":"2020-09-12T03:14:00.583Z","comments":true,"path":"2018/07/02/Java的equals和hashCode方法浅谈/","link":"","permalink":"https://pingao777.github.io/2018/07/02/Java%E7%9A%84equals%E5%92%8ChashCode%E6%96%B9%E6%B3%95%E6%B5%85%E8%B0%88/","excerpt":"一、概述equals和hashCode作为Java基础经常在面试中提到，比如下面几个问题： equals和==有什么区别？ equals和hashCode有什么关系？ equals和hashCode如何编写？ 对于第一个问题不少人只停留在字符串equals比较的是内容，==比较的是内存地址，而对equals的本质极少过问。第二个问题，大多数都知道答案，也有不少记反了，但是更进一步为什么是那样的关系，就不知道了。对于第三个问题，大部分人一上手就把方法签名写错了，就别谈正确的写出实现了。带着这些问题，接下来谈谈自己的一点理解。","text":"一、概述equals和hashCode作为Java基础经常在面试中提到，比如下面几个问题： equals和==有什么区别？ equals和hashCode有什么关系？ equals和hashCode如何编写？ 对于第一个问题不少人只停留在字符串equals比较的是内容，==比较的是内存地址，而对equals的本质极少过问。第二个问题，大多数都知道答案，也有不少记反了，但是更进一步为什么是那样的关系，就不知道了。对于第三个问题，大部分人一上手就把方法签名写错了，就别谈正确的写出实现了。带着这些问题，接下来谈谈自己的一点理解。 二、equals方法先来看见equals方法的签名， public boolean equals(Object obj) &#123; return (this == obj); &#125; 可以看到入参是Object，很多人没有注意到这一点，上来就写错了。equals方法顾名思义就判断对象的相等性，默认实现就是==，那么说到二者的区别，个人理解，equals方法是一种用户定义的“逻辑等”，而==是一种“物理等”，用俗语解释就是，equals判断是否相同，==判断是否一样。 equals方法在编写的时候需要遵循以下原则： 自反性 对称性 传递性 一致性 下面展开说一下， 自反性的意思是，对于一个非null的对象x，x.equals(x)一定为true，这是显而易见的，无须赘述。 对称性，对于非null对象x、y，x.equals(y) == true，当且仅当y.equals(x) == true。来看一个来自《Effective Java》的例子， // Broken - violates symmetry! public final class CaseInsensitiveString &#123; private final String s; public CaseInsensitiveString(String s) &#123; this.s = Objects.requireNonNull(s); &#125; // Broken - violates symmetry! @Override public boolean equals(Object o) &#123; if (o instanceof CaseInsensitiveString) return s.equalsIgnoreCase( ((CaseInsensitiveString) o).s); if (o instanceof String) // One-way interoperability! return s.equalsIgnoreCase((String) o); return false; &#125; ... // Remainder omitted &#125; CaseInsensitiveString cis = new CaseInsensitiveString(&quot;Polish&quot;); String s = &quot;polish&quot;; List&lt;CaseInsensitiveString&gt; list = new ArrayList&lt;&gt;(); list.add(cis); // true or false list.contains(s); 在JDK8运行list.contains(s)返回false，但是有的JDK可能会返回true，甚至直接崩溃，所以如果违反了对称性，程序的行为是不可预测的。 传递性，对于非null对象x、y、z，如果x.equals(y) == true且y.equals(z) == true，那么x.equals(z) == true。同样是来自《Effective Java》的一个例子， public class Point &#123; private final int x; private final int y; public Point(int x, int y) &#123; this.x = x; this.y = y; &#125; @Override public boolean equals(Object o) &#123; if (!(o instanceof Point)) return false; Point p = (Point)o; return p.x == x &amp;&amp; p.y == y; &#125; ... // Remainder omitted &#125; public class ColorPoint extends Point &#123; private final Color color; public ColorPoint(int x, int y, Color color) &#123; super(x, y); this.color = color; &#125; // Broken - violates transitivity! @Override public boolean equals(Object o) &#123; if (!(o instanceof Point)) return false; // If o is a normal Point, do a color-blind comparison if (!(o instanceof ColorPoint)) return o.equals(this); // o is a ColorPoint; do a full comparison return super.equals(o) &amp;&amp; ((ColorPoint) o).color == color; &#125; ... // Remainder omitted &#125; ColorPoint p1 = new ColorPoint(1, 2, Color.RED); Point p2 = new Point(1, 2); ColorPoint p3 = new ColorPoint(1, 2, Color.BLUE); 显然ColorPoint的equals实现违反了传递性，p1.equals(p2) == p2.equals(p3) != p1.equals(p3)。假如Point有两个子类ColorPoint和SmellPoint，colorPoint.equals(smellPoint)将会导致无限递归，最终导致内存耗尽。引用《Effective Java》的说法， There is no way to extend an instantiable class and add a value component while preserving the equals contract, unless you’re willing to forgo the benefits of object-oriented abstraction. 这句话的大意是如果你继承扩展一个类，就没法再保持equals的原则了，除非放弃使用继承。放弃继承？这不是让我们因噎废食嘛，咦，别说，还真能放弃继承，那就是组合，因为本文的重点是equals和hashCode就不展开了。 一致性，对于非null对象x、y，多次调用x.equals(y)返回一致。一致性意味着equals方法不要依赖不可靠的变量，这里“可靠”的意思不光意味着“不该变时不变”，还意味着“想获取时能获取到”，比如java.net.URL的equals实现依赖了ip地址，而网络故障时无法获取ip，这是一个不好的实现。 说了那么多，有人可能会说，哎呀这么多原则顾头不顾尾，都要满足，太难了吧，下面列出实现equals的一些tips，照着做实现起来就易如反掌， 使用==判断是否为null或this，如果是前者返回false，后者就返回true。 使用instanceof检测是否是正确的类型，如果不是直接返回false，如果是，强制转换为正确的类型，然后比较与“逻辑等”相关的变量。 三、hashCode方法hashCode主要用来在Java中哈希数据结构HashMap、HashSet生成哈希值，hashCode的方法签名， public native int hashCode(); 默认实现会将对象的内存地址转化为一个整数，因此只有同一个对象hashCode才一样，即使两个equals返回true的对象hashCode也不一样，如果不进行重写。和equals一样，hashCode也需要满足一些原则： 一致性，和equals相关的变量没有变化，hashCode返回值也不能变化。 两个对象equals返回true，hashCode返回值应该相等。由上面得知，hashCode默认实现不满足这一条件，因此任何类如果实现了equals就必须实现hashCode，确保二者的步调一致，下面来看一个反例， public class Person &#123; private int age; private String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; @Override public boolean equals(Object obj) &#123; if (obj == null) &#123; return false; &#125; if (obj == this) &#123; return true; &#125; if (obj instanceof Person) &#123; Person that = (Person) obj; return age == that.age &amp;&amp; Objects.equals(name, that.name); &#125; return false; &#125; &#125; Map&lt;Person, Integer&gt; map = new HashMap&lt;&gt;(); map.put(new Person(10, &quot;小明&quot;), 1); map.get(new Person(10, &quot;小明&quot;)); 初学者可能觉得最后一条语句会返回1，事实上返回的是null，为什么会这样呢？明明将数据放进去了，而数据却像被黑洞吞噬一样，要解释得从HashMap的数据结构说起，HashMap是由数组和链表组成的一种组合结构，如下图，往里存放时，hashCode决定数组的下标，而equals用于查找值是否已存在，存在的话替换，否则插入；往外取时，先用hashCode找到对应数组下标，然后用equals挨个比较直到链表的尾部，找到返回相应值，找不到返回null。再回过头看刚才的问题，先放进去一个new Person(10, &quot;小明&quot;)，然后取的时候又新建了一个new Person(10, &quot;小明&quot;)，由于没有重写hashCode，这两个对象的hashCode是不一样的，存和取的数组下标也就不一样，自然取不出来了。 两个对象equals返回false，hashCode返回值可以相等，但是如果不等的话，可以改进哈希数据结构的性能。这条原则也可以用HashMap的数据结构解释，举一个极端的例子，假如Person所有对象的hashCode都一样，那么HashMap内部数组的下标都一样，数据就会进到同一张链表里，这张链表比正常情况下要长的多，而遍历链表是一项耗时的工作，性能也就下来了。 那么如何写一个好的hashCode呢？ 声明一个变量int的变量result，将第一个和equals相关的实例变量的hashCode赋值给它。 然后按照下列规则依次计算剩下的实例变量的hashCode值c。 如果是null，设置一个常数，通常为0 如果是原始类型，使用Type.hashCode(f)，Type为它们的装箱类型 如果是数组，如果每一个元素都是相关的，可以使用Arrays.hashCode；否则将相关元素看作独立的变量计算 使用result = 31 * result + c的形式将每个变量的哈希值组合起来，最后返回result。 参考资料：《Effective Java》","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"}]},{"title":"侏罗纪下一部可以叫做We are family","slug":"侏罗纪下一部可以叫做We-are-family","date":"2018-06-25T02:14:51.000Z","updated":"2020-09-12T03:14:00.589Z","comments":true,"path":"2018/06/25/侏罗纪下一部可以叫做We-are-family/","link":"","permalink":"https://pingao777.github.io/2018/06/25/%E4%BE%8F%E7%BD%97%E7%BA%AA%E4%B8%8B%E4%B8%80%E9%83%A8%E5%8F%AF%E4%BB%A5%E5%8F%AB%E5%81%9AWe-are-family/","excerpt":"","text":"侏罗纪为了续集越来越无耻了，下一部名字都给你们起好了，就叫We are family，影片一开始，人类和恐龙手牵手围成一圈载歌载舞，一片和谐的景象，或许还可以制定个《恐龙人权保护法》什么的。","categories":[{"name":"生活生活","slug":"生活生活","permalink":"https://pingao777.github.io/categories/%E7%94%9F%E6%B4%BB%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"侏罗纪公园","slug":"侏罗纪公园","permalink":"https://pingao777.github.io/tags/%E4%BE%8F%E7%BD%97%E7%BA%AA%E5%85%AC%E5%9B%AD/"}]},{"title":"Maven插件屏蔽第三方包日志的方法","slug":"Maven插件屏蔽第三方包日志的方法","date":"2018-06-01T07:23:04.000Z","updated":"2020-09-12T03:14:00.583Z","comments":true,"path":"2018/06/01/Maven插件屏蔽第三方包日志的方法/","link":"","permalink":"https://pingao777.github.io/2018/06/01/Maven%E6%8F%92%E4%BB%B6%E5%B1%8F%E8%94%BD%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85%E6%97%A5%E5%BF%97%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"这几天写了一个Maven插件，里面用到了Zookeeper（下面简称ZK），里面打印出了很多“Client environment…”字样的info信息，看着挺闹心，就想着怎么屏蔽掉，让世界清净点。","text":"这几天写了一个Maven插件，里面用到了Zookeeper（下面简称ZK），里面打印出了很多“Client environment…”字样的info信息，看着挺闹心，就想着怎么屏蔽掉，让世界清净点。 刚开始认为ZK使用的log4j，那么在工程里建个resources/log4j.properties，使用log4j.logger.org.apache.zookeeper=WARN的形式来屏蔽掉，结果没起作用。后来又使用log4j.xml的形式，也是不行。再后来又用logback，还是不行，感觉把能想到的方法都试试了，统统不管用，真是郁闷。 将要放弃时，忽然想到既然是在Maven插件里，里面的log系统是不是另有一套呢，一看果然不是log4j，而是simplelogger，按着指导修改了[maven home]\\conf\\logging\\simplelogger.properties，现在有作用了。 因为插件jenkins部署的时候也要使用，如果要修改部署脚本或者挨个修改Maven的配置文件太麻烦，最好能在当前插件里设置，最后试了一下将simplelogger.properties里的配置写到Java系统变量里，果然可以，事情终于圆满解决了，解决方式为添加下面的代码： System.setProperty(&quot;org.slf4j.simpleLogger.log.org.apache.zookeeper&quot;, &quot;warn&quot;); 希望能给有类似需求的人一点参考，不得不感叹下Java的日志系统真是杂乱啊！","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://pingao777.github.io/tags/Maven/"},{"name":"日志","slug":"日志","permalink":"https://pingao777.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2018中期计划","slug":"2018中期计划","date":"2018-05-25T07:23:32.000Z","updated":"2020-09-12T03:14:00.580Z","comments":true,"path":"2018/05/25/2018中期计划/","link":"","permalink":"https://pingao777.github.io/2018/05/25/2018%E4%B8%AD%E6%9C%9F%E8%AE%A1%E5%88%92/","excerpt":"虽说伟大的大先知鲁迅曾经说过，要立长志，不要常立志。但是为了将来打脸留个证据，还是要立个字据的。","text":"虽说伟大的大先知鲁迅曾经说过，要立长志，不要常立志。但是为了将来打脸留个证据，还是要立个字据的。 Coursera上Algorithms课程，现在已进行到上半部分第二周。 啃完计算机程序与构造，做一部分习题。 至少每隔一天跑一次步，身体革命本钱。 每周一篇博客，不限制长度。 计划看起来不多，难度较大的是2和3。计算机程序和构造啃了好几次了，都不了了之，和1相比，没有Coursera的时间限制和分数激励，导致自己没有动力，成就感不高，加上有些习题难度较大，比较打击信心，希望这次能把这个硬骨头啃掉。跑步这个事说起来不算难事，难得是坚持下来，特别是一个人。北京这地方，冬天冷，夏天热，遇到刮风下雨，很容易给自己找借口开脱，所以我把标准降低了，允许自己偷下懒。我把朋友圈关闭了，就把博客当成朋友圈吧，每周一篇博客应该没啥问题。 好了，别的不说了，立了计划就得执行，希望年末不打脸。","categories":[{"name":"生活生活","slug":"生活生活","permalink":"https://pingao777.github.io/categories/%E7%94%9F%E6%B4%BB%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"2018","slug":"2018","permalink":"https://pingao777.github.io/tags/2018/"},{"name":"计划","slug":"计划","permalink":"https://pingao777.github.io/tags/%E8%AE%A1%E5%88%92/"}]},{"title":"一个初级阶段的五子棋ai","slug":"一个初级阶段的五子棋ai","date":"2017-12-11T08:46:03.000Z","updated":"2020-09-12T03:14:00.585Z","comments":true,"path":"2017/12/11/一个初级阶段的五子棋ai/","link":"","permalink":"https://pingao777.github.io/2017/12/11/%E4%B8%80%E4%B8%AA%E5%88%9D%E7%BA%A7%E9%98%B6%E6%AE%B5%E7%9A%84%E4%BA%94%E5%AD%90%E6%A3%8Bai/","excerpt":"一、前言16年alpha狗接连击败李世石和柯洁后，自己就有个想法，能不能利用机器学习也鼓捣一个类似的五子棋ai？最初的想法是训练一个机器学习模型，喂给它一些棋局，让它自己能够学会落子规则，能够积累优势，最终取得胜利，而且随着下棋盘数的增加，自身的能力可以进一步的提高。但是传统的机器学习需要输入和响应，对于一局棋输入和响应又是什么呢，搜肠刮肚的把自己知道的的几种算法想了一遍，也在网上查了半天，或者模型太复杂，短时间没法掌握相关的知识，或者模型计算代价太高，动辄训练个几天，所谓远水解不了近渴，最好的能一个周末能整出一个初级的ai，能打败我就行，以后有时间功能可以慢慢加，这也是标题的由来。","text":"一、前言16年alpha狗接连击败李世石和柯洁后，自己就有个想法，能不能利用机器学习也鼓捣一个类似的五子棋ai？最初的想法是训练一个机器学习模型，喂给它一些棋局，让它自己能够学会落子规则，能够积累优势，最终取得胜利，而且随着下棋盘数的增加，自身的能力可以进一步的提高。但是传统的机器学习需要输入和响应，对于一局棋输入和响应又是什么呢，搜肠刮肚的把自己知道的的几种算法想了一遍，也在网上查了半天，或者模型太复杂，短时间没法掌握相关的知识，或者模型计算代价太高，动辄训练个几天，所谓远水解不了近渴，最好的能一个周末能整出一个初级的ai，能打败我就行，以后有时间功能可以慢慢加，这也是标题的由来。 二、Minimax算法对于这种回合制的游戏，传统的方法就是利用minimax算法，那么什么是minimax算法呢，说白了，就是和人在脑子里模拟往下走几步一样，minimax算法也是模拟往下走棋，轮到自己时选自己最有利的，即max，轮到对方时选自己最不利的，即min，直到某一条件终止，然后选择一条对自己最有利的路径。由此可以看到，如果计算资源足够，计算机是可以找到一条可以使己方胜利的路径，但是事实上这是不可能的，以15X15的五子棋为例，大约有225!种可能的走法，想穷举出这么多种可能性，以目前的计算能力是达不到的，所以一般的做法是往下模拟走一定的步数，然后选择一条最优的。 三、评估函数由算法描述，必须有一种方法对当前的局势进行衡量，通常的方法就是使用评估函数。评估函数可以根据当前局势给出一个分数，使局势成为可量化的数值。具体到五子棋就是统计棋局中的活三、活四等模式并给予一定的分数然后将总的分数相加，具体请参考代码。 四、优化1、Alpha-beta剪枝单纯的minimax算法复杂度是非常高的，从算法的描述，算法的复杂度应该是$O(b^d)$,d是往后走的步数，b是每一步棋可选的位置。以五子棋为例，模拟走5步大约是$225^5=576650390625$，显然这个数目还是太大，所以需要引进alpha-beta剪枝。这种算法就是用一个变量alpha保存着max一方可以得到的最优值，beta保存着min一方只允许max一方获得的最优值，当beta小于等于alpha时其他的情况就不用再看了，因为最优值的上限就是beta。 2、减少可选的落子位置下过五子棋的可能都知道，如果落子的位置离己方和对方的棋子太远是没有意义的，因此我把这个距离限制为2，这样把原来b从225减少到了20~30，这个优化是很可观的。 3、历史启发alpha-beta剪枝的效率是和下一步棋的顺序密切相关，如果最合适的那一步棋总是先计算那么算法的效率可以达到$O(b^\\sqrt{d})$，这就相当于同样的时间原来只能往后推算5步，现在可以推算10步，而如果顺序不当，效率和没剪枝的minimax没什么两样。历史启发的原理就是记录那些发生剪枝次数最多的位置，以及得分的极值，赋予它们一定的值，以此来排序。 最终的核心代码如下， private int alphaBeta(Board board, int depth, int alpha, int beta, Player player) &#123; if (board.status().isGameOver() || depth &lt;= 0) &#123; return board.evaluate(this, this.depth - depth); &#125; Board.Pos bestPos = null; int v = (this == player) ? Integer.MIN_VALUE : Integer.MAX_VALUE; List&lt;Board.Pos&gt; childPos = sortChildPos(board); for (Board.Pos pos : childPos) &#123; Board bd = new Board(board); bd.mark(pos, player); int w = alphaBeta(bd, depth - 1, alpha, beta, bd.getEnemy(player)); if (this == player) &#123; if (v &lt; w) &#123; v = w; bestPos = pos; if (depth == this.depth) &#123; this.best = new Move(v, pos); &#125; &#125; alpha = Integer.max(alpha, w); &#125; else &#123; if (v &gt; w) &#123; v = w; bestPos = pos; &#125; beta = Integer.min(beta, w); &#125; if (beta &lt;= alpha) &#123; this.history[pos.getRow()][pos.getCol()] += 2 &lt;&lt; depth; break; &#125; &#125; if (bestPos != null) &#123; this.history[bestPos.getRow()][bestPos.getCol()] += 2 &lt;&lt; depth; &#125; return v; &#125; 五、战力如何首先是人机对战，当推算的步数达到4步时，我是没赢过，但是这并不能说明它的战力有多强，只能说明我的水平很臭，但是我的初步目标达到了；其次我让两个同等级的电脑对战50局，战绩如下， 等级（步数） 先手赢 后手赢 平局 1 40 10 0 2 16 12 22 3 27 18 5 似乎印证了先手的胜率高一点。 六、下一步工作 可以看到ai的战力是和评估函数密切相关的，获取一个比较好的评估函数是一个优化的方向。 目前ai不能自我学习，如何让ai自我学习，并逐步变强是另一个方向，这也是重点方向。 如果想在我的代码上继续前进，请戳这里，下图是一局电脑对战的动图。 参考资料： Minimax Alpha-beta pruning Killer_heuristic","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"五子棋","slug":"五子棋","permalink":"https://pingao777.github.io/tags/%E4%BA%94%E5%AD%90%E6%A3%8B/"},{"name":"minimax","slug":"minimax","permalink":"https://pingao777.github.io/tags/minimax/"},{"name":"alpha-beta","slug":"alpha-beta","permalink":"https://pingao777.github.io/tags/alpha-beta/"}]},{"title":"浅谈Java泛型","slug":"浅谈Java泛型","date":"2017-11-28T03:03:16.000Z","updated":"2020-09-12T03:14:00.590Z","comments":true,"path":"2017/11/28/浅谈Java泛型/","link":"","permalink":"https://pingao777.github.io/2017/11/28/%E6%B5%85%E8%B0%88Java%E6%B3%9B%E5%9E%8B/","excerpt":"相信每个Java程序员对泛型都不陌生，不少人也用过泛型，但是泛型中确实有些点容易让人迷惑，下面我结合自己的使用经历和理解谈谈对泛型的认识，不求面面俱到，但求切中要害。","text":"相信每个Java程序员对泛型都不陌生，不少人也用过泛型，但是泛型中确实有些点容易让人迷惑，下面我结合自己的使用经历和理解谈谈对泛型的认识，不求面面俱到，但求切中要害。 一、泛型是什么引用Java文档的解释， A generic type is a generic class or interface that is parameterized over types. 大致的意思就是类型经过参数化的类或接口。 二、为什么要泛型在泛型出现之前你要定义一个存储水果类的列表，你只能这样写， List fruits = new ArrayList(); Elephant e = new Elephant(); fruits.add(e); Fruit f = (Fruit) fruits.get(0); 虽然定义了一个名叫fruits的列表，但是你里面存大象也没人管你，只有在运行时你试图将列表的元素赋值给一个水果时才会报错。为了更早的发现这种错误，Java在5.0引入了泛型机制(Generics)。有了泛型上面的程序就可以这么写， List&lt;Fruit&gt; fruits = new ArrayList&lt;Fruit&gt;(); Elephant e = new Elephant(); fruits.add(e); // Compile error 这样当你往水果的列表里塞一个大象时编译器就会报错，而不用等到运行时，而且也避免了显式的转型。 三、泛型分类从程序的层次上，泛型分为泛型类和泛型方法。比如Java中的ArrayList类就是一个泛型类， public class ArrayList&lt;E&gt; 而集合工具类Collections中的emptyList方法就是一个泛型方法， public static final &lt;T&gt; List&lt;T&gt; emptyList() &#123; return (List&lt;T&gt;) EMPTY_LIST; &#125; 到这里其实没什么要说的。 四、更进一步1、通配符?通配符代表的意思应该是“某个或某些具体但不确定的类型”，首先具体的是指将来要用某个具体的类来替换通配符，其次不确定是指当前还确定不了是哪种具体类型。 2、边界边界也就是某种类型的子类型或父类型，即super定义的下界和extends定义的上界。 3、类型擦除如果用一句话解释就是用不用泛型编译后的代码是一样的，更详细更准确的解释是由于泛型是在Java 5.0引入的，为了兼容老版本的Java，编译器会将泛型参数替换为它的边界（上界），如果有多个边界，只保留最左边的，如果没有边界替换为Object，最终保留下来的只有正常的类、接口和方法。 public class GeneralTest&lt;T extends Comparable&lt;T&gt; &amp; Iterable&lt;T&gt; &amp; Serializable&gt; &#123; void test1(T t) &#123; ... &#125; &lt;E&gt; void test2(E e) &#123; ... &#125; &#125; 编译后生成的代码为， void test1(T); descriptor: (Ljava/lang/Comparable;)V &lt;E&gt; void test2(E); descriptor: (Ljava/lang/Object;)V 可以看到T的边界有三个Comparable&lt;T&gt; &amp; Iterable&lt;T&gt; &amp; Serializable，编译后只保留了Comparable，而且Comparable的泛型&lt;T&gt;也去掉了；test2中的E没有边界，它直接被替换为了Object，而且test2作为泛型方法编译后也没有任何泛型的信息。 4、替换原则一个类型的变量可以接受子类型的变量，一个据有某种参数的方法可以在参数的子类型上调用。这个原则几乎是面向对象编程的基础，它可以让我们这么写代码， Fruit a = new Apple(); List l = new ArrayList(); 可以把一个“苹果”赋值给“水果”，可以把ArrayList赋值给List。 5、PECS原则也就是所谓的Producer Extends, Consumer Super原则，作为生产者时使用extends，作为消费者时使用super，这条原则其实是替换原则的推论。 List&lt;??&gt; list = Arrays.asList(1, 1.3, 5L); Number i = list.get(0); Map&lt;String, ??r&gt; map = new HashMap&lt;&gt;(); map.put(&quot;212&quot;, 1); 比如你想要从list中取出的数据可以赋值给一个Number，根据替换原则，“一个类型的变量可以接受子类型的变量”，你就得定义list中的类型都是Number的子类型。那么如何表示一个Number的子类型呢，因为extends在Java中本来就表示继承的意思，所以很自然的想法就是? extends Number，这恰恰就是正确答案。 再比如，你想在map值里存储各种数字，根据替换原则，“一个据有某种参数的方法可以在参数的子类型上调用”，也就是你想要put方法适用在各种数字类型上，“各种数字类型”是这里的“子类型”，所以你需要定义map的值是“各种数字类型”的父类型才可以，表示父类Java中同样有个关键字super，所以你可能猜想? super Number表示的就是这个意思，没错，答案就是这个。 你可以看到，在两种情况下，确定泛型是替换原则中的子类型还是父类型是关键中的关键。这恰恰就是PECS原则的内容，即作为生产者，将泛型传递给别的变量时，使用extends；作为消费者，将别的变量传递给泛型时，使用super。 6、是泛型方法还是通配符在泛型中，经常面临的一个抉择就是是使用泛型方法还是使用通配符。比如下面的方法， interface Collection&lt;E&gt; &#123; public boolean containsAll(Collection&lt;?&gt; c); public boolean addAll(Collection&lt;? extends E&gt; c); &#125; 如果写成泛型方法， interface Collection&lt;E&gt; &#123; public &lt;T&gt; boolean containsAll(Collection&lt;T&gt; c); public &lt;T extends E&gt; boolean addAll(Collection&lt;T&gt; c); &#125; 可以看到类型参数T在方法中只使用了一次，和别的类型参数也没有关系，和函数返回值也没有关系，所以T在这里就显得有点多余。 再看另一个例子， class Collections &#123; public static &lt;T&gt; void copy(List&lt;T&gt; dest, List&lt;? extends T&gt; src) &#123; ... &#125; 这里的类型参数T就是必须的了，它表明了源列表和目标列表元素的依赖关系，如果没有一个具体的类型参数，这种依赖没法表述。但是如果你写成下面这个样子，就有点画蛇添足了。 class Collections &#123; public static &lt;T, S extends T&gt; void copy(List&lt;T&gt; dest, List&lt;S&gt; src) &#123; ... &#125; 可以说，原则就是尽可能的使用通配符，因为它更加精炼，当通配符达不到目的的时候再使用具体的类型参数。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://pingao777.github.io/tags/Java/"},{"name":"泛型","slug":"泛型","permalink":"https://pingao777.github.io/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"疏而不漏：随机森林","slug":"疏而不漏：随机森林","date":"2017-11-18T01:31:53.000Z","updated":"2020-09-12T03:14:00.590Z","comments":true,"path":"2017/11/18/疏而不漏：随机森林/","link":"","permalink":"https://pingao777.github.io/2017/11/18/%E7%96%8F%E8%80%8C%E4%B8%8D%E6%BC%8F%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/","excerpt":"一、概述在三生万物：决策树中我们提到当决策树和装袋法(Bagging)和提升法(Boosting)结合后会成为更强大的算法，那么今天就介绍一种名叫随机森林(Random Forest)的算法，它是将决策树、装袋法以及随机特征选取结合后衍生出的一种增强型的树算法。","text":"一、概述在三生万物：决策树中我们提到当决策树和装袋法(Bagging)和提升法(Boosting)结合后会成为更强大的算法，那么今天就介绍一种名叫随机森林(Random Forest)的算法，它是将决策树、装袋法以及随机特征选取结合后衍生出的一种增强型的树算法。 它有如下特点： 运行起来非常有效率，可以很容易的并行化 可以无删减的处理成千上万的输入变量，并可以评估变量的重要性 不用将数据专门分为训练集和测试集，随机森林构造完就可以得到近似的测试误差 能够很有效的处理缺失值 可以有效的分离出离群点 对过拟合有很强的抗性 还可以用于非监督式学习…… 看到随机森林有这么多的优点，你是不是心动了呢？那么接下来和我一起来认识一下它吧！ 二、算法1、基本步骤上文提到随机森林不是一种全新的算法，而是几种算法的强强联合。随机森林的构建一般有这么几个步骤： 首先确定树的数量(Tree Size)，而每个树的训练数据通过有放回的抽取原始数据。由于是有放回的抽样，原始数据中约有1/3的量没有被抽到，这些数据称为袋外数据(OOB, Out Of Bag) 树的树训练数据有了，接下来就该训练了，与决策树不同，这里的树在构建的时候，每一次分裂都要进行随机特征选取，也就是在特征的随机子空间进行分裂，比如一个数据集有5个特征，每次分裂有放回的随机取3(Feature Count)个 到这里，所有的树都应该构造完成了，森林也就有了，那么怎么对响应值进行预测呢？这就要依靠集体的智慧了，每个树都有一个预测值，对于分类问题，取频率最高的那个值；对于回归问题，取所有值的平均 2、袋外误差(OOB Error)算法作者说OOB Error可以作为测试误差的无偏估计，也就是计算出OOB Error就可以得到测试误差，不用专门把数据专门拿出来一部分作为测试集。下面举例说明如何计算OOB Error，比如我们要在一个有7条数据的数据集上构建一个5棵树的随机森林，那么在步骤1的时候会出现下面这样一张表: 数据编号 树1 树2 树3 树4 树5 1 X √ √ X √ 2 √ X X X X 3 √ √ √ √ √ 4 √ √ X √ √ 5 √ X √ √ X 6 √ √ X √ √ 7 X √ √ √ √ 表里的X代表没有选中，√代表选中。对于树1，数据1和7就是OOB，对于树2，数据2和5就是OOB，其他以此类推，那么数据1的预测值由树1和树4决定，数据2的预测值由树2-5来决定，以这样的方式计算出每个数据的预测值，进而得到误差值，即OOB Error。 3、变量重要性(Variable Importance)假设我们已经计算出了OOB Error，一个变量的重要性可以这么计算，将变量打散，然后重新计算打散后的OOB Error，取打散前后OOB Error差值的绝对值，越大代表这个变量越重要。变量重要性在实践过程中非常好用，比如在一个10000维度的数据集选出100个最重要的变量，即数据的降维。 4、相似性(Proximities)相似性由相似性矩阵体现，相似性矩阵是一个NxN的对称矩阵，它的计算方式如下，如果数据n和数据p同属于同一颗树的同一个叶子节点，那么相似性加1，即proximities[n,p]和proximities[p,n]均加1，最后除以树的数目进行标准化。 5、离群点(Outliers)有了相似性，也就可以计算离群点了。它基于这样的假设，如果一条数据和其他数据都不相似或者相似性很低，那么这条数据很可能是个离群点。这和人很类似阿，如果一个人不合群，那么他肯定是比较孤立的。不过在我实际操作的过程中，即使计算出了潜在的离群点，如何确定它真的是不是不是那么容易。 具体的计算过程如下，定义类别为j的数据n的平均相似性为： $$\\bar{P}(n) = \\sum_{cl(k)=j}prox^2(n,k)$$ 得到非相似性： $$Dissimilarity(n) = nsample(j) / \\bar{P}(n)$$ 然后在各自的类别中标准化，得到最终的Dissimilarity，算法作者给出的经验值是如果一条数据的Dissimilarity&gt;10，那么可能是一个潜在的离群点。 6、缺失值对于缺失值，传统的方法就是数值变量取均值，分组变量取最多的那一类。而随机森林处理缺失值另有一套：先使用一个不太准确的初始值替换缺失值，然后计算数据间的相似性，数值变量取同一类别非缺失值的相似性加权平均；分组变量取频率最高的值，频率要经过相似性加权，然后重复这一过程4-6次。 三、案例在决策树代码的基础上稍加改动就得到了随机森林，下面检验一下新算法的能力。 1、在三生万物：决策树里我尝试使用花萼长度(Sepal.Length)和花萼宽度(Sepal.Width)这两个变量来预测鸢尾花的种类(Species)，这里用随机森林试一试。 首先来看下不同数目的树对分类的影响，下图的分类边界(Decision Boundary)，使用的Node Size为1，特征数Feature Count也为1, 可以看到，与决策树相比，随机森林对过拟合(Overfit)有着很强的抗性，且随着树的数目增多过拟合越来越少。但是，另一方面也要看到尽管对过拟合很强的抗性，还是可以看到过拟合的影子，即便我们已经用了1000棵树。所以，还是要为随机森林选择一个合适的Node Size, 从上面的第一张图，可以看到Node Size从0～100增加时，OOB Error先降后增，且在Node Size为15时达到最低。从第二张图可以看到随机森林分类边界的变化过程，先是轻微的过拟合继而最合适的边界最后严重的欠拟合。第三张图是最合适的分类边界，尽管和决策树一样，预测的错误率都为0.2左右，但是和决策树的分类边界相比，随机森林的边界更平滑。 2、北京二手房 为了和决策树作对比，我也用随机森林来预测下房价(price)，也是使用区域(area)、是否学区(school)、是否有地铁(subway)、总价(num)这四个变量，使用的参数为树的数目TS=100，特征数Feature Count=4，节点数目Node Size=5，得到的结果如下， $r2 [1] 0.7014904 $importance area 0.48257784 num 0.37338239 school 0.08469551 subway 0.04547572 袋外决策系数R2为0.7，使用模型预测所有房屋价格的决策系数为0.74，比决策树的0.7高了4个百分点，大家不要小看了这4个百分点，在机器学习中哪怕1个百分点都要付出很大的努力。况且，我在这里并没有使用交叉验证获取最佳的参数，只是凭经验选取。另外模型还给出了预测房价各个变量的重要性，可以看到决定房价最重要的就是房子所在的区。 接下来是个分类问题，使用小区(region)、户型(zone)、面积(meters)、朝向(direction)、区域(con)、楼层(floor)、房龄(year)、学区(school)、地铁(subway)、税(tax)、总价(num)、单价(price)来预测区(area)。随机从29790中抽取了10000条数据构造100颗树的随机森林，构建一个100棵树的森林，OOB Error和变量重要性如下， $oob_error [1] 0.1241 $importance con 0.5454 price 0.3717 school 0.1132 year 0.0556 subway 0.0490 region 0.0168 direction 0.0163 meters 0.0043 num 0.0040 zone 0.0026 floor 0.0007 tax 0.0007 OOB Error约为0.12，使用得到的随机森林模型预测29790条房源的区域，误差约为0.08，两者还是比较接近的。不出所料，片区(con)的重要性最高，另外房价(price)、是否学区(school)对房子区域的重要性也决非浪得虚名。 上文提到，随机森林可以作为降维的工具，我从中选择前6个重要的变量重新构建一个随机森林，OOB Error和变量重要性如下， $oob_error [1] 0.11 $importance con 0.5638 price 0.3812 school 0.1140 year 0.0831 subway 0.0490 region 0.0254 可以看到，使用6个变量的OOB Error与使用全部12个变量的OOB Error不相上下。 下面看看有没有潜在的离群点，下图是每套房子的Dissimilarity， 有两套房子的Dissimilarity&gt;10，看看是什么房子， region zone meters direction con floor year school subway tax num price area 福成公寓A 3室1厅 135 南北 燕郊城区二手房 低楼层 2004 无学区 无地铁 非免税 405 30000 燕郊 达观别墅 4室2厅 270 南北 燕郊城区二手房 低楼层 2009 无学区 无地铁 非免税 1600 59260 燕郊 初步看来，这两套房子的总价(num)和价格(price)有点高，是不是这一点让它们鹤立鸡群呢？ 四、总结本文简单介绍了随机森林的特点及算法，并简单分析了iris和北京二手房两个数据集。本文只是抛砖引玉，其实随机森林的还有一些其他的特性，大家可以多多去发掘。 参考资料： Random Forests Leo Breiman and Adele Cutler Random forest","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://pingao777.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"随机森林","slug":"随机森林","permalink":"https://pingao777.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"}]},{"title":"三生万物：决策树","slug":"三生万物：决策树","date":"2017-11-11T08:53:19.000Z","updated":"2020-09-12T03:14:00.586Z","comments":true,"path":"2017/11/11/三生万物：决策树/","link":"","permalink":"https://pingao777.github.io/2017/11/11/%E4%B8%89%E7%94%9F%E4%B8%87%E7%89%A9%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91/","excerpt":"一、概述不知怎么回事，提到决策树我就想起”道生一，一生二，二生三，三生万物“这句话，大概是因为决策树从一个根节点慢慢“长”成一棵树，也要经历“一生二，二生三”的过程。决策树本质上就是一种二叉树，根据特定的标准不停的分成左右两个子树，直到符合某种条件停止。树算法解释性强、简单直观以及接近人的决策方式使它成为流行的机器学习算法之一。当决策树与装袋法(Bag)、提升法(Boosting)结合之后，可以成为更强大的算法。","text":"一、概述不知怎么回事，提到决策树我就想起”道生一，一生二，二生三，三生万物“这句话，大概是因为决策树从一个根节点慢慢“长”成一棵树，也要经历“一生二，二生三”的过程。决策树本质上就是一种二叉树，根据特定的标准不停的分成左右两个子树，直到符合某种条件停止。树算法解释性强、简单直观以及接近人的决策方式使它成为流行的机器学习算法之一。当决策树与装袋法(Bag)、提升法(Boosting)结合之后，可以成为更强大的算法。 决策树按响应值的类型大致分为分类树和回归树，实现决策树的方法也很多，比如CART、ID3、C4.5等等，本文将对CART这种算法进行介绍。 二、算法一棵树要长成要解决两方面的问题，一是如何分，二是何时停。这两点对于分类和回归略有区别，先说如何分，对于定量变量一般是将小于某个值的数据划分为左子树，大于等于某个值的划分为右子树；对于定性变量一般是将等于某个值的划分为左子树，不等于某个值的划分为右子树。那么什么才是一个好的划分呢？分类树大致分为两种，一种是按纯度(Purity)，纯度是通过基尼系数(Gini Index)进行定义的，基尼系数越小，纯度越大，那么划分效果越好。基尼系数的计算方法如下式所示： $$G = \\sum_{k=1}^K\\hat{p}_k(1 - \\hat{p}_k)$$ $\\hat{p}_k$代表第$k$类所占比例，当$\\hat{p}_k$接近0或1时，基尼系数会很小。 另一种标准是互熵(Cross-entropy)，互熵的定义如下： $$D = -\\sum_{k=1}^K\\hat{p}_k\\log\\hat{p}_k$$ 由定义可以看到，和基尼系数类似，当$\\hat{p}_k$接近0或1时，互熵也很小，划分的效果也越好。 回归树则根据方差： $$Variance = \\frac{1}{N}\\sum_{i=1}^N(y_i - \\bar{y})^2$$ $\\bar{y}$代表平均响应值，我们都知道方差是衡量数据变异性的量，因此越小表示回归模型效果越好。 注意上面的纯度、互熵以及方差均是树的一个分枝上的值，总的值要对左右分枝进行加权平均，例如基尼系数的最终值应该这样计算， $$G_{total} = \\frac{N_{left}}{N} G_{left} + \\frac{N_{right}}{N} G_{right}$$ $N$表示总的样本数，$N_{left}$，$N_{right}$分别代表左分枝和右分枝的样本数，互熵和方差的计算方式类似。 说了如何分，那什么时候停呢？一般的惯例是子树中的预测变量或响应值都一样了就可以停止分裂了。有时候这个条件可能有些苛刻，这时候可以设置一个Node Size值，表示叶子节点包含的最小的样本数。分裂过程中如果一个子树的样本数小于等于这个值就停止分裂，分类数取数目最多的那个类，回归树取响应的均值。 说了这么多，下面举个例子，来演示下决策树算法，比如这里有一份城市和农村儿童身高数据，注意这里的数据都是我杜撰的，只是为了演示决策树的算法。如果已知一个儿童身高和性别，如何判断所处的区域？ 身高 性别 地区 100 男 城市 90 女 城市 90 男 农村 80 女 农村 下面尝试根据基尼系数来构造一个分类树，第一次分裂： 身高&lt;100：3/4 x (1/3 x 2/3 + 2/3 x 1/3) + 1/4 x (1 x 0) = 1/3 身高&lt;90：1/4 x (1 x 0) + 3/4 x (2/3 x 1/3 + 1/3 x 2/3) = 1/3 身高&lt;80：0/4 x 0 + 4/4 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2 性别=男：2/4 x (1/2 x 1/2 + 1/2 x 1/2) + 2/4 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2 性别=女：2/4 x (1/2 x 1/2 + 1/2 x 1/2) + 2/4 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2 可以看到前面两个都是1/3，选择哪一个都行，这里我选择第一个最小值：“身高&lt;100”，数据被分为：左子树 身高 性别 地区 90 女 城市 90 男 农村 80 女 农村 右子树 身高 性别 地区 100 男 城市 第二次分裂： 由于右面的子树只有一条数据，因此只需计算左边子树的基尼系数， 身高&lt;90：1/3 x (1 x 0) + 2/3 x (1/2 x 1/2 + 1/2 x 1/2) = 1/3 身高&lt;80：0/3 x 0 + 3/3 x (1/3 x 2/3 + 2/3 x 1/3) = 4/9 性别=女：2/3 x (1/2 x 1/2 + 1/2 x 1/2) + 1/3 x (1 x 0) = 1/3 性别=男：1/3 x (1 x 0) + 2/3 x (1/2 x 1/2 + 1/2 x 1/2) = 1/3 同上选择第一个最低值“身高&lt;90”，数据分成了两部分：左子树 身高 性别 地区 80 女 农村 右子树 身高 性别 地区 90 女 城市 90 男 农村 第三次分裂： 同理，左边子树只有一条数据，只需计算右子树 身高&lt;90：0/2 x 0 + 2/2 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2 性别=女：1/2 x (1 x 0) + 1/2 x (1 x 0) = 0 性别=男：1/2 x (1 x 0) + 1/2 x (1 x 0) = 0 选择“性别=女”这个条件，至此所有的子树的响应值都是唯一的，停止分裂。 最终这个分类树的样子大概如下， 三、树的剪枝其实树的剪枝就是正则化，剪枝一般分为两种：一种称为预剪枝，通过设置Node Size的大小来达到控制树的分枝个数的目的，这种方式简单易用，但有短视的风险；另一种称为后剪枝，原理是让树充分“生长”，然后尝试合并树的分枝，通过对比合并前后错误率是否降低来决定是否真得合并，这种方式效果较前一种好，但是实现稍微复杂一些。 四、说了就练俗话说，光说不练假把式，下面我用R语言实现一个决策树，并尝试分析两个实际的数据集。 1、鸢尾花(iris)数据集，这个数据集包括五个变量：花萼长度(Sepal.Length)，花萼宽度(Sepal.Width)，花瓣长度(Petal.Length)，花瓣宽度(Petal.Width)，种类(Species)，下面尝试使用花萼长度(Sepal.Length)和花萼宽度(Sepal.Width)这两个变量来预测鸢尾花的种类(Species)。 为了简便，我采用的是预剪枝的方式。那么选择多大的Node Size合适呢？关于这个问题通常的方法就是交叉验证(Cross-validation))。下图是采用10折交叉验证(k-fold cross-validation)得到的错误率, 可以看到，当Node Size为40的时候测试集的错误率Eout最低，从另一个方面也可以看到如果不进行剪枝，Eout约为0.4，比剪枝后的错误率高了将近0.2。从下面的第一张图也可以直观的看到当Node Size从小到大增加时，分类边界(Decision Boundary)从过拟合(Overfit)到欠拟合(Underfit)的变化趋势。第二张图是根据交叉验证得到的最佳分类边界，它和Node Size为30的分类边界非常相似。 最终的错误率约为0.2，从上面第二张图可以看到versicolor和virginica这两类的鸢尾花有些数据在二维空间完全重合在了一起，仅仅依靠花萼长度(Sepal.Length)，花萼宽度(Sepal.Width)这两个变量是无法把它们分开的，这个时候单纯的增加样本数无法进一步提高模型的质量，这个时候最好去寻找新的变量，事实上，当加上花瓣长度(Petal.Length)，花瓣宽度(Petal.Width)这两个变量时，预测的错误率可以降低到0.06左右。 树的样子如下， 2、上面是个分类问题，那么再看一个回归问题。北京二手房这个数据集有13个特征，下面使用决策树根据房子的区域(area)、是否学区(school)、是否有地铁(subway)、总价(num)这四个变量来预测房价(price)。 同样，祭出我们的法宝交叉验证得到一个合适的Node Size，如下所示， 对于回归,我采用了决策系数R2作为衡量模型效果的标准，由于R2是越大越好，且0&lt;R2&lt;1，所以这里用1-R2作为模型的误差。和分类树类似，当Node Size从小到大的过程中，模型呈现出了从过拟合到欠拟合的变化过程，显然，当Node Size约为100的时候模型效果是最好的。下图是Node Size为100时从29790条数据中随机选取了10000条进行训练得到的模型，用这个模型预测所有29790条房屋的房价，相对误差((预测房价-实际房价)/实际房价)如下所示， 得到的决策系数R2约为0.7，也就是区域、是否学区、是否有地铁、总价这四个变量解释了70%房价变异。由这个相对误差图可以看出大部分的数据都落在了0附近，实际上有20275条数据落在[-0.2,0.2]，28379条数据落在[-0.5,0.5]。那么，那些误差比较大的都是些什么数据呢？ 下面的数据为相对误差大于3的 area region zone meters direction con floor year school subway tax num price 海淀 东小营甲1号 5室2厅 350 南 西北旺二手房 低楼层 1998 无学区 无地铁 非免税 280 8000 朝阳 北苑家园望春园 1室0厅 36 南北 北苑二手房 地下室 2008 无学区 无地铁 非免税 20 5556 昌平 香堂文化新村二期 5室4厅 460 南北 昌平其它二手房 低楼层 2010 无学区 无地铁 非免税 220 4783 昌平 东亚上北中心 1室0厅 738 北 回龙观二手房 地下室 2007 无学区 无地铁 非免税 370 5012 感觉这些数据好像异常数据，北京还有低于1万的房价？！ 五、总结当一个小小的种子慢慢成长为一颗参天大树，独霸森林一方，常常让人感受生命的强大，而决策树算法同样让人惊叹，易于实现又足够灵活，既能用于分类又能用于回归，也在机器学习领域赢得了一席之地。本文简单介绍了决策树的算法和剪枝，在此基础上用R实现了一个决策树，并在两个数据集上进行了测验，证实了决策树的能力。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"决策树","slug":"决策树","permalink":"https://pingao777.github.io/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"机器学习","slug":"机器学习","permalink":"https://pingao777.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"HTTPS为什么是安全的","slug":"HTTPS为什么是安全的","date":"2016-08-23T09:08:28.000Z","updated":"2020-09-12T03:14:00.580Z","comments":true,"path":"2016/08/23/HTTPS为什么是安全的/","link":"","permalink":"https://pingao777.github.io/2016/08/23/HTTPS%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E5%AE%89%E5%85%A8%E7%9A%84/","excerpt":"HTTP我们都知道是超文本传输协议，HTTPS与HTTP一字之差，它到底是什么呢？引用《HTTP权威指南》的介绍： HTTPS是最常见的HTTP安全版本。它得到了很广泛的应用，所有主要的商业浏览器和服务器上都提供HTTPS。HTTPS将HTTP协议与一组强大的对称、非对称和基于证书的加密技术结合在一起，使得HTTPS不仅很安全，而且很灵活，很容易在处于无序状态的、分散的全球互联网上进行管理。 HTTPS是最常见的HTTP安全版本。多出的S是Security安全的意思，那么它是如何保证安全的呢？","text":"HTTP我们都知道是超文本传输协议，HTTPS与HTTP一字之差，它到底是什么呢？引用《HTTP权威指南》的介绍： HTTPS是最常见的HTTP安全版本。它得到了很广泛的应用，所有主要的商业浏览器和服务器上都提供HTTPS。HTTPS将HTTP协议与一组强大的对称、非对称和基于证书的加密技术结合在一起，使得HTTPS不仅很安全，而且很灵活，很容易在处于无序状态的、分散的全球互联网上进行管理。 HTTPS是最常见的HTTP安全版本。多出的S是Security安全的意思，那么它是如何保证安全的呢？ 我们先看看HTTP和HTTPS通信协议层。 可以看到，相比HTTP，HTTPS多了一个安全层协议SSL/TLS（安全套接层Secure Sockets Layer和传输层安全协议Transport Layer Security，后者是SSL的后继版本），保证安全的秘密就是这个安全层协议。简单说来，HTTPS就是在安全的传输层上传输报文的HTTP。 让我们具体看看，SSL包括两部分：记录协议（record protocol）和握手协议（handshake protocol），前者主要定义了数据格式，后者定义了安全传输客户端/服务器需要交换的具体信息，这是我们要介绍的重点。 握手协议包括下面十个步骤： 客户端向服务器发送SSL协议版本、自己支持的加密方式、随机产生的一段数据。 服务器向客户端发送SSL协议版本、根据双方支持的加密方式确定一个最安全的加密方式、随机产生的一段数据以及自己的数字证书。 客户端验证服务器的合法性，如果合法进行下一步，否则会话终止，包括如下过程： 数字证书是否过期 数字证书是否可信，即证书的颁发机构是否在客户端往往是浏览器的信任列表 数字证书的公钥能否验证数字签名，即数字签名的合法性，这个过程参见数字签名是什么 域名是否与证书的域名匹配 如果第3步中服务器合法，客户端使用使用到目前产生的所有数据为本会话生成一个预置密码（ premaster secret），然后使用服务器的公钥加密预置密码，将密文发送给服务器。 如果服务器要求对客户端进行验证（可选），客户端会将签名数据和证书连同预置密码密文一并发给服务器。 服务器对客户端进行验证，过程与第3步类似。验证不通过会话终止，验证通过，服务器使用私钥解密预置密码，然后执行一系列步骤（客户端会同时执行同样的步骤）生成主密钥（master secret）。 客户端和服务器使用主密钥生成会话密钥（session key），这就是加密后面所有数据的对称密钥。 客户端发送一条消息通知服务器以后的数据都将使用会话密钥加密，然后再发送一条消息表明握手过程的客户端部分完成。 服务器也发送一条消息通知客户端以后的数据都将使用会话密钥加密，然后再发送一条消息表明握手过程的服务器部分完成。 握手过程完成，SSL会话开始使用会话密钥传输数据。 可以看到整个握手过程既包括非对称加密又包括对称加密，先用非对称密钥传送对称密钥，再用对称密钥传送后面的数据，充分利用了两种加密方式的优势，参见加密和解密。 回到开头的问题，HTTPS如何保证安全呢？兵法云：知己知彼百战百胜，我们知道互联网安全三大威胁：窃听、篡改和伪装，假如让我们作为攻击者，该如何去做呢？ 事实上，上面十个步骤中第1、2步是明文传输的，我们可以对这两步的信息进行拦截得到双方的协议版本、加密方式、随机数以及服务器证书，然后原封不动的将相应信息再发送给对方，我们在通信中间扮演一个伪装者，对客户端来说我们就是服务器，对服务器来说我们就是客户端。现在来到第3步，客户端对我们的攻击全然不知，还把我们当成真正的服务器，客户端验证我们发送给它的数字证书，结果肯定是通过的，因为我们是将服务器的数字证书原封不动的发过去的。接着客户端将预置密码加密然后发送给服务器，这个信息肯定也没法逃脱我们的火眼金睛，但是我们拿过拦截到的信息一看有点傻眼了，由于我们没有服务器密钥，无法进行解密，也就无法得到预置密码，接下来的步骤就无法进行，客户端这时候就反应过来了，等了这么久没反应，对方肯定就问题，会话终止。至于其他的步骤，都是加密数据，窃听篡改没什么意义，这样，三大威胁就被解决了。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Http","slug":"Http","permalink":"https://pingao777.github.io/tags/Http/"},{"name":"Https","slug":"Https","permalink":"https://pingao777.github.io/tags/Https/"}]},{"title":"加密和解密","slug":"加密和解密","date":"2016-08-22T08:40:34.000Z","updated":"2020-09-12T03:14:00.589Z","comments":true,"path":"2016/08/22/加密和解密/","link":"","permalink":"https://pingao777.github.io/2016/08/22/%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86/","excerpt":"最近学习HTTPS的知识，涉及了一些加密和解密的内容，在Mozilla MDN上找到一篇文章Encryption and Decryption，清晰明了，特地翻译一下，与大家分享。 加密（Encryption ）是将原始信息转化为对其他用户非明了信息的过程，除非信息的接受者；解密（Decryption）是将非明了信息转化为原始数据的过程。加密算法，也称作密码（cipher， 注：与传统意义上的密码不同），是一种用来加密和解密的数学函数。在大多数情况下，会同时采用两个相关的函数，一个用作加密，另一个用作解密。 当今的大多数加密技术保持信息私密并不依靠算法本身，因为算法都是众所周知的，而是依靠加密和解密的密钥（key）。使用正确的密钥进行解密轻而易举，而使用不正确的密钥想进行解密是非常困难的，在某些实际情况下，可以说是不可能的。 本篇文章将从下面三个方面介绍密钥在加密和解密中的用处： 对称密钥加密（Symmetric-Key Encryption） 公钥加密（Public-Key Encryption，也称作非对称密钥加密） 密钥长度和加密强度","text":"最近学习HTTPS的知识，涉及了一些加密和解密的内容，在Mozilla MDN上找到一篇文章Encryption and Decryption，清晰明了，特地翻译一下，与大家分享。 加密（Encryption ）是将原始信息转化为对其他用户非明了信息的过程，除非信息的接受者；解密（Decryption）是将非明了信息转化为原始数据的过程。加密算法，也称作密码（cipher， 注：与传统意义上的密码不同），是一种用来加密和解密的数学函数。在大多数情况下，会同时采用两个相关的函数，一个用作加密，另一个用作解密。 当今的大多数加密技术保持信息私密并不依靠算法本身，因为算法都是众所周知的，而是依靠加密和解密的密钥（key）。使用正确的密钥进行解密轻而易举，而使用不正确的密钥想进行解密是非常困难的，在某些实际情况下，可以说是不可能的。 本篇文章将从下面三个方面介绍密钥在加密和解密中的用处： 对称密钥加密（Symmetric-Key Encryption） 公钥加密（Public-Key Encryption，也称作非对称密钥加密） 密钥长度和加密强度 对称密钥加密在对称密钥加密中，加密密钥可以由解密密钥推知，反之亦然。事实上，在很多情况下，二者是相同的，如下图所示。 对称密钥加密效率非常高，以至于用户几乎察觉不到加密和解密的延迟。对称密钥加密还提供了一定程度的认证机制，因为信息一旦经密钥加密，不可能被其他密钥解密。因此，只要密钥没有泄露且信息可以正确的解密，通信双方都能确定是在与对方通信。 只有在通信双方保持密钥不被泄露的情况下，对称密钥加密才是有效的。如果其他人发现了密钥，将会影响双方的私密性和身份认证。一个未经授权的用户不仅可以使用密钥解密消息，还可以加密和发送一条新消息给通信中的一方，就好像它是拥有此密钥的另一方一样。 对称密钥加密在SSL协议中扮演着重要的角色，它广泛地应用在身份认证、篡改监测以及 TCP/IP网络加密中。另外，SSL也使用了公钥加密，下一节将介绍这种技术。 公钥加密公钥加密最常用的实现是基于RSA Data Security的专利算法，因此，本节将以RSA这种方式介绍公钥加密。 公钥加密包括一对密钥：一个公钥和一个私钥——还有对其进行电子认证、签名和数据加密的实体。公钥是公开的，而对应的私钥是保密的。公钥加密的数据只能被对应的私钥解密。下图简单展示了公钥加密的工作方式。 上图这种方案可以让你自由发布一个公钥，只有你才能使用公钥读取加密的数据。一般情况下，为了给某些人发送加密数据，你首先使用那人的公钥进行加密，那人收到加密数据后使用对应的私钥进行解密。 对比对称密钥加密，公钥加密需要更大的计算量，因此当数据量比较大时，这种加密方式就不太合适了。然而，可以使用它发送一个对称密钥，然后再用这个对称密钥加密另外的数据（注：这里有两个过程，第一步公钥加密，第二步对称密钥加密）。SSL正是使用的这种方式。 就像上图显示的那样，上面的方案反过来同样适用（注：我觉得原文说反了，图中展示的就是这种方案）：使用私钥加密，然后使用对应的公钥解密。对于敏感数据，这不是一个理想的方式，因为根据定义，拥有公钥的任何人都可进行解密。尽管如此，使用私钥进行加密这种方式还是非常有用的，因为这意味着你能够使用你的私钥进行电子签名，这在电子商务及其他商业应用程序加密中非常重要。客户端程序比如Firefox能够使用你的公钥来确认这份使用你的私钥加密的消息是否被篡改。数字证书是什么这篇文章介绍了这个确认过程。 密钥长度和加密强度破解一个加密算法就是要找到将加密数据变为原始数据的密钥。对于对称密钥加密来说就是要找到进行数据加密的密钥，对于公钥加密来说，就是获得通信双方的私钥。 破解对称密钥加密的一个方式是挨个测试算法中的每个密钥直到找到正确的密钥。对于公钥加密，密钥对中的一个（公钥）是公开的，另一个（私钥）经过已经公布的复杂数学计算得到。挨个测试密钥的方法被称作暴力破解法。 加密算法被破解将会带来私密信息被拦截、被冒充甚至被欺诈的风险。 加密算法的密钥强度是由破解此算法的最快方法与暴力破解法的速度对比值确定（注：意思是最快的破解方法和暴力破解速度差不多那么密钥强度高，如果最快的破解方法比暴力破解快得多那么密钥强度低）。 对于对称密钥，加密的强度是由加密密钥的长度或者大小确定的：一般情况下，密钥越长，强度越高。密钥长度是使用位（bit）进行衡量的。例如，SSL协议的RC4对称密钥加密算法，128位的密钥要比40位的密钥安全的多。大致来说，128位的RC4加密强度是40位的RC4加密强度的3 x 1026倍（关于SSL中RC4加密的更多信息，详见Introduction to SSL）。如果加密密钥已知最快的破解方法和暴力破解差不多，那么就可以说这个密钥是强力的（full strength）。 不同的加密算法可能需要不同的密钥长度来达到同样的加密强度。例如，公钥加密中的RSA算法，因为它所基于数学原理，密钥只能是给定长度所有值的一个子集。其他加密算法，比如对称密钥加密的用到的算法，密钥可以是给定长度所有值，而不只是一个子集。 因为RSA密钥破解起来相对容易，RSA加密算法的密钥长度要比较长，为了达到较高的加密强度，至少要达到1024位。相比之下，对于对称密钥加密的大部分算法，达到同样的加密强度，密钥长度只需要80位。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"加密","slug":"加密","permalink":"https://pingao777.github.io/tags/%E5%8A%A0%E5%AF%86/"},{"name":"解密","slug":"解密","permalink":"https://pingao777.github.io/tags/%E8%A7%A3%E5%AF%86/"}]},{"title":"数字签名是什么","slug":"数字签名是什么","date":"2016-08-20T03:49:30.000Z","updated":"2020-09-12T03:14:00.590Z","comments":true,"path":"2016/08/20/数字签名是什么/","link":"","permalink":"https://pingao777.github.io/2016/08/20/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E6%98%AF%E4%BB%80%E4%B9%88/","excerpt":"","text":"随着现在网银、电子商务的普及，“数字签名”屡屡被提到，我也曾一度迷惑，直到看到Mozilla MDN上的一篇文章Digital Signatures，下面我将翻译一下这篇文章。 加密和解密解决了三大互联网安全隐患（窃听、篡改、伪装）之窃听的问题，但是却没法避免信息被篡改。 本篇文章将向你介绍公共秘钥加密如何解决这个问题。 信息篡改及相关的认证技术依赖于一个数学函数单向哈希函数（one-way hash，也称作信息摘要）。单项散列函数可以根据原始数据生成一个定长的数据摘要，并且具有如下特性： 原始数据不同，摘要不同（注：严格说来这句话不对，当数据大到一定程度，会发生碰撞的可能，但是概率实在太小了，可以忽略不计）。只要修改或者删除原始数据中哪怕一个字符，摘要都会发生显著的改变。 原始数据不可能由摘要推出，这也是单向哈希的名字由来。 同样地，在公共密钥加密中为了进行数字签名，要产生一对秘钥（key），一个称为私有签名秘钥（private signing key ），一个称为公开验证秘钥（public verification key）。后者是公开的，前者是保密的，只有所有者知道。二者在数学上有一定的联系，想从公开验证秘钥推出私有签名秘钥几乎是不可能的或者要付出高昂的代价（注：比如时间、金钱）。摘要及其他相关信息，连同哈希算法，一并被称为数字签名。 下图简单展示了数字签名如何验证数据的合法性。 上图显示发送者将两份数据发送给接受者：一份原始数据，一份加密过的摘要数据，即用私钥和相关的单向哈希算法加密过的数据摘要（注：这里有两个过程，第一步求数据摘要：原始数据-&gt;摘要，第二步加密：摘要-&gt;加密过的摘要）。为了验证数据的合法性，接受者首先使用签名者的公钥对加密摘要进行解密得到摘要，然后对原始数据应用同样的单向哈希算法得到一份新的摘要（单项哈希算法会和数据一并发送给接受者，图中未标出），最后，接受者对比这两份摘要。如果二者一致，那么说明数据没有篡改，否则数据可能被篡改或者发送过来的公钥和签名者的私钥不匹配。 如果两份摘要一致，接受者就能确定解密签名的公钥和生成签名的私钥是匹配的，然后进一步确认签名者的身份，尽管要确认签名者的身份还需要其他一些步骤来确定这个公钥确实属于某个人或实体，详见Introduction to Public-Key Cryptography. 数字签名的意义堪比手写签名。如果秘钥没有失去所有者的控制，一旦签名，过后很难进行否认。数字签名的这个特性提供了高度的不可否认性，签名者签名后就无法抵赖。以致在一些情形中，数字签名具有手写签名的同等法律效力。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Http","slug":"Http","permalink":"https://pingao777.github.io/tags/Http/"},{"name":"加密","slug":"加密","permalink":"https://pingao777.github.io/tags/%E5%8A%A0%E5%AF%86/"},{"name":"解密","slug":"解密","permalink":"https://pingao777.github.io/tags/%E8%A7%A3%E5%AF%86/"}]},{"title":"他们征友（婚）时，他们征什么？","slug":"他们征友（婚）时，他们征什么？","date":"2016-08-17T14:06:53.000Z","updated":"2020-09-12T03:14:00.588Z","comments":true,"path":"2016/08/17/他们征友（婚）时，他们征什么？/","link":"","permalink":"https://pingao777.github.io/2016/08/17/%E4%BB%96%E4%BB%AC%E5%BE%81%E5%8F%8B%EF%BC%88%E5%A9%9A%EF%BC%89%E6%97%B6%EF%BC%8C%E4%BB%96%E4%BB%AC%E5%BE%81%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"有道是年年岁岁花相似，岁岁年年征友人，征友贴一茬又一茬，简历投了一波又一波，为什么迟迟得不到回复？当男女征友时，他们到底在征什么？你真的看懂征友贴了吗？你还在为你屡屡投条未收到答复而苦恼吗？你还在为简历被女神刷掉自怨自艾吗？","text":"有道是年年岁岁花相似，岁岁年年征友人，征友贴一茬又一茬，简历投了一波又一波，为什么迟迟得不到回复？当男女征友时，他们到底在征什么？你真的看懂征友贴了吗？你还在为你屡屡投条未收到答复而苦恼吗？你还在为简历被女神刷掉自怨自艾吗？ 本文以北邮人论坛征友贴为主要原料，使用独家秘制八卦手法，希望从中发现一些有意思的事，本着娱乐至上，看热闹不嫌事大的原则，有些观点和分析请观者自行甄别，图例中F(emale)代表女生，M(ale)代表男生。 一、总体情况首先是大家喜闻乐见的我邮男女比例，如下图所示， 我从论坛总共扒拉下来274个帖子，其中女征男148个，男征女126个，男女比例大概是1:1.17，好像并没有想象的那么悬殊。从年龄上看征友的主力军还是80后，如下所示， 80后约占66%，几乎是90后的两倍，且男女比例基本持平，是啊90后都26了，80后压力好大啊，想静静。值得一提的是90后征友者，女生明显比男生多。从平均年龄上来看，男生为27.9，女生为27.7，女生稍小。整个年龄区间主要集中在26 ~ 30， 女生中26、27岁的占了四分之一。 下面再来看看大家的发帖时间吧， 可以看到，帖子的发布时间集中在晚上23点左右，这可能是和论坛的十大机制有关系，大家选在这个点发帖，目标是为了十大。有几个帖子是在凌晨发的，但都是男征女，看来女神们都很注重养生啊，不熬夜。一周七天，周一、周二和周末两天帖子数稍多，中间三天稍微少点，总体差别不如上面时间那么明显。 二、征友关键词接下来，重点来了，回到开头我们提出的问题，当男女征友时他们在征什么？ 1、征友者说我选取了男女征友者都提到的高频词，列举如下， 除了“工作”、“生活”、“喜欢”、“性格”、“身高”这些千篇一律的词，还有一些有趣的词。不知道大家注意到那个扎眼的“山东”没，因为身为山东人，对“山东”这个字眼比较敏感，这么多词只有一个关于地域的词汇就是“山东”，我很纳闷为什么“山东”出现在这里，山东人那么多没对象吗，我统计了下，平均约12%的帖子提到了山东。我不知道是山东人征友的比较多还是山东人比较受征友者的欢迎，不管怎样我就当成后者吧，哈哈。大家经常议论的“京户”也出现了，约有14%的帖子，不算很多。另外“感情经历”都是双方比较重视的一点，其他的大家自己看看吧。 2、男生vs女生都说”男人来自火星，女人来自金星“，看过了男女生共同的话题，接下来看看两个来自不同星球的生物有哪些差别呢。 男生说的可以总结为：好“哥们”生于“86年”、“88年”，“收入”不错，有“户口”，有“能力”，“技术”过硬，爱好“羽毛球”、“游泳”、“健身”等，身体“健康”，寻“通情达理”，身高“160”以上妹子，插一句男生那么多都喜欢“羽毛球”吗，感觉没那么多啊。 女生可以总结为：单位“姐姐”、多年“闺蜜”生于“87年”、“90年”、“91年”，“活泼”可爱，性格“独立”，“喜欢运动”，会“做饭”，喜欢“孩子”，寻觅人“在北京”，“有责任”、“有上进心”，成熟“稳重”，“170”、“175”以上汉子，“非诚勿扰”，“哈哈哈”。 是的，我们又看到了万恶的“175”，可以看到男生更多的提到表示自己客观实力的字眼，女生则比较喜欢用一些主观一些的词汇。男生对女生最多的要求是“通情达理”，女生对男生最多的要求是“有责任”。 3、80后vs90后是的我又带节奏了，都说“80后是XXX的一代，90后是XXX的一代”，那么这两代人在择偶观上有没有差别呢？ 80后男生可以总结为“寒窗苦读十余载，一朝成名在今朝，高头马，黄金屋，良人你咋还不来”，90后男生则是“世界那么大，未来那么远，唯一不变的就是寻觅你的心，亲爱的，你在哪里”。 80后女生“爱过，痛过，笑过，哭过，姐累了，想结婚了”，90后女生“爱哭爱笑，爱美食爱运动，一直在路上，我要我自己的未来”。 很明显，80后和90后说的话还是挺不一样的，80后可能更“现实”了。不过我不认为这是出生年代造成的，我更愿意把这看成年龄大小的差别，或者更残酷点，成熟与否的区别，就像现在的自己和20岁那年的自己相比，确实有那么一点不同。 至此，相信你已经大概了解男女征友需求了，下次投简历更有针对些吧。不过这可能并没有什么卵用，毕竟一个看脸的社会-_-。 最后祝征友者都能找到理想的另一半，应征者都能面试成功，该玩的年纪勇敢去玩，该爱的年纪勇敢去爱！","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://pingao777.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"name":"R","slug":"R","permalink":"https://pingao777.github.io/tags/R/"}]},{"title":"简洁高效的Boyer-Moore算法","slug":"简洁高效的Boyer-Moore算法","date":"2016-07-31T13:40:41.000Z","updated":"2020-09-12T03:14:00.591Z","comments":true,"path":"2016/07/31/简洁高效的Boyer-Moore算法/","link":"","permalink":"https://pingao777.github.io/2016/07/31/%E7%AE%80%E6%B4%81%E9%AB%98%E6%95%88%E7%9A%84Boyer-Moore%E7%AE%97%E6%B3%95/","excerpt":"子串检索有着很广泛的应用，例如在文档软件中查找关键词，网站过滤敏感词，生物学家查找某种模式的基因组序列等等，很多人听说过著名的KMP算法，Boyer-Moore算法做到的更多，有迹象表明在某些情况下效率是前者的3-5倍，且实现起来更加简单，符合我简单高效的原则。","text":"子串检索有着很广泛的应用，例如在文档软件中查找关键词，网站过滤敏感词，生物学家查找某种模式的基因组序列等等，很多人听说过著名的KMP算法，Boyer-Moore算法做到的更多，有迹象表明在某些情况下效率是前者的3-5倍，且实现起来更加简单，符合我简单高效的原则。 下面先抛开算法不谈，如果让你在ABCSAKDFFEHHJDDEFKLD中查找DDEFK，你会怎么做？ ABCSAKDFFEHHJDDEFKLD DDEFK 最直接的就是暴力检索法，挨个比较文本和模式的每个字符，成功就继续比较模式字符的下一个，否则将模式往右移动一位，继续上述过程，直到文本的结尾或者搜索成功，通常情况下效率还可以，因为对于大部分文档往往只需要比较模式中的一两个字符，就会有非匹配字符，因此模式可以快速的向右移动，整体运行时间接近线性。java示例代码为 int M = pat.length(); int N = txt.length(); for(int i = 0; i &lt;= N - M; i++) &#123; for (int j = 0; j &lt; M; j++) &#123; if (txt.charAt(i + j) != pat.charAt(j)) &#123; break; &#125; if (j == M - 1) &#123; return i; &#125; &#125; &#125; return -1; 而本文的主角BM算法可谓别出心裁，它从后往前匹配模式的每一个字符，看看BM算法是如何处理上面的例子的，我们用i表示文本的起始位置，j表示模式中待匹配字符的位置。 第一步，i=0，j=4，A与K匹配失败，没有必要再往前匹配，i往后移动4+1=5个字符，因为小于这个数字，A都会与模式中的某个字符重叠，而模式中没有这个字符，无论如何都会失败。 i=0 ABCSAKDFFEFKJDDEFKLD DDEFK j=4 第二步，i=5，j=4，E与K匹配失败，i需要再次往后移动，这次需要移动几个字符呢，答案是2，这样会将模式中最右边的E与文本中E对齐，小于这个数，文本中E会与模式E右边的字符重叠，这些字符中没有E，因此不可能成功。 i=5 ABCSAKDFFEFKJDDEFKLD DDEFK j=4 第三步，i=7，j=4，这次匹配成功了，j减一j=3，又成功了，j再减一j=2，又成功了，j再减一j=1，这次F与D没有匹配成功，这次i要移动多少呢，F在文本和模式中都出现了，但是模式中的F已经匹配过了，我们不想让i回退，只能让i简单的加1。 i=7 ABCSAKDFFEFKJDDEFKLD DDEFK j=4 j=3 j=2 j=1 第四步，i=8，j=4，同样J和K匹配失败，且J不在模式字符串中，同第一步，我们将i移动4+1=5个字符。 i=8 ABCSAKDFFEFKJDDEFKLD DDEFK j=4 第五步，i=13，k=4，当j=4…0时，每个字符都匹配成功，成功检索到模式，将i=13返回，或者将i的值存储起来继续往后搜索，如果想得到模式的所有位置。 i=13 ABCSAKDFFEFKJDDEFKLD DDEFK j=4 j=3 j=2 j=1 j=0 这样i移动5次，总共比较了12个字符，就完成了查找。 总结一下，BM算法的策略是从后往前匹配模式中的每个字符，直到文本中出现一个不匹配的字符txt.charAt(i+j)或者检索成功返回i。与暴力检索不同的是，当匹配失败时，BM算法不会按部就班的移动i，它首先会构造一个right数组，数组中存储的是字符集中每个字符在模式中最右边的位置，如果字符不在模式中设为-1，比如上面的例子， right[&#39;D&#39;]=1 right[&#39;E&#39;]=2 right[&#39;F&#39;]=3 right[&#39;K&#39;]=4 下面是可能出现的三种情形， 当非匹配字符txt.charAt(i+j)不在模式中时，就像上面第一步那样，i需要右移j+1个字符，否则非匹配字符就会与模式字符串的某个字符重叠。 当非匹配字符txt.charAt(i+j)是模式中一员时，如上第二步那样，i需要右移j-right[txt.charAt(i+j)]，小于这个步数也会发生重叠。 第三种情形其实是第二种情形的补充，虽然非匹配字符txt.charAt(i+j)在模式中，但是已经比较过，这样j-right[txt.charAt(i+j)] &lt; 1，这种情形下只让i简单的右移1位。 这是一段示例代码， public List&lt;Integer&gt; search(String txt) &#123; int N = txt.length(); int M = pat.length(); List&lt;Integer&gt; pos = new ArrayList&lt;&gt;(); for (int i = 0, skip = 0; i &lt;= N - M; i += skip) &#123; for (int j = M - 1; j &gt;= 0; j--) &#123; if (pat.charAt(j) != txt.charAt(i + j)) &#123; skip = j - right[txt.charAt(i + j)]; if (skip &lt; 1) &#123;skip = 1;&#125; break; &#125; if (j == 0) &#123; pos.add(i); skip = M; break; &#125; &#125; &#125; return pos; &#125; 上面的代码会找出文本中模式出现的所有位置，在大部分情况下，上面这段代码的运行效率为$O(N/M)$，但是，当文本中包括大量的重复字符时，搜索的效率为$O(NM)$，请看下面的例子， txt length: 20 pat length: 5 -------------------- BBBBBBBBBBBBBBBBBBBB ABBBB #0 0 ABBBB #1 5 ABBBB #2 10 ABBBB #3 15 ABBBB #4 20 ABBBB #5 25 ABBBB #6 30 ABBBB #7 35 ABBBB #8 40 ABBBB #9 45 ABBBB #10 50 ABBBB #11 55 ABBBB #12 60 ABBBB #13 65 ABBBB #14 70 ABBBB #15 75 每一步后面有两个数字，第一个数字表示i移动的次数，后一个表示比较的字符数，如上所示，这个例子i移动了15次，总共比较了75个字符，接近于20*5，效率为$O(NM)$。这不是我们想看到的，为了应对这种情形需要引进另一个数组delta，delta数组中存储的是文本中每个字符最后出现的地方，默认值为模式的长度，这样当遇到非匹配字符txt.charAt(j)时至少delta[pat.charAt(j)]-j这一段是不可能匹配的，因为在文本中这一段没有出现pat.charAt(j)，比较的时候就有了两个移动距离，取其大者。下面是新的代码， public List&lt;Integer&gt; search(String txt) &#123; int N = txt.length(); int M = pat.length(); List&lt;Integer&gt; pos = new ArrayList&lt;&gt;(); for (int i = 0, skip = 0; i &lt;= N - M; i += skip) &#123; for (int j = M - 1; j &gt;= 0; j--) &#123; char c1 = txt.charAt(i + j); char c2 = pat.charAt(j); delta[c1] = j; if (c1 != c2) &#123; int skip1 = j - right[c1]; int skip2 = delta[c2] - j; skip = Math.max(skip1, skip2); if (skip &lt; 1) &#123;skip = 1;&#125; break; &#125; if (j == 0) &#123; pos.add(i); skip = M; resetDelta(); break; &#125; &#125; &#125; return pos; &#125; 每次匹配成功，需要重置delta数组，即上面resetDelta()。将这段代码与上面那一版进行对比，看看有哪些区别。完整代码在这里，用这一段代码再运行上面的例子， txt length: 20 pat length: 5 -------------------- BBBBBBBBBBBBBBBBBBBB ABBBB #0 0 ABBBB #1 5 ABBBB #2 10 ABBBB #3 15 这次好多了，i移动了3次，只比较了15个字符，就完成了整个检索，算法复杂度基本为线性。好了，算法分析与证明不是那么有意思，最后就以我做的两个实验来结束吧。 横轴为文本长度，纵轴表示比较的字符数，文本和模式从26个大写字母随机生成。可以看到，对于长度为10的模式，BM算法复杂度大约为$O(N/M)$，暴力检索为$O(N)$。 与上图不同，这幅图的文本和模式是从4个大写字母随机选择，因此重复率要高的多。可以看到，对于重复率很高的字符串，BM算法效率也能达到$O(N)$，而暴力检索接近$O(NM)$。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://pingao777.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Javascript中的this","slug":"Javascript中的this","date":"2016-03-27T15:07:42.000Z","updated":"2020-09-12T03:14:00.582Z","comments":true,"path":"2016/03/27/Javascript中的this/","link":"","permalink":"https://pingao777.github.io/2016/03/27/Javascript%E4%B8%AD%E7%9A%84this/","excerpt":"对于js的函数有两个特殊的关键字，this和arguments，后者存储的是函数的参数，类似于一个数组。例如如下的函数， var testArgus = function() &#123;console.log(arguments);&#125; // [1, 2] testArgus(1,2)","text":"对于js的函数有两个特殊的关键字，this和arguments，后者存储的是函数的参数，类似于一个数组。例如如下的函数， var testArgus = function() &#123;console.log(arguments);&#125; // [1, 2] testArgus(1,2) arguments的含义比较明确，而this就不那么直白了，this指代的是函数运行时所处的上下文。这句话有两点需要注意：一是this是在运行时决定的，也就是函数在调用之前this的值是不确定的，二是函数所处的上下文，也就是函数运行时所处的环境。 首先看看什么是上下文，对比下面的代码，注意它们的差别。 var o = &#123;testThis: function() &#123;return this;&#125;&#125;; var b = &#123;testThis: function() &#123;return this;&#125;()&#125;; o.testThis(); b.testThis; 它们的分别会输出什么？事实上，前者会输出Object，也就是o本身；后者会输出window，也就是全局对象。如果感到疑惑，再看《JavaScript高级程序设计》中的一个例子， window.color = &quot;red&quot;; var o = &#123;color: &quot;blue&quot;&#125;; function sayColor() &#123; alert(this.color); &#125; // &quot;red&quot; sayColor(); o.sayColor = sayColor; // &quot;blue&quot; o.sayColor(); 需要明确的是，函数的名字仅仅是一个包含指针的变量而已。即使是在不同的环境中执行，全局的sayColor()和o.sayColor()指向的仍然是同一个函数。前者在全局作用域调用，因此this指向的是window，因此输出”red”，当把这个函数赋给对象o并调用o.sayColor()时，this引用的是对象o，因此会输出”blue”。再回头看上面的代码，匿名函数在b中执行，并没有附加到任何对象，实际上相当于在window中执行，因此返回this，指向的是window。 事实上this有那么一条规律，如果调用函数时是以构造函数的形式，即new函数的形式，this会指向创建的新变量，如果是以普通函数的形式调用，this指向的是全局变量。还是老样子，用代码说话。 var Flower = function(name) &#123;this.name = name;&#125; // error alert(name); var f1 = Flower(&quot;f1&quot;); // &quot;f1&quot; alert(name); var f2 = new Flower(&quot;f2&quot;); // &quot;f1&quot; alert(name); // &quot;f2&quot; alert(f2.name); 根据这条规律，也可以解释为什么b.testThis为什么指向window，匿名函数在b中执行，是以普通函数的形式被调用，因此this指向的是全局变量，即window。 既然说到了this，就不得不提call和apply，js中这两个函数用来改变函数所处的上下文，也就是this的指向。例如上面的代码， window.color = &quot;red&quot;; var o = &#123;color: &quot;blue&quot;&#125;; function sayColor() &#123; alert(this.color); &#125; // &quot;blue&quot; sayColor.call(o); call和apply用法一样，只是接受的参数不一样，二者第一个参数都代表新的上下文，call接受逗号分隔的各个参数，apply接受数组形式的参数。要注意到，sayColor并不是o的一个方法，但是通过call我们却可以像使用自身的方法一样来调用一个函数，这提供了极大的灵活性，在各大js库中十分常见。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://pingao777.github.io/tags/Javascript/"}]},{"title":"Oracle中的高水位线","slug":"Oracle中的高水位线","date":"2016-03-25T01:37:21.000Z","updated":"2020-09-12T03:14:00.583Z","comments":true,"path":"2016/03/25/Oracle中的高水位线/","link":"","permalink":"https://pingao777.github.io/2016/03/25/Oracle%E4%B8%AD%E7%9A%84%E9%AB%98%E6%B0%B4%E4%BD%8D%E7%BA%BF/","excerpt":"","text":"高水位线(High Water Mark, HWM)类似于一个指针，用来标识分配给段(segment)的块(block)状态。块是Oracle中数据分配和操作的最小单位，段是类似于表、索引这样的数据库实体。块有下面几种状态： 在HWM之上，块是未格式化和未使用的(unformated and unused) 在HWM之下，块又有下面几种状态： 分配的(allocated)，但是还未格式化 格式化并且存有数据 格式化但是没有数据，delete操作会造成这种状态 另有一个低水位线的概念(Low HWM)，处于Low HWM之下的块都是格式化的，处于Low HWM和HWM之间有可能格式化也可能未格式化。示意图如下， -- ============================================================= -- &lt;-formated--&gt;Low HWM&lt;----allocated-----&gt;hwm&lt;-----empty----&gt;total -- ================^========================^===================^ HWM有如下特点： 一般情况下只升不降，只有在truncate、move、shrink等操作才会降低，delete不会降低，delete后留下的空间，以后insert可以使用。 执行全表扫描时，数据库扫描Low HWM以下所有的块，不管有没有数据，读取两个水位线之间的块时则要小心一点，因为这中间的块并不一定都是格式化的。如果频繁的删除插入操作，会在HWM下的块中留下大量碎片，影响性能。 当insert和update的时候，数据库在Low HWM和HWM之间或者Low HWM之下的空余空间进行写入。 可是为什么要设置一个HWM呢？既然有了一个位图块记录块的状态，为什么要设置一个水位线，全表扫描时还要扫描下面的所有块，而不是那些有数据的？这不是出力不讨好吗，百度了半天，没找到满意的答案，基本上大家都是说“它是这样的”，而没有说“它为什么是这样的”，知道的告诉一声。 下面是检测表水位线的一个小程序： PROCEDURE P_TABLE_HWM_ANALYSE(TABLE_NAME IN VARCHAR2) IS -- 表占用空间高水位检测 LVC_TABLE_TMP VARCHAR2(50); LVC_MB NUMBER; -- 表的大小MB LVC_TOTAL NUMBER; -- 总的block数 LVC_BLOCKS NUMBER; -- 水位线，即hwm LVC_EMPTY_BLOCKS NUMBER; -- 空余block LVC_USED NUMBER; -- 使用的block LVC_USED_PERCENT NUMBER; -- 使用百分比，LVC_USED/LVC_TOTAL LVC_HWM_PERCENT NUMBER; -- 水位线百分比，LVC_BLOCKS/LVC_TOTAL LVC_USED_PERCENT_POS NUMBER; LVC_HWM_PERCENT_POS NUMBER; BEGIN LVC_TABLE_TMP := UPPER(TABLE_NAME); EXECUTE IMMEDIATE &#39;ANALYZE TABLE &#39; || LVC_TABLE_TMP || &#39; ESTIMATE STATISTICS&#39;; SELECT ROUND(SUM(DECODE(BYTES, NULL, 0, BYTES)) / 1024 / 1024, 1), SUM(DECODE(BLOCKS, NULL, 0, BLOCKS)) INTO LVC_MB, LVC_TOTAL FROM USER_SEGMENTS WHERE SEGMENT_NAME = LVC_TABLE_TMP GROUP BY SEGMENT_NAME; SELECT DECODE(BLOCKS, NULL, 0, BLOCKS), DECODE(EMPTY_BLOCKS, NULL, 0, EMPTY_BLOCKS) INTO LVC_BLOCKS, LVC_EMPTY_BLOCKS FROM USER_TABLES WHERE TABLE_NAME = LVC_TABLE_TMP; EXECUTE IMMEDIATE &#39;SELECT COUNT(DISTINCT DBMS_ROWID.ROWID_BLOCK_NUMBER(ROWID) || DBMS_ROWID.ROWID_RELATIVE_FNO(ROWID)) FROM &#39; || LVC_TABLE_TMP INTO LVC_USED; IF LVC_TOTAL = 0 THEN LVC_USED_PERCENT := 0; LVC_HWM_PERCENT := 0; ELSE LVC_USED_PERCENT := ROUND(LVC_USED / LVC_TOTAL * 100); LVC_HWM_PERCENT := ROUND(LVC_BLOCKS / LVC_TOTAL * 100); END IF; IF LVC_USED_PERCENT &lt; 6 THEN LVC_USED_PERCENT_POS := 3; ELSE LVC_USED_PERCENT_POS := ROUND(LVC_USED_PERCENT / 2); END IF; IF LVC_HWM_PERCENT &lt; 6 THEN LVC_HWM_PERCENT_POS := 3; ELSE LVC_HWM_PERCENT_POS := ROUND(LVC_HWM_PERCENT / 2); END IF; DBMS_OUTPUT.PUT_LINE(RPAD(LVC_TABLE_TMP || &#39;: &#39; || LVC_MB || &#39;MB&#39;, 50) || LPAD(&#39;U: Used, H: HWM, T: Total&#39;, 52)); DBMS_OUTPUT.PUT_LINE(LPAD(&#39;=&#39;, 102, &#39;=&#39;)); DBMS_OUTPUT.PUT_LINE(LPAD(LVC_USED_PERCENT || &#39;%&#39;, LVC_USED_PERCENT_POS)); DBMS_OUTPUT.PUT_LINE(&#39;|&#39; || LPAD(&#39;|U&#39;, LVC_USED_PERCENT + 2, &#39;-&#39;)); DBMS_OUTPUT.PUT_LINE(LPAD(LVC_HWM_PERCENT || &#39;%&#39;, LVC_HWM_PERCENT_POS)); DBMS_OUTPUT.PUT_LINE(&#39;|&#39; || LPAD(&#39;|H&#39;, LVC_HWM_PERCENT + 2, &#39;-&#39;)); DBMS_OUTPUT.PUT_LINE(&#39;&#39;); DBMS_OUTPUT.PUT_LINE(LPAD(&#39;T&#39;, 103, &#39;=&#39;)); EXCEPTION WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(LVC_TABLE_TMP || &#39;, &#39; || SQLERRM); END P_TABLE_HWM_ANALYSE; 测试一下， DM2_LDCX_SY: 10MB U: Used, H: HWM, T: Total ====================================================================================================== 88% |----------------------------------------------------------------------------------------|U 98% |--------------------------------------------------------------------------------------------------|H ======================================================================================================T","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"高水位线","slug":"高水位线","permalink":"https://pingao777.github.io/tags/%E9%AB%98%E6%B0%B4%E4%BD%8D%E7%BA%BF/"},{"name":"Oracle","slug":"Oracle","permalink":"https://pingao777.github.io/tags/Oracle/"},{"name":"数据库","slug":"数据库","permalink":"https://pingao777.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Javascript中的原型","slug":"Javascript中的原型","date":"2016-03-20T05:28:20.000Z","updated":"2020-09-12T03:14:00.582Z","comments":true,"path":"2016/03/20/Javascript中的原型/","link":"","permalink":"https://pingao777.github.io/2016/03/20/Javascript%E4%B8%AD%E7%9A%84%E5%8E%9F%E5%9E%8B/","excerpt":"首先要明确的是， js中的原型是一个对象，而且这个对象是函数(对象)的一个属性，即prototype。 当以构造函数的形式调用函数时，即new一个函数，会创建一个实例对象，这个实例的__proto__属性会指向构造函数的prototype，由于原型也是对象，所以它也有一个__proto__属性，这个属性指向的是原型对象的构造函数的prototype，这样一步一步上溯到Object.prototype,Object.prototype对象的__proto__指向的是null，这就形成了一个锁链一样的东西，称为原型链。如果把原型链看做一条河流那么null就是源头了。注意原型prototype是函数的属性而不是实例的。 当一个函数被创建时，Function构造器产生的函数对象会执行类似的代码：this.prototype = &#123;constructor: this&#125;","text":"首先要明确的是， js中的原型是一个对象，而且这个对象是函数(对象)的一个属性，即prototype。 当以构造函数的形式调用函数时，即new一个函数，会创建一个实例对象，这个实例的__proto__属性会指向构造函数的prototype，由于原型也是对象，所以它也有一个__proto__属性，这个属性指向的是原型对象的构造函数的prototype，这样一步一步上溯到Object.prototype,Object.prototype对象的__proto__指向的是null，这就形成了一个锁链一样的东西，称为原型链。如果把原型链看做一条河流那么null就是源头了。注意原型prototype是函数的属性而不是实例的。 当一个函数被创建时，Function构造器产生的函数对象会执行类似的代码：this.prototype = &#123;constructor: this&#125; 下面我们用代码来阐述一下上面的结论，假设有这样一段代码： var Flower = function(name) &#123;this.name = name;&#125; var f = new Flower(&quot;flower&quot;); 那么这段代码的原型链是什么样子的呢？ 原型链为图中红色虚线，我们用代码验证下我们的猜想， // true f.__proto__ === Flower.prototype; // true; Flower.prototype.__proto__ === Object.prototype; // true Object.prototype.__proto__ === null; 如果把原型链看做一条河流，那么null那一端就是上游，另一端为下游。我们都知道河流是有方向的，水只能由上游流向下游，而不能相反。 那么这个原型链有什么作用呢？它是js继承系统的基础。上面提到，原型也是一个对象，既然是对象就可以拥有属性和方法，但是这个对象有点特殊，如果你往这个对象里添加了属性和方法，处于下游的对象包括原型都会拥有这个属性和方法，甚至会影响到已有的对象。这有点像你往河里面导入一瓶墨水，那么下游很快就会被染上颜色。 还是老样子，用代码验证下， Object.prototype.nishishui = &quot;wo&quot; // &quot;wo&quot; Flower.prototype.nishishui // &quot;wo&quot; Flower.nishishui // &quot;wo&quot; f.nishishui // &quot;[object Object]&quot; f.toString() 我们从来没有在Flower和f上定义nishishui这个属性，但是它们都可以访问到。这是怎么回事呢，实际上当f调用nishishui这个属性时，首先检查自身，当然没有，然后通过__proto__去Flower.prototype中去找发现也没有，最后，以同样的方法找到Object.prototype，发现这小子原来在这里，当然不能放过了。js正是通过这种方式实现自己的继承，例如上面的toString()方法。不过如果原型链过长，会有潜在的性能问题，这个以后再说吧。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://pingao777.github.io/tags/Javascript/"}]},{"title":"统计中的p值","slug":"统计中的p值","date":"2016-03-20T03:36:27.000Z","updated":"2020-09-12T03:14:00.591Z","comments":true,"path":"2016/03/20/统计中的p值/","link":"","permalink":"https://pingao777.github.io/2016/03/20/%E7%BB%9F%E8%AE%A1%E4%B8%AD%E7%9A%84p%E5%80%BC/","excerpt":"在我看来，假设检验从本质上是一种反证法。当你想证明一样事物是对的，有时候不太好证明，因为一件你以为对的东西可能只是因为你还没发现它错的一面，相反你想证明一件事物是错的就容易多了。在假设检验中，证明备择假设H1存在困难，我们就去证明它的反面原假设H0。","text":"在我看来，假设检验从本质上是一种反证法。当你想证明一样事物是对的，有时候不太好证明，因为一件你以为对的东西可能只是因为你还没发现它错的一面，相反你想证明一件事物是错的就容易多了。在假设检验中，证明备择假设H1存在困难，我们就去证明它的反面原假设H0。 p值一直是一个令人迷惑的地方，p值实际上是当H0假设为真，一些极端情况出现的概率。即$$p值 = {极端情况概率|H0}$$ 那么极端情况是什么呢？在H0的前提下，假设样本均值符合正态分布，我们都知道偏离均值3个均方差的概率几乎为0，但是这种情况还是出现了，我们就有理由判断前提条件错了，即H0是错的，由此我们拒绝H0。 上面提到在正态分布的情况下，偏离均值3个均方差的概率几乎为0，但毕竟不是0，事实上约为0.27%。虽然概率很小，但是还是有一定的可能性会拒绝本是正确的H0，这个犯错概率称为第一类错误，也称为显著性水平$\\alpha$。 那么，这个显著性水平$\\alpha$和p值有什么关系呢？在我看来就是拒绝一个真H0所允许的最大错误概率，也就是这种极端情况出现的最高概率，当p小于等于$\\alpha$时我们拒绝H0，否则不能拒绝H0。 在假设检验中，通常的流程为： 提出原假设和备择假设。 指定显著性水平$\\alpha$，通常取0.01或0.05。 搜集样本数据计算检验统计量的值。 利用检验统计量的值计算p值。 如果p值&lt;=$\\alpha$，则拒绝H0，否则不能拒绝H0。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"统计","slug":"统计","permalink":"https://pingao777.github.io/tags/%E7%BB%9F%E8%AE%A1/"}]},{"title":"VIM中的正则表达式","slug":"VIM中的正则表达式","date":"2015-11-01T13:00:10.000Z","updated":"2020-09-12T03:14:00.584Z","comments":true,"path":"2015/11/01/VIM中的正则表达式/","link":"","permalink":"https://pingao777.github.io/2015/11/01/VIM%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"VIM作为一款编辑软件有着强大的操作指令，灵活的配置方法，通过适当的组合能够实现令人眼花缭乱的功能，而正则表达式作为一门处理文本和数据的重要工具，和VIM异曲同工，通过元字符的简单组合就可以匹配千变万化的文本和数据，它是如此的强大以至于有些任务如果没有正则表达式几乎没有其他好的方法实现。下面看看这两个强大的武器是如何结合在一起的。","text":"VIM作为一款编辑软件有着强大的操作指令，灵活的配置方法，通过适当的组合能够实现令人眼花缭乱的功能，而正则表达式作为一门处理文本和数据的重要工具，和VIM异曲同工，通过元字符的简单组合就可以匹配千变万化的文本和数据，它是如此的强大以至于有些任务如果没有正则表达式几乎没有其他好的方法实现。下面看看这两个强大的武器是如何结合在一起的。 本文翻译自http://www.vimregex.com/，算是一篇比较全面的VIM正则表达式介绍。 2.介绍2.1什么是VIM？VIM（VI Improve）是VI编辑器的改进版，它在UNIX中无处不在。VIM由Bram Moolenaar发明，是一款免费的编辑器，当然如果你愿意，可以捐助一部分钱。 VIM有自己的网站为www.vim.org和邮件列表，上面的资料涵盖VIM的方方面面。目前，VIM能够运行在各大操作系统上，甚至是一些linux发型版本（redhat）的默认编辑器。 VIM拥有现代编辑的许多特点：语法高亮、可以定制化的用户界面、可以方便的与多种IDE集成在一起，从而具有一些更加吸引人的特色，比如故障恢复、自动命令补全、会话管理等。 VIM拥有庞大的用户群，仅linux用户就超过1000万，这个数字还在进一步增加。 2.2关于本教程之所以写这个教程，只是因为我爱正则表达式，没有什么能比写出一个精心设计满足需要的正则表达式更让人兴奋的了，我希望这能作为一个引言。 不过说真的，正则表达式作为一个处理文本和数据的工具不是独立存在，而是嵌入在其他的程序语言或工具中，比如UNIX中的著名的grep程序，它根据一定的模式查找文件中的内容。你可以把正则表达式看做一种模式匹配语言，用它来处理一些棘手的文本问题会有意想不到的效果。 2.3致谢感谢Benji Fisher, Zdenek Sekera, Preben “Peppe” Guldberg, Steve Kirkendall, Shaul Karl（排名不分先后）以及所有给我建议的人。 如果你有好的建议或者想法，随时发信给我（olontir at yahoo dot com）。 3.替换命令3.1查找/替换 :range s[ubstitute]/pattern/string/cgiIc 每次替换都要确认g 替换一行当中所有的匹配项（没有g只替换第一个匹配值，pingao注：注意与%区别）i 忽略大小写I 不忽略大小写 []中表示可选项 3.2范围操作、行地址及标记在讲匹配模式之前，先来了解下行地址。一些命令可以接受行范围，这样命令就会限定在这个范围内执行。行范围通常由逗号（，）或者分号（；）分隔的标示符组成，你也可以使用命令mI在当前位置作一个标记，以方便后面使用，”I”可以是任何字母。 标示符 说明 数字 行号 . 当前行 $ 文件的最后一行 % 整个文件，与1,$相同 ‘t 标记t /pattern[/] pattern的下一个匹配行 ?pattern[?] pattern的上一个匹配行 \\/ 最近一个搜索pattern的下一个匹配行 \\? 最近一个搜索pattern的上一个匹配行 \\&amp; 最近一个替换pattern的下一个匹配行 如果没有指定行，操作只针对当前行。 这里有一些例子， 10, 20 -10到20行 /Section 1/+,/Section 2/- -所有Section 1和Section 2之间的行，不包括它们所在行，+标示加一，-标示减一，可以重复多个 :/Section/+ y -复制Section的下一个匹配行 :// normal p -粘贴到Section下一个匹配行的下一行 Tip1:如果你在pattern里使用/，一定要使用\\进行转义，比如，s/\\/dir1\\/dir2\\/dir3\\/file/dir4\\/dir5\\/file2/g 为了避免这种令人迷惑的转义灾难，VIM中可以自定义分隔符，我喜欢用冒号（:） Tip2：将下面两个快捷键映射放在你的vimrc文件中，noremap ;; :%s:::g&lt;Left&gt;&lt;Left&gt;&lt;Left&gt;noremap ;&#39; :%s:::cg&lt;Left&gt;&lt;Left&gt;&lt;Left&gt;&lt;Left&gt; 有了这两个快捷键，你会省去不少敲击键盘的时间，它会直接定位到搜索模式那里，输入搜索部分后再输入替换部分然后按回车键。第二个快捷键增加了确认标志。 4.模式说明4.1锚假设你想把所有的vi替换为VIM，很容易会想到下面的命令， s/vi/VIM/g 但是如果你真的这么做了，你会发现，它会把所有vi替换为VIM，甚至vi只是某个单词的一部分，这可能不是你想要的。 你可能还会想到，在vi两边添加空格来达到想要的效果， s: vi : VIM :g 你会发现结果并没有变化，正确的方法是使用单词边界标志\\&lt;\\&gt;， s:\\&lt;vi\\&gt;:VIM:g 行开始和结束有自己的标识符^和$，替换所有在行开始出现的vi， s:^vi\\&gt;:VIM: 如果一行之中只有vi则进行替换， s:^vi$:VIM: 现在假设你不仅要替换vi还要替换Vi、VI，有几种方法可以实现， 最简单的方法是使用i标志， %s:vi:VIM:gi 定义字符类（character class），:%s:[Vv]i:VIM:将会替换所有的Vi和vi 4.2转义字符或元字符到目前为止，所有的匹配模式（pattern）都是由一些正常字符组成的，而正则表达式的真正强大之处就在于元字符（metacharacter），元字符是是指一些具有特殊含义的字符，从外观上它们的前面常有一个反斜杠，如下表所示， # 匹配 # 匹配 . 除换行符之外的任意字符 \\s 空白字符 \\S 非空白字符 \\d 数字 \\D 非数字 \\x 十六进制 \\X 非十六进制 \\o 八进制 \\O 非八进制 \\h 单词头（a-zA-Z_） \\H 非单词头 \\p 可打印字符 \\P 非打印字符 \\w 单词字母 \\W 非单词字母 \\a 字母 \\A 非字母 \\l 小写字母 \\L 非小写字母 \\u 大写字母 \\U 非大写字母 比如，你想匹配 09/01/2000，可以使用下面的正则表达式， \\d\\d/\\d\\d/\\d\\d\\d\\d 匹配一个首字母大写的六字母单词， \\u\\w\\w\\w\\w\\w 如果你想匹配一个不知道长度的单词或者一个长单词，写出每个\\w不是很方便，这就要用到下面介绍的量词（quantifiers）概念了。 4.3量词、贪婪匹配与惰性匹配将一个量词（quantifiers）放置在模式（pattern）一部分后面，就可以限制这部分的重复次数。 量词 说明 * 0个或多个，.*匹配任何东西，甚至一个空行 \\+ 1个或多个 \\= 0个或1个（pingao注：相当于?） \\{n, m} 匹配n到m次 \\{n} 匹配n次 \\{, m} 匹配0到m次 \\{n, } 至少匹配n次 n和m都必须是正整数 现在很容易就能写出一个匹配任意长度单词的表达式：\\u\\w\\+。 上面这些量词都是工作在贪婪模式下的，它们会尽可能多的匹配字符。有时候这会带来意想不到的问题，考虑一个典型的例子，假如你想匹配一个含有某种限定符的文本，比如被引号或者括号包围的文本，因为你不知道这些限定符里有什么，我们可以使用/&quot;.*&quot;/。 但是这个表达式将会匹配任何处于第一个引号和最后一个引号中间的文本，如粗体标注的部分 this file is normally “$VIM/.gvimrc”. You can check this with “:version”. 这种问题可以使用惰性（non-greedy）量词来解决， 量词 说明 \\{-} 0个或多个，尽可能少的匹配 \\{-n,m} n个或多个，尽可能少的匹配 \\{-n, } 至少匹配n次，尽可能少的匹配 \\{-, m} 至多匹配m次，尽可能少的匹配 让我们用\\&#123;-&#125;替换上面的*，所以.\\&#123;-&#125;将会匹配第一个引号的内容。 this file is normally “$VIM/gvimrc”. You can check this with “:version”. \\&#123;-&#125;确实没有让我们失望，下面看看执行下面的命令将会发生什么， :s:.\\&#123;-&#125;:_:g 执行前： n and m are decimal numbers between 执行后： _n_ _a_n_d_ _m_ _a_r_e_ _d_e_c_i_m_a_l_ _n_u_m_b_e_r_s_ _b_e_t_w_e_e_n_ “尽可能的少的匹配”在这里的意思是匹配0个字符，然而匹配竟然发生在了字符之间，下面我引用Bram自己的话来解释这种行为， 匹配到0个字符也是一种匹配，因此它会将0字符替换为一个”_”，然后走到下一个位置，继续匹配到0个字符。 大部分情况下，\\&#123;-&#125;没有多大的用处，它的这种运行方式主要是为了和*保持一致，后者也会匹配0个字符，相比之下，x\\&#123;-1,&#125;是一种更加没用的写法，它只会匹配一个x，和x功能一样，比较有用的一种写法为x\\&#123;70&#125;，至于x\\&#123;-3,&#125;&quot;, &quot;x\\&#123;-2,&#125;&quot;, &quot;x\\&#123;-1,&#125;用处也不大，只是为了和贪婪模式的量词保持一致。 -Bram 但是如果你只想匹配第二个引号的内容呢？或者我们只想改变引号中的一部分内容呢？我们将会用到分组（grouping）和反向引用（backreference），在这之前我们先来看下字符区间的概念（character range）。 4.4字符区间典型的字符区间： [012345]将会匹配括号中的任意一个，[0-5]与之等价，类似地，我们可以定义全部小写字母的字符区间[a-z]，所有的字母[a-zA-Z]，数字加字母[0-9a-zA-Z]，根据你所在的区域，你可以在字符区间添加à, Ö, ß这样的非ASCII字符。 注意字符区间仅仅匹配其中的一个字符，[0123]和0123不同，顺序对于一个字符区间不重要，[0123]和[0231]一样，而0123和0231是两个截然不同的模式。看看执行下面的句子会发生什么， s:[65]:Dig:g 执行前： High 65 to 70. Southeast wind around 10 执行后： High DigDig to 70. Southeast wind around 10 然后执行 s:65:Dig:g 执行前： High 65 to 70. Southeast wind around 10 执行后： High Dig to 70. Southeast wind around 10 通过放置一个反选符号（^）在字符区间的最前面可以很容易的去除不愿匹配的字符，下面将会匹配除大写字母外的任意字符， /[^A-Z]/ 我们可以使用字符区间重写匹配引号内的文本， /&quot;[^&quot;]\\+&quot;/ 注意[]内部的元字符会失去其特殊的意义，所以如果你想要一个包含-的字符区间，把-放在最前面，如下表达式将会匹配所有的数字和-， /[-0-9]/ 同时^如果不在最前面，也会失去其特殊意义。 现在考虑一个现实的例子，假设有一个语法检测器想找出所有不以大写字母开头的句子，下面的表达式可以实现这一点， \\.\\s\\+[a-z] 这将会匹配一个句号、一个或多个空格然后是一个小写字母，我们现在知道如何找到错误，下面来看看如何修复它。这里就需要我们记住前面的匹配值以便后面可以重新调用它，这就是反向引用大显身手的地方了。 4.5分组和反向引用你可以使用\\(\\)对模式匹配项进行分组，然后通过\\1, \\2 ... \\9来引用。一个典型的例子为交换每一行的头两个单词， s:\\(\\w\\+\\)\\(\\s\\+\\)\\(\\w\\+\\):\\3\\2\\1: \\1代表第一个单词，\\2代表一个或多个空白符，\\3代表第二个单词。如何知道哪个数字代表哪个匹配项，从左往右数\\(的个数。 # 含义 # 含义 &amp; 模式匹配到的全部内容 \\L 将后面的字符都转换为小写 \\0 同上 \\U 将后面的字符都转换为大写 \\1 第一个括号中匹配的内容 \\E end of \\U and \\L \\2 第二个括号中匹配的内容 \\e end of \\U and \\L … … \\r 将一行分为两行 \\9 第九个括号中匹配的内容 \\I 将下一个字符转换为小写 ~ 前面替换的字符串 \\u 将下一个字符转换为大写 看下上面的语法检查问题完整的表达式， s:\\([.!?]\\)\\s\\+\\([a-z]\\):\\1 \\u\\2:g 我们将0个或多个空白符替换为两个空格。 4.6备选备选（alternation）是指用\\|将多个表达式结合在一起，这样一旦有一个表达式匹配到，则整个表达式匹配成功，返回这个表达式匹配内容。（pingao注：类似于逻辑操作符|） \\(Date:\\|Subject:\\|From:\\)\\(\\s.*\\) 上面的表达式将会把邮件的头部和内容放在\\1和\\2中，对于备选需要注意的是，它不是贪婪匹配的，一旦多个表达式有一个表达式匹配到，后面的表达式将不再匹配，这意味着对于一个备选，表达式的顺序十分重要。 Tip3:将\\(\\)快速的放在表达式中，cmap ;\\ \\(\\)&lt;Left&gt;&lt;Left&gt; 4.7正则表达式操作符的优先级和算数表达式一样，正则表达式的运算符也有一定的优先级，下表从高到低列出了各个操作的优先级， 优先级 操作符 说明 1 \\(\\) 分组 2 \\=,\\+,*,\\&#123;n&#125; 量词 3 abc\\t\\.\\w 字符、元字符 4 “\\ ” 备选 5.全局命令5.1全局搜索及执行我想介绍另一个用处广泛功能强大的命令， :range g[lobal][!]/pattern/cmd在range的范围内，在pattern匹配行执行Ex cmd（默认为:p[rint]），如果pattern前面加上一个!，表示pattern没有匹配的行。 全局命令的工作原理为，第一遍扫描range范围的每一行，并对pattern匹配行做一个标记；第二遍对每一个标记行执行cmd。range默认为整个文件。 注意：Ex command包括所有你在VIM命令行输入的命令，比如 :s[ubstitute], :co[py] , :d[elete], :w[rite] 非Ex command（normal command）也可以执行， :norm[al]non-ex command 5.2例子:g/^$/ d -删除文件中所以的空行 :g/^$/,/./-j -将多个空行转换为一个空行 :10,20g/^/ mo 10 -颠倒10到20行的顺序 下面是一个来自 Walter Zintz vi教程的例子，例子有改动 :&#39;a,&#39;b g/^Error/ . w &gt;&gt; errors.txt -在标记’a和’b之间找到以Error开始的行，然后将这些行追加到errors.txt。注意：w前面的.（当前行）不要漏掉，否则将会把整个文件追加到errors.txt中。 你可以使用|作为分隔符执行多个命令，如果你想在参数中使用|，要用\\对其进行转义。 Zintz的另一个例子， :g/^Error:/ copy $ | s /Error/copy of the error/ 将所有Error行拷贝到文件的最后，然后将Error替换为copy of the error。s命令没有指定地址，默认为当前行。 :g/^Error:/ s /Error/copy of the error/ | copy $ 将上面的操作顺序颠倒了一下，先替换后复制。 6.更多的例子6.1小贴士(1)由Antonio Colombo提供 去掉所有行尾部的空白符， s:\\s*$::或者s:\\s\\+$:: 6.2创建一个大纲这个例子需要你有点html的背景，我们需要将&lt;h1&gt;和&lt;h2&gt;标签中的标题和副标题分离出来，做一个表格。 (1)首先我们给每个标签做一个标记，&lt;h1&gt;&lt;a name=&quot;anchor&quot;&gt;Heading&lt;/a&gt;&lt;/h1&gt;，anchor是标签的唯一标示，实现表达式如下， :s:\\(&lt;h[12]&gt;\\)\\(.*\\s\\+\\([-a-zA-Z]\\+\\)\\)\\s*\\(&lt;/h[12]&gt;\\):\\1&lt;a name=&quot;\\3&quot;&gt;\\2&lt;/a&gt;\\4: 说明： (2)接下来，将标题拷贝到一个地方， :%g/&lt;h[12]&gt;/ t$ 上面的命令将会把&lt;h1&gt;和&lt;h2&gt;标签所在行拷贝到文件的最后。现在文件的样子如下， &lt;h1&gt;&lt;a name=&quot;anchor1&quot;&gt;Heading1&gt;&lt;/a&gt;&lt;/h1&gt; &lt;h2&gt;&lt;a name=&quot;anchor2&quot;&gt;Heading2&gt;&lt;/a&gt;&lt;/h2&gt; &lt;h2&gt;&lt;a name=&quot;anchor3&quot;&gt;Heading3&gt;&lt;/a&gt;&lt;/h2&gt; .......................... &lt;h1&gt;&lt;a name=&quot;anchorN&quot;&gt;HeadingN&gt;&lt;/a&gt;&lt;/h1&gt; 第一步，为了要把表格的元素链接到各自的位置，我们要把name=&quot;替换为href=&quot;#。 s:name=&quot;:href=&quot;#: 第二步，要让h1与h2看起来不同，我们定义”majorhead”和”minorhead”两个CSS类， g/&lt;h1&gt;/ s:&lt;a:&amp; class=&quot;majorhead&quot;: g/&lt;h2&gt;/ s:&lt;a:&amp; class=&quot;minorhead&quot;: 现在文件看起来像这样， &lt;h1&gt;&lt;a class=&quot;majorhead&quot; name=&quot;anchor1&quot;&gt;Heading1&gt;&lt;/a&gt;&lt;/h1&gt; &lt;h2&gt;&lt;a class=&quot;minorhead&quot; name=&quot;anchor2&quot;&gt;Heading2&gt;&lt;/a&gt;&lt;/h2&gt; #（pingao注：我认为此时文件应该是这样的） &lt;h1&gt;&lt;a class=&quot;majorhead&quot; href=&quot;#&quot;&gt;Heading1&gt;&lt;/a&gt;&lt;/h1&gt; &lt;h2&gt;&lt;a class=&quot;minorhead&quot; href=&quot;#&quot;&gt;Heading2&gt;&lt;/a&gt;&lt;/h2&gt; 我们不再需要&lt;h1&gt;和&lt;h2&gt;标签， s:&lt;h[21]&gt;:: 替换&lt;/h1&gt;和&lt;/h2&gt;标签为&lt;br&gt;， s:/h[21]:br: 现在文件的样子， &lt;a class=&quot;majorhead&quot; name=&quot;anchor1&quot;&gt;Heading1&gt;&lt;/a&gt;&lt;br&gt; &lt;a class=&quot;minorhead&quot; name=&quot;anchor2&quot;&gt;Heading2&gt;&lt;/a&gt;&lt;br&gt; #（pingao注：我认为此时文件应该是这样的） &lt;a class=&quot;majorhead&quot; href=&quot;#&quot;&gt;Heading1&gt;&lt;/a&gt;&lt;br&gt; &lt;a class=&quot;minorhead&quot; href=&quot;#&quot;&gt;Heading2&gt;&lt;/a&gt;&lt;br&gt; 6.3处理表格很多情况下，你需要处理表格形式的文本。例如，下面的文本， Asia America Africa Europe Africa Europe Europe Africa Europe Asia Europe Europe Asia America Africa Europe Africa Europe Asia Africa Europe Asia Asia Europe Europe America Africa Asia Africa Europe Europe Africa Europe Asia Europe Europe 假设你想把第三列的”Europe”替换为 “Asia”， :%s:\\(\\(\\w\\+\\s\\+\\)\\&#123;2&#125;\\)Europe:\\1Asia: 交换前两列， :%s:\\(\\w\\+\\)\\(.*\\s\\+\\)\\(\\w\\+\\)$:\\3\\2\\1: 未完待续… 7.其他语言正则表达式特点现在我将VIM的正则表达式与其他语言的正则表达式做一个对比，特别是Perl。提起正则表达式，Perl肯定不得不提。 （在Steve Kirkendall的帮助下整理）Perl和VIM的主要区别为， Perl的大多数元字符不需要反斜杠。个人认为，反斜杠越少越好，这样正则表达式会更加可读。 Perl中你可以在量词后加上一个?将贪婪模式的量词转换为非贪婪模式， 比如*?为非贪婪模式的*。 Perl的正则表达式支持各种奇怪的选项。 Perl的正则表达式可以包含变量，变量将会替换为具体的值，这称作”变量替换”。 8.链接在正常模式下，输入”:help pattern”，阅读VIM帮助文档的正则表达式和搜索章节。 市场上有两本不错的介绍VIM正则表达式的书， “Learning the vi Editor” by Linda Lamb and Arnold Robbins. “vi Improved - VIM” by Steve Oualline Jeffrey Friedl的”Mastering Regular Expressions”是一本正则表达式的权威指南，此书主要介绍Perl的正则表达式，由O’Reilly出版，官网上有一章免费。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://pingao777.github.io/tags/Vim/"}]},{"title":"大道至简：朴素贝叶斯分类器","slug":"大道至简：朴素贝叶斯分类器","date":"2015-10-11T05:45:30.000Z","updated":"2020-09-12T03:14:00.589Z","comments":true,"path":"2015/10/11/大道至简：朴素贝叶斯分类器/","link":"","permalink":"https://pingao777.github.io/2015/10/11/%E5%A4%A7%E9%81%93%E8%87%B3%E7%AE%80%EF%BC%9A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/","excerpt":"万物之始,大道至简,衍化至繁。 ——ifelse(is.element(this, 道德经), 道德经, unknown) 一、背景提到贝叶斯分类，首先来看下贝叶斯其人，贝叶斯(Thomas Bayes,1701—1761)英国牧师、业余数学家。可别小看了欧洲的牧师，孟德尔，被誉为“遗传学之父”也曾为一名神父，假如你不记得孟德尔是谁，那么你肯定记得高中生物上那个著名的豌豆实验。","text":"万物之始,大道至简,衍化至繁。 ——ifelse(is.element(this, 道德经), 道德经, unknown) 一、背景提到贝叶斯分类，首先来看下贝叶斯其人，贝叶斯(Thomas Bayes,1701—1761)英国牧师、业余数学家。可别小看了欧洲的牧师，孟德尔，被誉为“遗传学之父”也曾为一名神父，假如你不记得孟德尔是谁，那么你肯定记得高中生物上那个著名的豌豆实验。 具有讽刺意味的是，当初贝叶斯发明概率统计理论是为了证明上帝的存在，而至死这个愿望都没有实现，不过感谢伟大的贝叶斯，因为他的无心插柳，才有了今天的贝叶斯公式。接下来，来一睹贝叶斯公式的风采， $$P(B|A)=\\frac{P(B)P(A|B)}{P(A)}$$ 公式看起来是不是很简洁，看起来很有对称美。记得上学那会数学老师的一句话，假如你算出来的答案不够简洁，那么多半这道题你算错了。贝叶斯公式有什么意义呢？它解决了两个事件条件概率的转换问题。比如说，已知感冒导致流鼻涕的概率，那么流鼻涕有多大的概率感冒呢？贝叶斯可以解决这类问题。 二、贝叶斯分类 贝叶斯可以解决条件概率转换，可是它怎么与分类联系起来的呢？ 让我以一个例子加以说明，假设有这样一个数据集（本例来自朴素贝叶斯分类器的应用）， 症状(A1) 职业(A2) 疾病(B)打喷嚏 护士 感冒打喷嚏 农夫 过敏头痛 建筑工人 脑震荡头痛 建筑工人 感冒打喷嚏 教师 感冒头痛 教师 脑震荡 那么一个打喷嚏的建筑工人是感冒还是没感冒呢？根据贝叶斯定理， P(感冒|打喷嚏x建筑工人) = P(打喷嚏x建筑工人|感冒) x P(感冒) / P(打喷嚏x建筑工人) 假定”打喷嚏”和”建筑工人”这两个特征是独立的，因此，上面的等式就变成了 P(感冒|打喷嚏x建筑工人) = P(打喷嚏|感冒) x P(建筑工人|感冒) x P(感冒) / P(打喷嚏) x P(建筑工人) = 0.66 x 0.33 x 0.5 / 0.5 x 0.33 = 0.66同理，P(非感冒|打喷嚏x建筑工人) = P(打喷嚏|非感冒) x P(建筑工人|非感冒) x P(非感冒) / P(打喷嚏) x P(建筑工人) = 0.33 x 0.33 x 0.5 / 0.5 x 0.33 = 0.33 因为P(感冒|打喷嚏x建筑工人) &gt; P(非感冒|打喷嚏x建筑工人) ，所以我们更愿意相信一个打喷嚏的建筑工人是感冒的。 从上面的例子可以看出，贝叶斯分类的步骤是这样的： 设$x = {a_1,a_2,\\cdots}$为一个待分类项，每个a为x的一个特征属性。 有类别集合$C = {y_1,y_2,\\cdots,y_n}$. 根据训练集计算，$P(y_1|x), P(y_2|x),\\cdots,P(y_n|x)$. 如果$P(y_k|x)=max{P(y_1|x), P(y_2|x),\\cdots,P(y_n|x)}$，则$x$的分类为$y_k$。 说到贝叶斯分类，还有几个需要注意的问题： 如果已知条件不止一个属性，二是多个呢，这个时候贝叶斯公式可以写作$$P(y|a_1a_2\\cdots)=\\frac{P(y)P(a_1a_2\\cdots|y)}{P(a_1a_2\\cdots)}=\\frac{P(y)P(a_1|y)P(a_2|y)\\cdots}{P(a_1)P(a_2)\\cdots}$$上述公式假设特征属性$a_1,a_2\\cdots$相互独立，这也是“朴素”一词的由来。另外，可以看到对于不同的分类，分母都是恒定的，而我们只想找到概率最大的类别，因此可以把分母省略，求条件概率的相对值，$$P(y|a_1a_2\\cdots)_{relative}=P(y)P(a_1|y)P(a_2|y)\\cdots$$ 不知道大家有没有注意到，上面的已知条件都是离散值，如果是连续值呢，对于连续值通常有两种办法，一是将连续值截取为离散值，然后求概率，二是假定离散值服从高斯分布，即$$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$因为我们只需求概率的相对值，所以这里只需计算属性的概率密度值即可。 还有一个问题，当某些类别下某个特征值计数为0，即$P(a_i|y_j)$=0，这会使某些分类最终的概率为0，会降低分类器的准确性，为了解决这个问题，引入Laplace校准，就是对这些类别的某些特征值计数加1，这样如果训练样本集数量充分大时，并不会对结果产生影响。 如果想更详细的了解贝叶斯分类，请参考这两篇文章分类算法之朴素贝叶斯分类和朴素贝叶斯分类器的应用。 接下来，我用R语言实现一个分类器并用一些数据集测试分类效果。 三、算法实现 程序主要由三部分组成： 分类器主要由下面几个函数组成，具体的代码见GitHub。 # 1.求各个分类概率P(ycol) get.ytable &lt;- function(ycol, trainset) # 2.1求离散属性xcol的条件概率P(xcol|ycol) get.discrete.xtable &lt;- function(xcol, ycol, trainset) # 2.2求连续属性xcol的概率密度，假设服从高斯分布 get.continout.xdensity &lt;- function(xcol, ycol, trainset) # 3.对于某些概率为零的类别，采用Laplace校准设置默认值 get.defaultx &lt;- function(ycol, trainset) # 注：xcol特征属性，ycol类别属性，trainset训练集 下面以基础包里的iris数据集验证一下分类器的效果，选取前四列为特征，预测鸢尾花的种类， 图上有两条曲线，黑色为我实现的贝叶斯分类器，红色虚线为e1071包里的一个贝叶斯分类器实现。观察可得，随着训练集样本数的增加，测试集的分类正确率越来越高。 再来看看特征属性的选取对正确率的影响， 这次只选择了第二列（花萼宽度）作为特征值，可以看到正确率明显下降了。 再来看一个多分类问题，采用北京二手房这个数据集， 通过房价和是否学区这两列来预测房子所在的区，可以看到这两个特征属性的预测正确率稳定在0.4左右，下面再添加户型、朝向、楼层三列， 上图显示，添加了三个特征属性后，正确率并没有明显的改善，但是如果再添加一个区域列(con)， 由图观察，添加了区域这一列后，正确率得到了大幅度的提升，事实上仅保留区域这一列，预测的正确率也很高，这是因为区域(con)与区(area)的相关性较强。 根据我实验的结果，通常情况下，提高预测正确率的方法有两种： 增加训练集样本数，但是样本到达一定的数目正确率就保持稳定，很难再提高了。 选取恰当的特征，注意单纯的增加特征数目并不能提高正确率，反而会引入更多的误差造成过拟合。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://pingao777.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"贝叶斯","slug":"贝叶斯","permalink":"https://pingao777.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"}]},{"title":"当Python和R遇上北京二手房（下）","slug":"当Python和R遇上北京二手房（下）","date":"2015-09-05T03:47:00.000Z","updated":"2020-09-12T03:14:00.590Z","comments":true,"path":"2015/09/05/当Python和R遇上北京二手房（下）/","link":"","permalink":"https://pingao777.github.io/2015/09/05/%E5%BD%93Python%E5%92%8CR%E9%81%87%E4%B8%8A%E5%8C%97%E4%BA%AC%E4%BA%8C%E6%89%8B%E6%88%BF%EF%BC%88%E4%B8%8B%EF%BC%89/","excerpt":"四、各区情况作为买房者第一步就是看房选房，那么各区的情况是怎样的呢？下面从买房者比较注重的五个方面横向对比一下。","text":"四、各区情况作为买房者第一步就是看房选房，那么各区的情况是怎样的呢？下面从买房者比较注重的五个方面横向对比一下。 1.各区总价 （图中红点为本区域的均值） 果然不出所料，西城、东城、海淀、朝阳四区均值和中位数均在前列，且数据区间分布比较广，而一些新兴的郊区如房山、门头沟、燕郊总价则较为集中，大概是因为房子是同一时期建设，功能需求也比较单一的缘故。 另外我注意到，各区的总价均值均不同程度的偏离中位点，城区偏离较大，郊区偏离较小，是不是因为城区房子需求多样，一些别墅豪宅拉高了均值？值得注意是顺义的均值超过了上四分位数，是不是顺义有较大比例的高档房产呢？ 下面换个角度，以二维直方图来展示下 由于各区二手房总量差异较大，这里的颜色代表的是总价区间在本区的占比，从这张图上可以看到西城、东城、海淀、朝阳、顺义确实有一定数量的千万房产。 2.各区单价 这张图很有意思，能发现很多东西。 第一，市区的房价高，郊区房价低，这傻子都知道，呵呵。第一梯队东西城、海淀50%的房子单价都在5万以上，想买这些地方的房子，看看腰包鼓不鼓，第二梯队朝阳、丰台、石景山大部分房子都在3万以上，第三梯队剩下的区房价大部分都在2万5以下，燕郊最低，基本上在1万2左右； 第二，市区的房价范围广，均值偏离中位数幅度大，比如东西城，应该是这两区一些高质量的学区房导致。 3.各区面积 （图中红点为本区域的均值） 可以看出一个趋势，郊区的房子要比市区的房子大。例如东西城面积中位数在75平米左右，而昌平、亦庄等均在100平米左右。还有就是市区房子面积范围较大，而郊区可能起步较晚，基本上建筑年代都在同一时期，房子的面积也较为单一。 顺义200平米的房子比例不少，再结合其千万以上的总价，看来顺义卧虎藏龙。 4.各区建筑年代 这张图上印证了上面的猜测，昌平、房山、亦庄、通州、燕郊等郊区房子建筑年代较为集中，尤其是燕郊，基本上都是2010年左右的房子，而最近因市政府东迁而大火的通州75%的房子是2000年后。而东西城、海淀等区域则是各个年代的房子都有。 从这张图似乎更能明显的看出，昌平、通州、亦庄、燕郊都有一些颜色较深的色块。大兴、房山、顺义、亦庄、燕郊均有超过20%的2010年后的房子，东城、石景山、西城则有20%的90年以前的老房子。 5.各区学区 再来看一下喜闻乐见的学区房，不出所料，海淀区的学区房最多，朝阳区学区次之。由于没有对学区的质量进行分类，东西城这两区虽然数量不如前两者，但是从质量上这两区应该是不言而喻的。 上面，从5个方面分区域做了一下比较，总结一下，喜欢新房的多去昌平通州等区走走，想要学区房的海淀、朝阳是你的选择，如果你只想最贵的，那么东城、西城是你的不二之选，如果你是土豪，顺义是个好去处。 五、一些有意思的事1.房子是不是随着时代的发展越来越大了呢？ 因为大部分房子都在1985 ~ 2015这个时间段，我将视角集中在这个时间段。图中红线为均值，蓝线为中位数。 从图上可以很清楚的看出在1995年房屋面积有一个很明显的上扬，到2000年左右保持平稳，从之前的60平到100平，从2005年开始又有小幅度的下降，难道是刚开始起高了？还有一点是，1995年前的房子，均值和中位数基本持平，95年之后均值大于中位数10个平方左右，是否可以得出以前我们都是无产阶级，现在确实有一部分先富起来了哈哈。 看来，随着时代的发展房屋面积确实有了不小的增长，希望随着时代的进步，人人都能住得起大房子。 2.学区房房价要比非学区贵多少呢？ 数据显示，各个区学区房房价确实要比非学区贵一些，这个差距大概在5000 ~ 15000左右,石景山、西城这个差距较大，都在10000以上，昌平和海淀稍微低些，大约每平方相差8,9千，朝阳东城相差的不多，丰台通州几乎持平。 3.那些地方房价最贵？ 这些房价最贵的地方除万柳其余都在二环以里，基本上分布在北京最中心的地带，果然寸土寸金啊。 4.哪些地方千万豪宅最多？ 而一些豪宅就不一样了，除金融街其余都在三环以外。这也难怪，三环里面就那么点地方，早就占满了，想要豪宅就得往郊区盖，比如中央别墅区、西北旺都在五环以外。 5.哪些地方学区最多呢？ 学区最多的十个区域，朝阳四个，海淀两个，西城两个，东城两个。 六、总结通过两篇文章，我尝试对北京二手房的一些特点进行了分析，分析很初级，基本上就是统计个数量或者比例，对于一些高大上的统计分析方法也在学习当中，等学的差不多了，再补上。 说句题外话，即便是最简单的数据展示和统计分析也能让人学到不少东西，当你着手开始做的时候，你会碰到各种各样的问题，小到图形的字体怎么调整、图形的legend如何改变，大到一些统计方法的实用、数据的处理方法等，鼓励大家根据自己的兴趣，自己动手整一个小的数据集，在这个基础上有目的的进行学习，有道是，当你上路了，你就已经进步了。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"R","slug":"R","permalink":"https://pingao777.github.io/tags/R/"},{"name":"Python","slug":"Python","permalink":"https://pingao777.github.io/tags/Python/"},{"name":"统计","slug":"统计","permalink":"https://pingao777.github.io/tags/%E7%BB%9F%E8%AE%A1/"}]},{"title":"当Python和R遇上北京二手房（上）","slug":"当Python和R遇上北京二手房（上）","date":"2015-09-02T14:26:36.000Z","updated":"2020-09-12T03:14:00.589Z","comments":true,"path":"2015/09/02/当Python和R遇上北京二手房（上）/","link":"","permalink":"https://pingao777.github.io/2015/09/02/%E5%BD%93Python%E5%92%8CR%E9%81%87%E4%B8%8A%E5%8C%97%E4%BA%AC%E4%BA%8C%E6%89%8B%E6%88%BF%EF%BC%88%E4%B8%8A%EF%BC%89/","excerpt":"最近忙活了一阵子，终于把房子的事情落实了，俗话说饱暖思淫欲，某天突发奇想能不能利用手头上的一些工具对北京的二手房数据捣鼓一下，看看能不能有一些有意思的发现？想到以前有点python经验，正巧最近也在看R，正好借此机会巩固一下，齐活，走起！","text":"最近忙活了一阵子，终于把房子的事情落实了，俗话说饱暖思淫欲，某天突发奇想能不能利用手头上的一些工具对北京的二手房数据捣鼓一下，看看能不能有一些有意思的发现？想到以前有点python经验，正巧最近也在看R，正好借此机会巩固一下，齐活，走起！ 一、数据准备看了下各大房产网站，从数据的量级、真实性、即时性等方面对比了下，有的数据挺多，但是数据真实性不高，上面既有房主的帖子，也有中介的帖子；有的真实性不错，但是房源太少，综合对比下来，最终选择了某家网。 有了数据源，用Python写了一个爬虫，从网站上随机爬取了30000条房源数据。有人可能说数据太少了，少就少吧，这里只是想起到一个抛砖引玉的作用。 二、数据整理来看下获取的数据，每条数据描述了房子的13个属性，分别为：区、小区、户型、面积、朝向、区域（区下面更细分的一级，比如昌平的天通苑、回龙观）、楼层、房龄、学区、地铁、税、总价、单价。 区，原始数据都是英文代号，比如BJCP代表昌平，BJCY代表朝阳，为了查看起来方便，将它们都替换为相应的中文名。 楼层，原始数据大部分是以“低楼层”、“中楼层”这样的楼层区间划分的，不过有少量数据也写了具体楼层，我统一把它替换为楼层区间。 学区和地铁，我进行了简化，只进行了是否学区、是否地铁的划分，对于学区的品质，地铁的远近没有细分。 税，抓取的30000条数据里面很奇怪只有“满五唯一”和空值这两种，并没有例如“满二不唯一”、“满二唯一”等类型，为了简化，就认为空值没有免税。 对异常值的处理，查看了一下数据，通过与网站上同区域同小区的数据对比，有一些年代过早、总价、单价过高过低等异常情况，比如年代为1000年的房子，总价43亿的“西山小镇”等等，这可能是信息录入员笔误或者采用了默认值造成，由于异常值占比较小，我进行了简单的删除处理。 为了对面积、年代这样的连续值进行分组，我增加了四列， 面积分组：0~50, 50~100, 100~150, 150~200, &gt;200 年代分组：&lt;1990, 90~95, 95~00, 00~05, 05~10, 10~15, &gt;=2015 总价分组：0~1, 1~2, 2~3, 3~4, 4~5, 5~6, 6~7, 7~8, 8~9, 9~10,>10，单位为百万 单价分组：0~1万, 1~2万, 2~3万, 3~4万, 4~5万, 5~6万, 6~7万, 7~8万, 8~9万,9~10万, &gt;10万 整理完共有29790条数据，这是数据的结构： ## &#39;data.frame&#39;: 29790 obs. of 17 variables: ## $ area : Factor w/ 15 levels &quot;昌平&quot;,&quot;朝阳&quot;,..: 2 13 7 7 15 5 6 14 2 11 ... ## $ region : Factor w/ 5139 levels &quot;@北京&quot;,&quot;10AM新坐标&quot;,..: 674 2299 1789 1955 1063 463 2764 407 2480 2601 ... ## $ zone : Ord.factor w/ 53 levels &quot;0室0厅&quot;&lt;&quot;0室1厅&quot;&lt;..: 12 27 12 6 11 16 11 6 6 16 ... ## $ meters : int 67 408 75 47 83 136 68 57 55 128 ... ## $ direction: Factor w/ 50 levels &quot;&quot;,&quot;北&quot;,&quot;北东北&quot;,..: 40 26 27 26 26 27 27 26 2 27 ... ## $ con : Factor w/ 221 levels &quot;CBD二手房&quot;,&quot;安定门二手房&quot;,..: 169 158 132 207 196 215 189 201 73 114 ... ## $ floor : Ord.factor w/ 4 levels &quot;地下室&quot;&lt;&quot;低楼层&quot;&lt;..: 2 2 2 4 3 2 3 4 3 3 ... ## $ year : int 2000 2002 1996 1997 2007 2010 2011 2008 2000 1998 ... ## $ school : Ord.factor w/ 2 levels &quot;无学区&quot;&lt;&quot;有学区&quot;: 2 2 1 1 1 1 1 1 1 1 ... ## $ subway : Ord.factor w/ 2 levels &quot;无地铁&quot;&lt;&quot;有地铁&quot;: 2 1 2 1 1 1 1 2 2 1 ... ## $ tax : Factor w/ 2 levels &quot;非免税&quot;,&quot;满五年唯一&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ num : int 360 950 290 260 95 350 220 120 180 205 ... ## $ price : int 53732 23285 38667 54622 11446 25736 32353 21053 32728 16016 ... ## $ meters_cg: Ord.factor w/ 5 levels &quot;0~50&quot;&lt;&quot;50~100&quot;&lt;..: 2 5 2 1 2 3 2 2 2 3 ... ## $ year_cg : Ord.factor w/ 7 levels &quot;&lt;1990&quot;&lt;&quot;90~95&quot;&lt;..: 4 4 3 3 5 6 6 5 4 3 ... ## $ num_cg : Ord.factor w/ 11 levels &quot;0~1&quot;&lt;&quot;1~2&quot;&lt;&quot;2~3&quot;&lt;..: 4 10 3 3 1 4 3 2 2 3 ... ## $ price_cg : Ord.factor w/ 11 levels &quot;0~1万&quot;&lt;&quot;1~2万&quot;&lt;..: 6 3 4 6 2 3 4 3 4 2 ... 三、数据概览下面从总体上看下数据， 1.县区分布 本次抽到的数据包括北京13个区和2个特别区域亦庄和燕郊，后两个地方不是区，但是在北京的朋友都知道，这两个地方有可能比某些区还有名。 总体来看市区的二手房市场比较活跃，可以看到朝阳、海淀、丰台分列三甲，三个区的二手房之和几乎占去了北京二手房一半的数量，朝阳一个区的岀房量更是比后两名都多。昌平区和燕郊紧随其后，昌平区有天通苑和回龙观这两个人口聚集区（这个后面会看到），而燕郊满足了一些在城区无法买房，又要在市区工作的人的需求，二手房数量也是不容小觑。 2.户型分布 最多的是两室一厅，占到33%，然后是一室一厅、三室两厅、三室一厅这样的户型。 看来小户型还是主流，不过这有可能因为一是大部分二手房年代较早，小户型较多,不过查看了下数据，2000年以后的房子二室一厅也有26%；另外一点可能是北京房价太贵，作为购房者的主体普通大众大部分购买力有限，开发商盖房的时候主要盖的就是这种户型。 3.面积分布 右上角密度图显示本次抽取的数据，面积的区间为0 ~ 3000平方，不过大部分的房子的面积还是集中在一个较小的范围内。从下图可以看到大部分面积都落在50 ~ 150这个区间，50 ~ 100的房子约为54%，而200平米以上的大房子仅为6%。 不太清楚其他地方的房子，在北京房子的面积和要交的税是有关系的。这可能在一定程度上会遏制房子的面积。 4.朝向分布 买过房的都知道，朝向很重要。什么东西向的只有早晚才能见阳光，北向的天天喝西北风，衣服都晒不干，还有一些风水上的讲究就更复杂了，反正我是不懂，凡此种种，充分说明了买房者对朝向的注重。 由于朝向比较多，这里只挑选了数量最多的10种。从图上我发现南北向、南向这些大家都比较喜欢的朝向竟然最多，二者合起来约有61%，这点和自己的看房经历不太一样，咋看有点不可思议，细想原因可能是这样的，一般楼房建设的时候，都是南北朝向的，我想没有哪个傻帽故意把房子盖成朝北的，盖好以后一些边角没有办法，朝向为东西、北等等，所以主体还是南北。 5.区域分布 由于区域众多，我这里只选择了出房量最多的10个区域。从上图可以看到，二手房数量最多的10个区域恰恰也是北京人口较为密集的区域，10个区域朝阳3个，昌平2个，房山1一个，顺义1个，门头沟1个，石景山1个，燕郊1个。 前面我们看到，北京二手房数量以朝阳为最，朝阳以望京为最，望京一个区域占了朝阳12%的房产数量。而天通苑、回龙观也不负众望，分别为第三和第四，另外如良乡、顺义城等我们熟知的人口聚居区交易也异常火爆，假如岀房量能在一定程度上代表交易量的话。 6.楼层分布 买房者对楼层的重视也是不言而喻，众所周知，顶层和低层的房子一般人都不太喜欢，顶层房子冬天冷夏天热，低楼层比较潮湿等等，这两种房子住起来不是那么舒服，所以我原本以为卖房的大部分是这两种楼层。 不过从数据上看，楼层分布比较平均，这点也和自己的看房经历不太一样，从自己的看房经历来看中楼层较少，大部分的二手房都是高楼层或者低楼层。原因可能和楼层的划分有关系，比如一座20层的楼房，1 ~ 5为低层，6 ~ 15为中层，16 ~ 20为高层，这样中楼层就比较多了。 7.建筑年代分布 房子的建筑年代对于土豪不是那么重要，但是对于普通购房者就不一样了，因为贷款的年限和房龄是有关系的。一般情况下钢混结构带电梯的贷款年限为57减去房龄，砖结构比如6层不带电梯的板楼是45减去房龄，具体的年限和你的房屋具体评估值有关系，我在网上找了半天，没有找到这种算法的明文规定，这应该是一个经验值，不过具有一定的准确性。也就是说你想贷款30年，钢混的必须至少为88年后的，砖混的必须至少是2000年后的。 数据显示，建筑年代区间为1952 ~ 2015，从图中可以看到，建筑年代主要集中在1995年到2015年这个时间段，2000年后的房子竟然占了总量的72%。这是我没有想到的，因为看房的时候，看到的房子基本上都是90年代的房子，这可能和当初我的定位有关系，当初买房的时候就想买个离市区近点的，上班方便，房子老点没关系，而市区可能新房子较少。 8.学区房、地铁房、免税房 这三个属性有点相似，放在了一起。这里没有对学区的优劣，地铁的远近等进行细分，只是简单粗暴的分为有无两种。 从图上可以看到学区的差异性较大，学区房只占总量的20%，怪不得学区房这么贵了；而地铁就较为普遍了，随着北京城市交通的建设地铁越来越多，表现在住房上就是地铁房的比例越来越高，约占41%，相信随着城市的发展，这个比例会越来越高。 税费这一项对于普通购房者也很重要，例如满五唯一只有1%的契税，满二唯一还要加收差价20%的个税，具体的费率和是否首套，房屋面积也有一定的关系，买房的朋友可以去查查。 数据显示，满五唯一的房子约为38%，比例不算低，看来，虽说大部分的房子都是2000年后的房子，有相当一部分的人还是在房子满五年之后再出售，虽然房主可以把税费转移到购房者身上，但是定价太高，房屋就不好出了，所以国家的征税政策对房产的恶意交易是有一定的作用的。 9.总价分布 对于总价和单价两种数据，我都是抱着猎奇的态度看待的，不过这两个数据的重要性自不必说，特别是总价，因为这关系到你的预算。看密度图（单位为万元），还真有3亿元的房子，我应该没数错0的个数，不过好在这样的房子只是凤毛麟角，让我等凡人还有些念想。 从直方图上可以看出100 ~ 300万的房子大概有50%，不过大于500万的房子也占到了17%，还得好好努力挣钱啊。 10.单价分布 单价对于普通购房者可能不够直接，因为在我看来，一般人买房之前先确定了总价，也就是自己能拿出多少钱，然后再结合自己大致的需求，比如想要一个多大的，什么户型的等等，总价和需求定了基本上能购买的单价也就定了，也就是说单价影响你选择的余地，比如说你本来想买个100平方的，你在看房过程中特别中意一个小区，那个小区单价贵，你能拿出的钱就那些，那你只能换一个小点的房子了。 密度图（单位元）显示还有30万一平方的房子，赶紧看看是何方宝地，原来是两套5平方的学区房，好吧，喝口水压压惊。不过好在单价主要还是集中在1 ~ 5万的区间，约占80%，其中2 ~ 4万最多，约为总量的50%。 上面大致看了下数据的总体情况，并尝试对一些原因做了分析，当然有些只是推测，这段时间比较忙，正好趁阅兵放假的时间看看能不能从数据中发现一些有利的证据。","categories":[{"name":"技术人生","slug":"技术人生","permalink":"https://pingao777.github.io/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"}],"tags":[{"name":"R","slug":"R","permalink":"https://pingao777.github.io/tags/R/"},{"name":"Python","slug":"Python","permalink":"https://pingao777.github.io/tags/Python/"},{"name":"统计","slug":"统计","permalink":"https://pingao777.github.io/tags/%E7%BB%9F%E8%AE%A1/"}]}]}